<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>Ayanami's Cave Blog</title>
        <link>https://ayanami1314.github.io/blog</link>
        <description>Ayanami's Cave Blog</description>
        <lastBuildDate>Sun, 23 Nov 2025 15:35:41 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[从现代Coding Agent视角回看代码搜索与嵌入]]></title>
            <link>https://ayanami1314.github.io/blog/code-search&amp;code-embedding</link>
            <guid>https://ayanami1314.github.io/blog/code-search&amp;code-embedding</guid>
            <pubDate>Sun, 23 Nov 2025 15:35:41 GMT</pubDate>
            <description><![CDATA[应该如何说起代码搜索呢，先说代码搜索的几个小的子流派吧，这方面可能略微和其他领域不同]]></description>
            <content:encoded><![CDATA[<p>应该如何说起代码搜索呢，先说代码搜索的几个小的子流派吧，这方面可能略微和其他领域不同</p>
<p>代码的检索我认为是可以分解成以下几种的：</p>
<ul>
<li>搜索引擎式</li>
<li>grep传统搜</li>
<li>向量embedding搜</li>
<li>码仓index</li>
</ul>
<p>每一种都是什么意思呢，举个例子</p>
<p>搜索引擎式是复用传统的搜索引擎，如elasticsearch, meilisearch等；也有一些变体，比如github的代码搜索，主要是弥补传统搜索引擎在代码搜索的不足</p>
<p>grep如其名字，基于linux grep或者riggrep，在agent内使用最广</p>
<p>向量embedding搜则有多个子任务，如NL2Code, Code2Code, Code2NL等，每个还有一些细微差别，这个很有意思，待会讲；</p>
<p>码仓index呢，则大致有两种：一种基于传统的AST分析，希望构建整个码仓的符号树或者CKG来辅助搜，另一种则寄希望于新型的生成式大模型，希望让LLM读了仓库之后能生成”索引“，典型的做法比如deepwiki。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="搜索引擎式">搜索引擎式<a class="hash-link" aria-label="Direct link to 搜索引擎式" title="Direct link to 搜索引擎式" href="https://ayanami1314.github.io/blog/code-search&amp;code-embedding#%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E5%BC%8F">​</a></h3>
<p>传统的搜索引擎其实在代码搜上有很多问题，参见</p>
<p><a href="https://github.blog/engineering/architecture-optimization/the-technology-behind-githubs-new-code-search/" target="_blank" rel="noopener noreferrer">https://github.blog/engineering/architecture-optimization/the-technology-behind-githubs-new-code-search/</a></p>
<p>最严重的问题甚至不是想象的NL2Code的问题，而是传统搜索引擎的部分优化不够、部分优化又不足，总之不与代码适配</p>
<ol>
<li>索引的开销, 恐怖的内存消耗</li>
</ol>
<blockquote>
<p>当我们第一次部署 Elasticsearch 时，需要几个月的时间才能索引 GitHub 上的所有代码（当时大约有 800 万个存储库）。今天，这个数字已经超过 2 亿，而且代码不是静态的：它不断变化，这对搜索引擎来说是相当具有挑战性的。</p>
</blockquote>
<ol start="2">
<li>可不可以不要索引？对大规模库高并发是不可能的：</li>
</ol>
<blockquote>
<p>首先，让我们探讨一下解决问题的蛮力方法。我们经常收到这样的问题：“你<strong>为什么不直接使用 grep</strong>？为了回答这个问题，让我们使用 <a href="https://github.com/BurntSushi/ripgrep" target="_blank" rel="noopener noreferrer">ripgrep</a> 对这 115 TB 的内容进行一些数学计算。在具有八核 Intel CPU 的机器上，ripgrep 可以在 2.769 秒内对缓存在内存中的 13 GB 文件运行<a href="https://github.com/BurntSushi/ripgrep#quick-examples-comparing-tools" target="_blank" rel="noopener noreferrer">详尽的正则表达式查询 </a>，即大约 0.6 GB/秒/内核。
我们很快就会发现，这对于我们拥有的大量数据来说确实不起作用。代码搜索在 64 个核心、32 个机器集群上运行。即使我们设法将 115 TB 的代码放入内存中并假设我们可以完美并行化工作，我们也会在 96 秒内使 2,048 个 CPU 内核饱和，以处理单个查询！只能运行一个查询。其他人都必须排队。结果是<strong>每秒 0.01 次查询</strong></p>
</blockquote>
<ol start="3">
<li>
<p>分词器不需要了：搜索引擎依赖分词来减少构建倒排的成本和作为基础搜索单元，但就和Tokenizer的引入一样，这个开销的减少从来不是免费的，接下来的问题就是：代码如何分词？另一个问题是：停用词全部没用了！无论是<code>!@?/#$:{}()[]</code>还是什么别的乱七八糟的符号，都是编程语言的最爱, 这使得传统的分词系统更加雪上加霜</p>
<ol>
<li>如果提前跑一遍AST分析呢？我们的CPU要算爆炸了<code>:)</code>, 并且你如何统一没有LSP小众语言，不同的语法版本（<code>py2-&gt;3</code>）... 工程量立刻爆炸了</li>
<li>能不能在char level倒排？太爆炸了索引，所以github是使用<strong>3-char</strong>的倒排的 <code>argument -&gt; arg、rgu、gum、...</code></li>
<li>代码里面还有注释，注释还有多语言，甚至单个仓库都很常见中英两种语言的注释...看起来朴素的分词器比如jieba要全面阵亡了...</li>
</ol>
</li>
<li>
<p>基于git的增量更新：增量更新本身可以用merkel tree，这也是cursor在用的技术，但结合git版本？你发现事情变得复杂起来了，这是纯工程的复杂性。一次git commit涉及到十几个文件的几行变化，需要触发至少十几个chunk的embedding更新？如何处理多分支呢？我的每一个存储代码块是否还得加一个tag标识它的branch，然后在搜索引擎里面支持完备地按tag过滤，省的不同branch的代码在同一个搜索引擎中返回？（然后发现branch name作为tag简直太烂了，它是一个完全动态的无限的集合）</p>
</li>
</ol>
<p>鉴于恐怖的存储代码数量，github采用的搜索引擎相当简陋，甚至是弱化版本的完全匹配：3-grams索引</p>
<blockquote>
<p>对于代码搜索，我们需要一种特殊类型的倒排索引，称为 ngram 索引，它对于查找内容的子字符串很有用。<a href="https://en.wikipedia.org/wiki/N-gram" target="_blank" rel="noopener noreferrer">ngram</a> 是长度为 <em>n</em> 的字符序列。例如，如果我们选择 n=3，则构成内容“limits”的 ngram 是 <code>lim</code>、<code>imi</code>、<code>mit</code>、<code>its</code>。<strong>(二元组的选择性不够，四元组占用了太多空间)</strong></p>
</blockquote>
<p>这个索引显然是非常大无法放入内存的，所以github采用了一些传统数据库里面的懒加载和流式优化技术，使得可以仅读取一个小子集完成搜索</p>
<p>而关于构建索引本身，github还有很多特殊设计，但这其实属于system/后端任务了，不细讲：</p>
<ul>
<li>
<p>用Git blob object ID来分片，kafka分区</p>
</li>
<li>
<p>用path, branch, repository + 元信息(owner, visibility, etc.) 来构建增量索引key</p>
</li>
<li>
<p>commit-level的一致性</p>
</li>
<li>
<p>Github相当多的blob是相同的，使用增量编码很有吸引力, 这里用到了概率上的近似数据结构和一些分布式图（近似）算法</p>
<blockquote>
<p>To determine the optimal ingest order, we need a way to tell how similar one repository is to another (similar in terms of their content), so <strong>we invented a new probabilistic data structure to do this in the same class of data structures as <a href="https://en.wikipedia.org/wiki/MinHash" target="_blank" rel="noopener noreferrer">MinHash</a> and <a href="https://en.wikipedia.org/wiki/HyperLogLog" target="_blank" rel="noopener noreferrer">HyperLogLog</a></strong>. This data structure, which we call a geometric filter, allows computing set similarity and the symmetric difference between sets with logarithmic space. <strong>In this case, the sets we’re comparing are the contents of each repository as represented by (path, blob_sha) tuples. Armed with that knowledge, we can construct a graph where the vertices are repositories and edges are weighted with this similarity metric. Calculating a minimum spanning tree of this graph (with similarity as cost) and then doing a level order traversal of the tree gives us an ingest order where we can make best use of delta encoding. Really though, this graph is enormous (millions of nodes, trillions of edges), so our MST algorithm computes an approximation that only takes a few minutes to calculate and provides 90% of the delta compression benefits we’re going for.</strong></p>
</blockquote>
</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="grep">Grep<a class="hash-link" aria-label="Direct link to Grep" title="Direct link to Grep" href="https://ayanami1314.github.io/blog/code-search&amp;code-embedding#grep">​</a></h3>
<p>grep属实是在Coding Agent时代焕发了第二春，由于其系统级别自带+完美匹配Bash工具和Unix文本管道的特性，在现代的LLM之中都大量训练了如何写出各种米奇妙妙grep的数据</p>
<p>claude code这种经过更多优化的grep会更过分一点，它会有几个细节优化：</p>
<ul>
<li>使用更现代的<code>rg</code>(riggrep)代替原始的grep</li>
<li>逆向cc源码可知，它的grep有<strong>七八个参数</strong>，分别对应grep里面的不同参数比如 <code>-A</code> <code>-E</code> <code>-C</code> , 除了一些呈现格式（比如带不带行号和文件名）之类的差别，主要的几个参数就是在<strong>匹配行前保留多少行、匹配行后保留多少行、和上下保留多少行</strong>
<ul>
<li>如果读者熟悉coding agent的工作的话，其实早在swe-agent就已经探究过这个context window开多少的问题，原始论文的实验结论是50行</li>
</ul>
</li>
</ul>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">❯ tldr grep</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">grep</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Find patterns in files using regular expressions.More information: https://www.gnu.org/software/grep/manual/grep.html.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> - Search for a pattern within a file:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   grep "{{search_pattern}}" {{path/to/file}}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> - Search for an exact string (disables regular expressions):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   grep {{[-F|--fixed-strings]}} "{{exact_string}}" {{path/to/file}}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> - Search for a pattern in all files recursively in a directory, showing line numbers of matches, ignoring binary files:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   grep {{[-r|--recursive]}} {{[-n|--line-number]}} --binary-files {{without-match}} "{{search_pattern}}" {{path/to/directory}}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> - Use extended regular expressions (supports ?, +, {}, (), and |), in case-insensitive mode:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   grep {{[-E|--extended-regexp]}} {{[-i|--ignore-case]}} "{{search_pattern}}" {{path/to/file}}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> - Print 3 lines of [C]ontext around, [B]efore or [A]fter each match:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   grep --{{context|before-context|after-context}} 3 "{{search_pattern}}" {{path/to/file}}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> - Print file name and line number for each match with color output:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   grep {{[-H|--with-filename]}} {{[-n|--line-number]}} --color=always "{{search_pattern}}" {{path/to/file}}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> - Search for lines matching a pattern, printing only the matched text:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   grep {{[-o|--only-matching]}} "{{search_pattern}}" {{path/to/file}}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> - Search stdin for lines that do not match a pattern:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   cat {{path/to/file}} | grep {{[-v|--invert-match]}} "{{search_pattern}}"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>另一个有趣的事情是，现在的coding agent不约而同地使用了grep而不是rag作为其系统原生的工具，我觉得理由也是非常清晰的：</p>
<ol>
<li>grep的输出是标准可预测的，而rag的输出依赖于 <code>{基础模型， 分块方法，召回topk，重排模型}</code> 等多个配置参数，一个标准的输出带来的好处是 <strong>可强化学习</strong>， 如果对一个 code llm + rag 的系统做RL，最后的搜索策略一定会是拟合到和rag的embedding模型和具体策略相匹配，丧失了可迁移性</li>
<li>除此之外的好处也有很多，比如RL环境不需要embedding的额外开销（存储和计算上甚至编码成本上），整体轨迹可解释，精确匹配效果好，速度快...</li>
</ol>
<p>rag的index开销其实相当大，学界不在乎这个，为了提升精度每个token一个embedding的方法也有，但一个embedding是一个1024维的向量，光存储开销就是4KB，对于百万行级别的代码仓库，其chunk可能在数万，达到了GB级别的存储开销</p>
<p>而工业项目有百万码仓，在TB级别的存储上进行高效地索引和查询着实压力很大，可以参考 美团和milvus/lancedb的相关文章 ，索引优化也有相当多的新实践，但这是做DB的人考虑的（雾</p>
<p>但Grep就是万灵药吗？并非如此</p>
<p><strong>Grep提供了一个切面，能够让模型Agentic Search，根据搜索到的局部反馈调整搜索方法，从部分开始探索整个代码仓库——大部分需求的完成不需要对全仓的理解</strong></p>
<p>——吗？</p>
<p>一个Grep的bad case是<strong>高阶语义的需求</strong>：</p>
<ul>
<li>哪里导致了这个bug?</li>
<li>某个模块的核心逻辑是什么？</li>
<li>整体的代码结构？</li>
<li>...</li>
</ul>
<p>模型要么老实cat，要么就只能在log中见到它尝试“猜”你的变量名字，比如你问“...的实现”就会开始Grep <code>impl</code>，如果你把所有变量换成abcde，它立刻就GG了</p>
<p>比起失败的搜索浪费的上下文更糟地是浪费的交互轮数 —— 长达几百轮的agent轨迹是相当稀少的训练数据，如果再配合没那么好的历史压缩方法，或是没有精心设计的防止模型死循环的额外环境反馈，连续失败的grep会让agent的性能迅速地劣化</p>
<p>基于这方面的需求，在推理阶段Grep还是得配合别的工具，比如deepwiki，比如CKG（代码知识图谱，例如每个函数的caller和callee），</p>
<p>比如Code RAG</p>
<p>这方面也有一些新的探索，例如 <a href="https://cognition.ai/blog/swe-grep" target="_blank" rel="noopener noreferrer">https://cognition.ai/blog/swe-grep</a> 的RL并行工具调用（<strong>关键不在速度，关键在减少交互轮数！</strong>），比如在工程侧融合Grep和RAG如<a href="https://github.com/daimh/mgrep" target="_blank" rel="noopener noreferrer">https://github.com/daimh/mgrep</a> 和 <a href="https://github.com/zilliztech/claude-context" target="_blank" rel="noopener noreferrer">https://github.com/zilliztech/claude-context</a> ，以及我们将要发的一篇文章（自吹自擂一下，关注主包后续的工作谢谢喵）</p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="code-embedding">code embedding<a class="hash-link" aria-label="Direct link to code embedding" title="Direct link to code embedding" href="https://ayanami1314.github.io/blog/code-search&amp;code-embedding#code-embedding">​</a></h3>
<p>主包主包，code embedding和文本的embedding有什么区别呢？为什么要强调code?</p>
<p>非常好问题，爱来自AI4SE。我认为code其实和图像比较像，某种意义上<strong>算是一种特殊的模态</strong>，不完全是文本——code某种意义上是“反语言常理”的，例如大部分语言的上下文有限，一句话很难和1000个字之前的某个东西形成强烈的联系，而这种长程交互在code之中非常常见——甚至有跨文件、跨模块、跨仓库的交互</p>
<p>而另一个很有趣的事情是，<strong>当我们在讲“某段代码的语义”的时候，这件事本身是模糊的</strong>，文本没有那么强的二义性，太阳就是太阳，月亮就是月亮，但一个递归斐波那契函数的语义到底是 “递归“ 还是 ”斐波那契“？这其实折射出了代码的某种特殊性，它同时具备<strong>字面义</strong> ”斐波那契“ 和<strong>运行义</strong> ”递归“（甚至”低效“、”算法“、“python”），而在一个代码仓库之中，代码还具备了<strong>上下游的属性</strong>：谁是我的caller，谁是我的callee?</p>
<p><strong>这件事情为什么重要呢，因为传统的embedding向量相似度产出的是一个标量，它只能衡量一个维度的相似性！</strong></p>
<ul>
<li>当你在说“查找与function A相关的代码”时，你想要的到底是什么？<!-- -->
<ul>
<li>function A的字面义相关的代码？</li>
<li>function A的运行效果相关的代码？</li>
<li>function A的caller/callee?</li>
<li>...</li>
</ul>
</li>
</ul>
<p>然后你就发现从这个角度上来说，Code2Code的向量搜是很诡异的一件事情，至少传统的cos相似度无法干这件事——</p>
<ul>
<li>更悲伤（从学术研究的角度上来说或许是兴奋）的是，在现实需求中，我们真的不在意找到和一个function的字面意相关的function...假设你想要补全一段代码，你可能更需要关注谁会是它的caller，假设你需要优化一段代码，你可能搜索的方法是某种低效的pattern...<strong>而这些embedding相似度全部做不到</strong>
<ul>
<li>据我所知，企业对这个接近摆烂了，只有MSRA有一个group还在研究，我之前溯源到的比较早的上下游建模技术是Order Embedding，感兴趣的或许可以试试做</li>
</ul>
</li>
</ul>
<p><strong>直接结果是：我们只有NL2Code了</strong></p>
<p>并且这个NL也只能关注一个方面...</p>
<p>什么样的NL才是真实会问会写的NL呢？Coding Agent的轨迹数据</p>
<p>没有轨迹数据怎么办？从大规模代码中<strong>挖掘注释作为NL</strong></p>
<p><strong>一个人写注释的方法和提问的方法不一样，这个语义空间的unmatch如何处理？各家自显神通</strong></p>
<ul>
<li>
<p>例如2025年5月快手的OASIS: Order-Augmented Strategy for Improved Code Search，认为<strong>现有的code</strong> <strong>embedding</strong>往往关注的是<strong>代码的字面相似性</strong>，即只把代码认为是一种特殊的“语言”，而忽略了代码的非文字意义上的相似性</p>
<ul>
<li>对代码片段（结合其他静态分析信息），用LLM产生其作用的描述文本</li>
<li>计算这个描述文本和其他代码片段的相似性，以此来挖掘难负样本</li>
<li>因为这个文本描述的是相对High Level的函数作用，能够一定程度上避免变量名字等带来的影响，专注于实际作用</li>
</ul>
</li>
<li>
<p>24年12月的Nomic AI的cornstack</p>
<ul>
<li>强调<code>&lt;文档，代码&gt;</code>对的相关性重要性，并采用双重过滤：如果文档与代码间相似度低，或者并不在topK，只要有一个满足就筛掉</li>
<li>动态硬负例挖掘策略：对于批内负样本挖掘，采用softmax概率采样，但是在训练过程中，逐步改变softmax的温度，前期温度高提高多样性，后期温度低，注重难负样本的区分</li>
</ul>
</li>
<li>
<p>25年5月的BAAI Towards A Generalist Code Embedding Model Based On Massive Data Synthesis</p>
<ul>
<li>强调退火训练，第一阶段纯文本，第二阶段全数据训练text-code能力，第三阶段纯代码</li>
</ul>
</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="码仓index---deepwikickg">码仓Index - DeepWiki/CKG<a class="hash-link" aria-label="Direct link to 码仓Index - DeepWiki/CKG" title="Direct link to 码仓Index - DeepWiki/CKG" href="https://ayanami1314.github.io/blog/code-search&amp;code-embedding#%E7%A0%81%E4%BB%93index---deepwikickg">​</a></h3>
<p>这个说起来就比较简单了，deepwiki重要的始终是LLM的能力，而CKG则是静态分析的质量，开源的tree-sitter固然可用，企业也有一些统一各种语言的私有AST，静态分析已经日趋成熟，困难的是<strong>如何将这个信息给到LLM</strong>？</p>
<p>很早在Google的博客中就有论述: <strong>现在的vibe coding就像是把一个几千行的代码粘贴到记事本里面，然后让程序员来修改bug</strong> —— LLM看到的就是 “记事本”，而不是程序员的带有各种Lint和跳转的IDE界面</p>
<p>AST分析树如此庞大，除了摆烂式地提供一个获取caller/callee的mcp工具给agent之外，还可以做些什么？</p>
<p>先前在web领域有一个llms.txt的旨在LLM-friendly的格式，代码领域却暂时缺乏哪怕是新兴的统一处理格式</p>
<p>AI-friendly IDE可能对于Coding Agent的能力提升相当重要，这也是moonbit社区他们宣传的，不过我没有实际上手用过，也不是学PL的，就不瞎讲了，感兴趣的可以看张宏波的演讲</p>
<p>【AI时代下的基础软件 | 张宏波 刘子悦 蚂蚁&amp;MoonBit Meetup杭州站回放】</p>
<p><a href="https://www.bilibili.com/video/BV1wL8DzgEXZ/" target="_blank" rel="noopener noreferrer">https://www.bilibili.com/video/BV1wL8DzgEXZ/</a></p>
<p><strong>除此之外，可能我们原先认为不能搜索或者没必要搜索的部分，现在也正在发挥着额外的作用</strong>：</p>
<ul>
<li>python的package，众所周知（可能并非），pip包只是一个特殊的压缩包，可以直接看到文本格式的原始代码，现代的claude-sonnet-4等模型在环境出错的时候会主动读/搜 <code>pyproject.toml</code>, <code>.venv</code>等特殊文件，遇到<code>import</code>的不了解api还会尝试进入package观看源码</li>
<li>而某些binary风格或是一串神秘哈希引入的包可能对于LLM并不是很友好...</li>
</ul>
<p>除此之外也有很多新兴的想法，例如注释本身可不可以作为一个天生的码仓Index? ...</p>
<p><strong>CLI版本</strong>的Coding Agent好处是可以在各处方便的引用，尤其利于<strong>大规模并发采集数据</strong></p>
<p>但<strong>IDE版本的Coding Agent则会更加地“懂人</strong>”，原因是AI IDE在背后做了一大堆不仅仅是diff等格式渲染的工作，用户环境信息，用户系统信息，... 这些都被从后台塞入了Coding Agent的system prompt，使得你在Linux上运行Copilot的时候，模型不会让你执行 <code>brew install</code>命令</p>
<p>但文本本身依然有着局限，或许在某个未来，我们能看到真正的code native架构，不在绞尽脑汁地想把编译器的报错，AST的分析等等原本结构化的东西转成markdown再塞入永远不够的agent上下文...</p>]]></content:encoded>
            <category>ai</category>
            <category>ai4se</category>
            <category>coding agent</category>
            <category>embedding</category>
            <category>rag</category>
        </item>
        <item>
            <title><![CDATA[李沐dl笔记]]></title>
            <link>https://ayanami1314.github.io/blog/AI limu</link>
            <guid>https://ayanami1314.github.io/blog/AI limu</guid>
            <pubDate>Sun, 23 Nov 2025 15:28:43 GMT</pubDate>
            <description><![CDATA[vgg]]></description>
            <content:encoded><![CDATA[<h3 class="anchor anchorWithStickyNavbar_LWe7" id="vgg">vgg<a class="hash-link" aria-label="Direct link to vgg" title="Direct link to vgg" href="https://ayanami1314.github.io/blog/AI%20limu#vgg">​</a></h3>
<p>内存占用大，推理慢（深），但效果好</p>
<p>卷积层参数小，全连接层最大问题是参数太大过拟合</p>
<p>所以最后一层全连接是很大的问题</p>
<p>大参数还有内存 bound 的问题</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="nin">NiN<a class="hash-link" aria-label="Direct link to NiN" title="Direct link to NiN" href="https://ayanami1314.github.io/blog/AI%20limu#nin">​</a></h3>
<p>用卷积层替代全连接</p>
<p>两个 1*1 卷积无 padding, stride1 起全连接的作用(只做通道混合)</p>
<p>每个卷积后面跟两个全连接作为 NiN block</p>
<p>交替使用 NiN 块和 stride = 2 的 maxpooling 逐步减小高宽和增大通道数</p>
<p>最后使用全局平均池化得到输出(通道数 = 分类个数)</p>
<p>打印结构:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> layer </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> net</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    X </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> layer</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">X</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">layer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">__class__</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">__name__</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"output shape:\t"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> X</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">shape</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>超级宽的 hidden layer: 非常容易过拟合</p>
<p>泛化性提高-&gt; 收敛变慢</p>
<p>全连接的方案: 非常强, 收敛很快</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="googlenet">GoogLeNet<a class="hash-link" aria-label="Direct link to GoogLeNet" title="Direct link to GoogLeNet" href="https://ayanami1314.github.io/blog/AI%20limu#googlenet">​</a></h3>
<p>inception 块: 不做选择, 全都要</p>
<p>output = output1 + o2 + o3 + o4</p>
<p>o1 = conv1x1</p>
<p>o2 = conv1x1 + conv3x3, padding 1</p>
<p>o3 = conv1x1 + conv3x3, padding 1 + conv5x5, padding 2</p>
<p>o4 = 3x3 maxpool, padding 1</p>
<p>四条路径从不同层面抽取信息, 在输出通道合并 concatenation</p>
<p>四条路径分配不同的通道数(你认为那种模式哪个通道的信息更重要)</p>
<p>降低通道数来控制模型复杂度</p>
<p>googlenet 5 段, 9 个 inception 块</p>
<p>不降低维数的 1x1 卷积就是通道融合</p>
<p>第一个 stage 总是把通道数拉上去, 高宽减下去, 先筛选出足够多的特征</p>
<p>v2: batch normalization</p>
<p>v3: 5x5-&gt; 3x3, 5x5-&gt; 1x7+7x1(单长和单宽)</p>
<p>v4: 残差连接</p>
<p>优点是模型参数少, 计算复杂度低</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="批量归一化">批量归一化<a class="hash-link" aria-label="Direct link to 批量归一化" title="Direct link to 批量归一化" href="https://ayanami1314.github.io/blog/AI%20limu#%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96">​</a></h3>
<p><strong>损失出现在最后, 后面的层训练快</strong></p>
<p><strong>反向传播: loss 在顶层, 数据在最底部, 底部的层(前面的层)训练慢, 底部层一变, 所有都得跟着变</strong></p>
<p><strong>导致离 loss 近的后面层需要重新学习多次, 导致收敛变慢</strong></p>
<p><strong>有没有方法让学习前面层的时候避免变化后面层?</strong></p>
<p>批量归一化: 将分布固定, 来让输出模式稳定一些, 固定小批量的均值和方差</p>
<p>正则化, 将数据分布固定为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">N(0,1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.10903em">N</span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span> 正态分布, 数据的修改只是在变化正态分布的超参数, 限制变化不要太剧烈</p>
<p>对于全连接, 作用 <strong>在激活函数前面</strong>, 作用在特征维度</p>
<p>对卷积, 作用在通道维</p>
<p>效果太好了, 原始论文觉得是减少内部协变量转移, 后续发现 <strong>可能就是等效于在每个小批量里面加入噪音来控制模型</strong>, 均值近似于随机偏移, 方差近似于随机缩放</p>
<p><strong>因此没必要和丢弃混合使用</strong></p>
<p><strong>加速收敛(模式更稳定之后可以把 lr 调得更大), 但一般不改变模型精度</strong></p>
<p>根据内存挑 batch size, 不能太大也不能太小, 然后调学习率和 epoch</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="resnet">ResNet<a class="hash-link" aria-label="Direct link to ResNet" title="Direct link to ResNet" href="https://ayanami1314.github.io/blog/AI%20limu#resnet">​</a></h3>
<p>残差的重要性不必多言</p>
<p>深网络必有残差思想</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="新硬件">新硬件<a class="hash-link" aria-label="Direct link to 新硬件" title="Direct link to 新硬件" href="https://ayanami1314.github.io/blog/AI%20limu#%E6%96%B0%E7%A1%AC%E4%BB%B6">​</a></h3>
<p>DSP 主要做数字计算处理长指令, FPGA 可编程阵列</p>
<p>工具链质量良莠不齐, 一次 "编译" 需要很久</p>
<p>AI ASIC: Google TPU eg</p>
<p>核心 systolic array, 专门做大矩阵乘法 2d 计算单元(PE)阵列, 卷积换成矩阵乘法</p>
<p>一般的矩阵乘: 切开和填充匹配 SA 大小</p>
<p>批量输入来降低延时, 其他硬件单元来处理别的 NN 操作子, 例如激活层</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="多卡并行">多卡并行<a class="hash-link" aria-label="Direct link to 多卡并行" title="Direct link to 多卡并行" href="https://ayanami1314.github.io/blog/AI%20limu#%E5%A4%9A%E5%8D%A1%E5%B9%B6%E8%A1%8C">​</a></h3>
<p>数据并行(切割小批量), 模型并行(切割模型, 适用于模型太大的时候),</p>
<p>all reduce: 将所有 gpu 的结果放到一个 gpu 上, 然后相加, 加完再复制回其他 gpu</p>
<p><code>nn.parallel.scatter</code></p>
<p><code>nn.DataParallel</code></p>
<p>多卡时也要相应的加大 batchsize 和 lr</p>
<p>大 batch size 在小模型上会采出重复样本导致浪费和一定程度上的过拟合</p>
<p>分布式</p>
<p>GPU 和 GPU 通信快, 和 CPU 通信慢, 和交换机网卡更慢</p>
<ul>
<li>类似存储器山</li>
</ul>
<p>解法是把 parameter server 尽量从 cpu 搬到 gpu 上</p>
<p>这样简单的 parameter 迁移分配就能在 gpu 本地完成, 不涉及到 cpu 的 copy(感觉像 DMA)</p>
<p>每个 worker 拿参数, 复制到 GPU 上, 每个 GPU 算自己的梯度, GPU 梯度求和, 传回服务器, 再更新, 回发</p>
<p>类似 mr, server mapper, 本地 gpu 完成计算和 combine, 在 server reduce</p>
<p>同步 SGD, 每个 worker 同步计算一个批量</p>
<p>所以需要调 batch size, 来针对并行省下的时间与通信开销做 trade off</p>
<p>实践:</p>
<ul>
<li>大数据集</li>
<li>好的 GPU-GPU 和机器-机器带宽</li>
<li>高效的数据读取和预处理</li>
<li><strong>好的计算(FLOP)和通信(model size)比 Inception &gt; ResNet &gt; AlexNet</strong></li>
<li>足够大的 batch size</li>
<li>高效优化算法（因为 batch size 变大了, 如何适配）</li>
<li>更复杂的分布式有异步, 模型并行</li>
</ul>
<p>一般 N 个类, batch size 差不多到 10N 再往上就不太能 fit 了</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="数据增广">数据增广<a class="hash-link" aria-label="Direct link to 数据增广" title="Direct link to 数据增广" href="https://ayanami1314.github.io/blog/AI%20limu#%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%B9%BF">​</a></h3>
<p>已有数据集让他有更多多样性</p>
<ul>
<li>在语言里面加背景噪音</li>
<li>改变图片的亮度, 颜色, 形状</li>
</ul>
<p>一般的做法: 原始数据在线生成, 随机增强</p>
<p>测试不做增强</p>
<p>翻转:</p>
<ul>
<li>左右翻转, 上下翻转</li>
<li>切割, 随即高宽比, 随机大小, 随机位置</li>
</ul>
<p>其他:</p>
<ul>
<li>高斯模糊</li>
<li>锐化</li>
<li>变形</li>
<li>滤镜</li>
<li>马赛克（相当于遮挡, 逼着去看全局）</li>
<li>...</li>
</ul>
<p>从实际部署的场景反推需要什么样的增强</p>
<p>异常检测, 偏斜数据, 重采样, 增广</p>
<p>mixup 增广: 有效但不知道为什么</p>
<p><code>torchvision.transforms</code></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="微调迁移学习">微调(迁移学习)<a class="hash-link" aria-label="Direct link to �微调(迁移学习)" title="Direct link to 微调(迁移学习)" href="https://ayanami1314.github.io/blog/AI%20limu#%E5%BE%AE%E8%B0%83%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0">​</a></h3>
<p>标注一个数据集很贵</p>
<p>希望在大数据集上做好的东西, 能以小代价迁移到小数据集上</p>
<p>神经网络分层两块: 特征提取+线性分类</p>
<p>dl: 让特征提取变得可以学习, 而不是人来提取特征</p>
<p>训练:</p>
<ul>
<li>更强正则化</li>
<li>更小学习率</li>
<li>更少的数据迭代</li>
</ul>
<p>源数据集远复杂于目标, 微调效果更好</p>
<p>固定一些层, 固定底部一些层的参数, 不参与更新</p>
<p>低层次的特征更加通用</p>
<p>小 trick, 微调的时候最后一层用大学习率, 前面用小的</p>
<p>迁移的也不能差太大, 否则效果很可能不够好</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="目标检测">目标检测<a class="hash-link" aria-label="Direct link to 目标检测" title="Direct link to 目标检测" href="https://ayanami1314.github.io/blog/AI%20limu#%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B">​</a></h3>
<p>bounding box</p>
<p>锚框: 提出多个被称为锚框的区域, 预测每个框里面是否有关注的物体, 如果是, 预测锚框到真实框的偏移</p>
<p>交并比 IoU</p>
<p>每个锚框是一个训练样本, 要么标注成背景, 要么关联一个真实边缘框</p>
<p>可能生成大量锚框, 导致大量的负类样本</p>
<p>选择合适的锚框(赋予锚框标号):</p>
<p>先生成一堆框, 之后算锚框 i 和真实框 j 的 IoU, 在 i, j 之中找最大的, 就得到了一组锚框和真实框的对应</p>
<p>然后从集合中剔除这个锚框 i 和边缘框 j(删除矩阵行列), 再找下一组</p>
<p>重复直到真实框为空, 这就是正类样本, 剩下的锚框挑一些作为负类样本</p>
<p>锚框生成: 一种固定切分画格子</p>
<p>NMS 非极大抑制: 合并相似的预测框</p>
<ul>
<li>选中非背景类的最大预测值</li>
<li>去掉所有和它 IoU 大于阈值的预测</li>
<li>重复直到所有预测要么被选中, 要么被去掉</li>
</ul>
<p>生成锚框的另一种示例方法</p>
<p>宽度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi><mi>s</mi><msqrt><mi>r</mi></msqrt></mrow><annotation encoding="application/x-tex">ws\sqrt r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.04em;vertical-align:-0.2397em"></span><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="mord mathnormal">s</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8003em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:0.02778em;padding-left:0.833em">r</span></span><span style="top:-2.7603em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2397em"><span></span></span></span></span></span></span></span></span>, 高度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mi>s</mi><mi mathvariant="normal">/</mi><msqrt><mi>r</mi></msqrt></mrow><annotation encoding="application/x-tex">hs/\sqrt{r}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0503em;vertical-align:-0.25em"></span><span class="mord mathnormal">h</span><span class="mord mathnormal">s</span><span class="mord">/</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8003em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord" style="padding-left:0.833em"><span class="mord mathnormal" style="margin-right:0.02778em">r</span></span></span><span style="top:-2.7603em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2397em"><span></span></span></span></span></span></span></span></span></p>
<p>对给定几组 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>r</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(s,r)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="mclose">)</span></span></span></span> 对每(n)个像素生成</p>
<p>算法的核心之一: 如何生成高质量锚框</p>
<p>锚框到偏移的算法: 多种多样</p>
<p>autogluon</p>
<p>工业界很少用模型融合和测试增强, 计算代价过高</p>
<p>通常固定模型超参数, 简单模型, 精力花在提升数据质量和加入的新数据</p>
<p>RCNN:</p>
<p>启发式搜索算法选择锚框</p>
<p>预训练模型对每个锚框抽取特征</p>
<p>训练一个 SVM 对类别分类</p>
<p>训练一个线性回归来预测偏移</p>
<p>RoI pooling</p>
<p>锚框均匀分割 mxn, 输出每块里面的最大值</p>
<p>不管锚框多大, 总是输出 mn</p>
<p>Fast RCNN</p>
<p>不再对每一个锚框抽取特征</p>
<p>而是将所有的锚框丢进 cnn(输入里面对应的映射区域), 一次 CNN 对整个图片抽取</p>
<p>Faster RCNN: 使用区域提议网络代替启发式搜索来获得更好的锚框</p>
<p>2-stage</p>
<p>Mask RCNN 如果有像素级别的编号, 给每个像素做预测, 用 FCN 利用信息</p>
<p>Faster RCNN: 速度非常慢, 精度高</p>
<p>SSD: single stage</p>
<p>基础网络抽特征, 多个 conv 减半高宽</p>
<p>每段都生成锚框</p>
<ul>
<li>底部段拟合小物体, 顶部段拟合大物体</li>
</ul>
<p>对每个锚框预测类别和边缘框</p>
<p>yolo: 追求快</p>
<p>ssd 锚框大量重叠, 浪费计算</p>
<p>均匀切分 SxS 个锚框, 每个锚框预测 B 个边缘框</p>
<p>后续有许多微调和改进</p>
<p>工业常用</p>
<p>非锚框: 例如 central net</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="语义分割">语义分割<a class="hash-link" aria-label="Direct link to 语义分割" title="Direct link to 语义分割" href="https://ayanami1314.github.io/blog/AI%20limu#%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2">​</a></h3>
<p>像素级分类</p>
<p>应用: 背景虚化, 路面分割</p>
<p>另一个相近的概念: 实例分割</p>
<p>数据集: 输入是图片, label 也是图片(每个像素的值就是 label)</p>
<p>crop: 怎么做, 对输入进行裁剪, 在 label 上也要相对应的裁剪</p>
<p>拉伸也是需要特殊处理的</p>
<p>旋转? 一种是可以加一个 label 是旋转角度, 另一个是可以在转完的斜框上涨再画一个大框框住斜框</p>
<p>人像: 难点在光照, 阴影和背景</p>
<p>人像语义分割: pretrain model 已经很成熟</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="转置卷积">转置卷积<a class="hash-link" aria-label="Direct link to 转置卷积" title="Direct link to 转置卷积" href="https://ayanami1314.github.io/blog/AI%20limu#%E8%BD%AC%E7%BD%AE%E5%8D%B7%E7%A7%AF">​</a></h3>
<p>卷积的问题：不能很有效的增加高宽</p>
<p>类似语义分割这种-&gt; 卷积不断减小高宽, 会影响像素级别的输出</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo stretchy="false">[</mo><mi>i</mi><mo>:</mo><mi>i</mi><mo>+</mo><mi>h</mi><mo separator="true">,</mo><mi>j</mi><mo>:</mo><mi>j</mi><mo>+</mo><mi>w</mi><mo stretchy="false">]</mo><mo>+</mo><mo>=</mo><mi>X</mi><mo stretchy="false">[</mo><mi>i</mi><mo separator="true">,</mo><mi>j</mi><mo stretchy="false">]</mo><mo>×</mo><mi>K</mi></mrow><annotation encoding="application/x-tex">Y[i:i+h, j:j+w] += X[i,j] \times K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.22222em">Y</span><span class="mopen">[</span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7429em;vertical-align:-0.0833em"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal">h</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.05724em">j</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05724em">j</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="mclose">]</span><span class="mord">+</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="mopen">[</span><span class="mord mathnormal">i</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.05724em">j</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">K</span></span></span></span></p>
<p>增大输入高宽</p>
<p>为什么是转置卷积:</p>
<p>卷积等价于矩阵乘法 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>=</mo><mi>V</mi><mi>X</mi></mrow><annotation encoding="application/x-tex">Y = VX</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.22222em">Y</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="mord mathnormal" style="margin-right:0.07847em">X</span></span></span></span>, 转置卷积就是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>=</mo><msup><mi>V</mi><mi>T</mi></msup><mi>X</mi></mrow><annotation encoding="application/x-tex">Y = V^{T}X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.22222em">Y</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.07847em">X</span></span></span></span></p>
<p><code>nn.ConvTranspose2d</code></p>
<p>卷积是下采样, 卷积是上采样</p>
<p>转置卷积与线性插值: 可以用线性插值作为转置卷积核的初始值</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="fcn">FCN<a class="hash-link" aria-label="Direct link to FCN" title="Direct link to FCN" href="https://ayanami1314.github.io/blog/AI%20limu#fcn">​</a></h3>
<p>全连接卷积神经网络</p>
<p>用 dl 做语义分割的最早工作</p>
<p>用转置卷积替换 CNN 最后的全连接层+全局池化</p>
<ul>
<li>先过 1x1 conv 压缩通道</li>
<li>再过转置卷积拉大图片, 得到像素级别的切分<!-- -->
<ul>
<li>思想是每个像素的的 label 信息这个 feature 应该存在 channels 里面</li>
</ul>
</li>
</ul>
<p><code>net = nn.Sequential(*list(pretrained_cnn.children()))[:-2]</code></p>
<p>可以用双线性插值的矩阵初始化转置卷积层的 kernel</p>
<p>loss: 由于每一个像素都有了 label</p>
<p>所以在矩阵上做均值再 cross_entropy</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="样式迁移">样式迁移<a class="hash-link" aria-label="Direct link to 样式迁移" title="Direct link to 样式迁移" href="https://ayanami1314.github.io/blog/AI%20limu#%E6%A0%B7%E5%BC%8F%E8%BF%81%E7%A7%BB">​</a></h3>
<p>基于 CNN 的样式迁移</p>
<p>核心思想: 训练一个 CNN, 将他作用在内容图片上得到输出, 在样式图片上得到输出</p>
<p>而输出图片在内容层上的输出和内容图片在内容层上的输出相近(content loss)</p>
<p>输出图片在样式层上的输出和样式图片在样式层上的输出相近(style loss)</p>
<p>训练的不是 CNN, 而是输入网络的的“输出图片”</p>
<p>哪些层是“style layer”, 哪些是 "content layer"?</p>
<p>样式: 最小, 中间和上层, 较均匀</p>
<ul>
<li>样式有全局的特征和局部的特征, 各个尺度均有</li>
</ul>
<p>内容: 偏末尾的层, 靠近 loss</p>
<ul>
<li>允许内容上更多的变形</li>
</ul>
<p>内容损失可以是简单的 MSE</p>
<ul>
<li>元素值, 通道里面的值, 认为是内容</li>
</ul>
<p>样式损失? 通道内部和之间的统计分布, 认为是样式</p>
<ul>
<li>分布匹配, 一阶平均值, 二阶协方差, 用二阶就还不错</li>
</ul>
<p>最后: tv_loss, 不要有噪点, 每个像素和周围像素不要差太多, 计算每个与周围的 MSE 再求平均</p>
<p>这几个损失如何加起来? 加权平均, 权值是超参数</p>
<p>style 一般更重要, 例如 <code>content:style:tv=1:1000:10</code></p>
<p>这几个超参数的调整是训练几次之后, 观察三种 loss, 调到差不多大小得出的</p>
<p>不更新: <code>y.detach()</code></p>
<p>卷积只作为抽特征</p>
<p>麻烦: 后续技术, GAN, 使用 CNN 接收随机输入生成图片等</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="序列模型">序列模型<a class="hash-link" aria-label="Direct link to 序列模型" title="Direct link to 序列模型" href="https://ayanami1314.github.io/blog/AI%20limu#%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B">​</a></h3>
<p>标号和样本是一个东西: 自回归模型 <code>t-k ~ t-1 -&gt; t</code></p>
<p>方法 A: 马尔可夫假设: 假设当前数据只和 k 个过去数据点相关</p>
<p>方法 B: 潜变量模型: 引入潜变量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">h_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> 来表示过去信息 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub><mo>=</mo><mi>p</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>t</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>h</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">x_t = p(x_t|h_t)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>t</mi></msub><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">h_t = f(x_1,...x_{t-1})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">...</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p>
<p>那我们就可以将预测拆成两步:</p>
<ol>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>t</mi></msub><mo>=</mo><mi>M</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi><mn>1</mn><mo stretchy="false">(</mo><msub><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">h_t = Model1(h_{t-1}, x_{t-1})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span><span class="mord mathnormal">o</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord">1</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub><mo>=</mo><mi>M</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi><mn>2</mn><mo stretchy="false">(</mo><msub><mi>h</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">x_t = Model2(h_t, x_{t-1})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span><span class="mord mathnormal">o</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord">2</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="文本预处理">文本预处理<a class="hash-link" aria-label="Direct link to 文本预处理" title="Direct link to 文本预处理" href="https://ayanami1314.github.io/blog/AI%20limu#%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86">​</a></h3>
<p>预处理的核心是分词</p>
<p>GPU 上存算的是 token 索引而非字符串</p>
<p>语言模型:</p>
<p>给定文本序列, 估计联合概率</p>
<ul>
<li>做预训练模型</li>
<li>生成文本</li>
<li>判断多个序列之中哪个更常见</li>
</ul>
<p>简单方法: 基于计数建模</p>
<p>序列很长的时候, 由于文本量不够大, 可能 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>x</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo>≤</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">n(x_1,...x_t)\le 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">...</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span></p>
<p>使用马尔可夫假设缓解, n 元语法假设, 假设只和前 n 个词相关</p>
<p>以二元为例, 则有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>3</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>4</mn></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>n</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo></mrow><mrow><mi>x</mi><mn>1</mn></mrow></mfrac><mfrac><mrow><mi>n</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow><mrow><mi>n</mi><mo stretchy="false">(</mo><mi>x</mi><mn>1</mn><mo stretchy="false">)</mo></mrow></mfrac><mfrac><mrow><mi>n</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>3</mn></msub><mo stretchy="false">)</mo></mrow><mrow><mi>n</mi><mo stretchy="false">(</mo><mi>x</mi><mn>2</mn><mo stretchy="false">)</mo></mrow></mfrac><mfrac><mrow><mi>n</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>3</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>4</mn></msub><mo stretchy="false">)</mo></mrow><mrow><mi>n</mi><mo stretchy="false">(</mo><mi>x</mi><mn>3</mn><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">p(x_1,x_2,x_3,x_4) = \frac{n(x_1)}{x1} \frac{n(x_1,x_2)}{n(x1)} \frac{n(x_2,x_3)}{n(x2)} \frac{n(x_3,x_4)}{n(x3)} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.53em;vertical-align:-0.52em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.485em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.485em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mord mtight">2</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.485em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mord mtight">3</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.485em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="rnn">RNN<a class="hash-link" aria-label="Direct link to RNN" title="Direct link to RNN" href="https://ayanami1314.github.io/blog/AI%20limu#rnn">​</a></h3>
<p>更新隐藏状态: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>t</mi></msub><mo>=</mo><mi>ϕ</mi><mo stretchy="false">(</mo><msub><mi>W</mi><mrow><mi>h</mi><mi>h</mi></mrow></msub><msub><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>W</mi><mrow><mi>h</mi><mi>x</mi></mrow></msub><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>b</mi><mi>h</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">h_t = \phi (W_{hh}h_{t-1} + W_{hx}x_{t-1} + b_h)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">ϕ</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">hh</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8917em;vertical-align:-0.2083em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p>
<p>输出: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>o</mi><mi>t</mi></msub><mo>=</mo><mi>ϕ</mi><mo stretchy="false">(</mo><msub><mi>W</mi><mrow><mi>h</mi><mi>o</mi></mrow></msub><msub><mi>h</mi><mi>t</mi></msub><mo>+</mo><msub><mi>b</mi><mi>o</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">o_t = \phi (W_{ho}h_t + b_o)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">ϕ</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight">o</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">o</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p>
<p>训练的模型: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mrow><mi>h</mi><mi>h</mi></mrow></msub><mo separator="true">,</mo><msub><mi>W</mi><mrow><mi>h</mi><mi>x</mi></mrow></msub><mo separator="true">,</mo><msub><mi>W</mi><mrow><mi>h</mi><mi>o</mi></mrow></msub><mo separator="true">,</mo><msub><mi>b</mi><mi>h</mi></msub><mo separator="true">,</mo><msub><mi>b</mi><mi>o</mi></msub></mrow><annotation encoding="application/x-tex">W_{hh}, W_{hx}, W_{ho}, b_h, b_o</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">hh</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight">o</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">o</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></p>
<p>如果没有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mrow><mi>h</mi><mi>h</mi></mrow></msub><msub><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">W_{hh}h_{t-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9028em;vertical-align:-0.2083em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">hh</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span></span></span></span> 就是 MLP</p>
<p>loss 设计: 困惑度 perplexity</p>
<p>把输出看成是词典大小为 label 数量的话, 可以用交叉熵, 然后对整个句子取平均</p>
<p>但实际不是用这个, 而是用 exp(平均交叉熵)</p>
<p>梯度裁剪: 在 T 个时间步上的梯度, 反向传播 O(T)矩阵乘法, 梯度爆炸</p>
<p>如果梯度长度超过 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.02778em">θ</span></span></span></span>, 变回 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.02778em">θ</span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mo>×</mo><mi>m</mi><mi>i</mi><mi>n</mi><mo stretchy="false">(</mo><mn>1</mn><mo separator="true">,</mo><mfrac><mi>θ</mi><mrow><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi>g</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi></mrow></mfrac><mo stretchy="false">)</mo><mo>→</mo><mi>g</mi></mrow><annotation encoding="application/x-tex">g \times min(1, \frac{\theta}{||g||}) \to g</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">g</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.4001em;vertical-align:-0.52em"></span><span class="mord mathnormal">min</span><span class="mopen">(</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣∣</span><span class="mord mathnormal mtight" style="margin-right:0.03588em">g</span><span class="mord mtight">∣∣</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">g</span></span></span></span></p>
<p>更多的 RNN:</p>
<ul>
<li>1 对多: 文本生成</li>
<li>多对 1: 文本分类</li>
<li>多对多: 问答, 机器翻译</li>
<li>多对多: tag 生成</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="grulstm">GRU&amp;LSTM<a class="hash-link" aria-label="Direct link to GRU&amp;LSTM" title="Direct link to GRU&amp;LSTM" href="https://ayanami1314.github.io/blog/AI%20limu#grulstm">​</a></h3>
<p>对于一个序列, 记住相关观察需要 更新门(能关注的机制) + 重置门(能遗忘的机制)</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mi>t</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mi>t</mi></msub><msub><mi>W</mi><mrow><mi>x</mi><mi>r</mi></mrow></msub><mo>+</mo><msub><mi>H</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><msub><mi>W</mi><mrow><mi>h</mi><mi>r</mi></mrow></msub><mo>+</mo><msub><mi>b</mi><mi>r</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">R_t = \sigma (X_tW_{xr} + H_{t-1}W_{hr} + b_r)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.03588em">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight" style="margin-right:0.02778em">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8917em;vertical-align:-0.2083em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0813em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight" style="margin-right:0.02778em">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> reset gate</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>t</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mi>t</mi></msub><msub><mi>W</mi><mrow><mi>x</mi><mi>z</mi></mrow></msub><mo>+</mo><msub><mi>H</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><msub><mi>W</mi><mrow><mi>h</mi><mi>z</mi></mrow></msub><mo>+</mo><msub><mi>b</mi><mi>z</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Z_t = \sigma (X_tW_{xz} + H_{t-1}W_{hz} + b_z)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.03588em">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight" style="margin-right:0.04398em">z</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8917em;vertical-align:-0.2083em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0813em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight" style="margin-right:0.04398em">z</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.04398em">z</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> update gate</p>
<p>候选隐状态</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>H</mi><mrow><mi>c</mi><mi>a</mi><mi>n</mi><mi>d</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></msub><mo>=</mo><mi>t</mi><mi>a</mi><mi>n</mi><mi>h</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mi>t</mi></msub><msub><mi>W</mi><mrow><mi>x</mi><mi>h</mi></mrow></msub><mo>+</mo><mo stretchy="false">(</mo><msub><mi>R</mi><mi>t</mi></msub><mo>⊙</mo><msub><mi>H</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo><msub><mi>W</mi><mrow><mi>h</mi><mi>h</mi></mrow></msub><mo>+</mo><msub><mi>b</mi><mi>h</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">H_{cand(t)} = tanh(X_tW_{xh} + (R_t \odot H_{t-1})W_{hh}+b_h)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0385em;vertical-align:-0.3552em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.5198em;margin-left:-0.0813em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">an</span><span class="mord mathnormal mtight">d</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">anh</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⊙</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0813em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">hh</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">R_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> : <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[0,1]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1</span><span class="mclose">]</span></span></span></span> 软控制</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>H</mi><mi>t</mi></msub><mo>=</mo><msub><mi>Z</mi><mi>t</mi></msub><mo>⊙</mo><msub><mi>H</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msub><mi>Z</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo>⊙</mo><msub><mi>H</mi><mrow><mi>c</mi><mi>a</mi><mi>n</mi><mi>d</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></msub></mrow><annotation encoding="application/x-tex">H_t = Z_t \odot H_{t-1} + (1 - Z_t) \odot H_{cand(t)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0813em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⊙</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8917em;vertical-align:-0.2083em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0813em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⊙</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.0385em;vertical-align:-0.3552em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.5198em;margin-left:-0.0813em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">an</span><span class="mord mathnormal mtight">d</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em"><span></span></span></span></span></span></span></span></span></span></p>
<p>隐藏层多大? 例如 128,256, 长序列就 1024</p>
<p>实际不考虑 RNN, 一般 GRU/LSTM</p>
<p>超过 100,1000 这样的长度量级, 考虑 Attention</p>
<p>LSTM</p>
<p>忘记门: 将值朝 0 减少</p>
<p>输入门: 决定是不是忽略输入</p>
<p>输出门: 决定是不是使用隐状态</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/01/21/NOBVjdUuAbGaPiI.png" alt="image-20250121223000822" class="img_ev3q"></p>
<p>更深(多个隐藏层)的 RNN, 更多的非线性性</p>
<p>双向 RNN</p>
<p>一个前向 RNN 隐层</p>
<p>一个反向 RNN 隐层</p>
<p>合并两个得到输出</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/01/21/UlEQrGwNOycTKgB.png" alt="image-20250121230923026" class="img_ev3q"></p>
<p>output 是前向和反向的共同贡献</p>
<p>推理怎么推? 非常不适合做推理, 几乎不能推</p>
<p>主要作用: 对句子做特征提取, 填空, 而不是预测未来</p>
<p>输入需要定长(为了以 batch 的形式读入)</p>
<p>如何做不定长的? 填充或者截断, 例如翻译</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="encoder-decoder-架构">encoder-decoder 架构<a class="hash-link" aria-label="Direct link to encoder-decoder 架构" title="Direct link to encoder-decoder 架构" href="https://ayanami1314.github.io/blog/AI%20limu#encoder-decoder-%E6%9E%B6%E6%9E%84">​</a></h3>
<p>encoder: 将输入编程成中间表达形式(特征)</p>
<p>decoder: 将中间表示解码成输出</p>
<p>encoder 将 state 传给解码器做输入</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="seq2seq">seq2seq<a class="hash-link" aria-label="Direct link to seq2seq" title="Direct link to seq2seq" href="https://ayanami1314.github.io/blog/AI%20limu#seq2seq">​</a></h3>
<p>encoder 是一个 RNN, 可以双向</p>
<p>decoder 是另一个 RNN</p>
<p>编码器是没有输出的 RNN</p>
<p>encoder 最后时间步的 hidden state 作为 decoder 的初始 hidden state</p>
<p>训练, 训练时 decoder 用目标句子作为输入</p>
<p>衡量生成序列的好坏: BLEU</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/02/12/TsAcfuqWrhtpiFw.png" alt="image-20250122095953273" class="img_ev3q"></p>
<p>exp 项: 防止 pred 句子长度过短偷懒提高精度</p>
<p>BLEU 越大越好</p>
<p>seq2seq: 从一个句子生成另一个句子</p>
<p>sequence_mask：在序列中屏蔽不相关的项(padding)</p>
<p>拓展 softmax 来屏蔽不相关的预测(padding 对应的 output)</p>
<p>预测</p>
<p>最开始输入 <code>&lt;bos&gt;</code>, 然后 RNN 每次输出作为下一个的输入</p>
<p>seq2seq 可以纯 transformer</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="束搜索">束搜索<a class="hash-link" aria-label="Direct link to 束搜索" title="Direct link to 束搜索" href="https://ayanami1314.github.io/blog/AI%20limu#%E6%9D%9F%E6%90%9C%E7%B4%A2">​</a></h3>
<p>beam search</p>
<p>seq2seq：用当前时刻预测概率最大词输出（贪心）</p>
<p>但贪心很可能不是最优的</p>
<p>暴搜指数级增长肯定不行</p>
<p>bin search: 对每个时刻, 保存最好的 K 个序列</p>
<p>每一次新预测会对 k 的 kn 个可能的下一个序列之中再调最好的 k 个</p>
<p>如何选择 "最好"?</p>
<p>单纯的概率乘总是倾向于选择短句子, 需要给长句子加权</p>
<p>每个候选的最终分数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><msup><mi>L</mi><mi>α</mi></msup></mfrac><mi>l</mi><mi>o</mi><mi>g</mi><mi>p</mi><mo stretchy="false">(</mo><msub><mi>y</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>y</mi><mi>L</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\frac{1}{L^{\alpha}}logp(y_1,...y_L)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">L</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.5935em"><span style="top:-2.786em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.0037em">α</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em">g</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">...</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>, 取 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.75</mn><mo>&lt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\alpha=0.75 &lt; 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6835em;vertical-align:-0.0391em"></span><span class="mord">0.75</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span> 给长句子加权</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="attention">Attention<a class="hash-link" aria-label="Direct link to Attention" title="Direct link to Attention" href="https://ayanami1314.github.io/blog/AI%20limu#attention">​</a></h3>
<p>卷积, 全连接, 池化只考虑“不随意”的线索</p>
<ul>
<li>"最大值", 明显的特征</li>
</ul>
<p>注意力机制显式地考虑随意线索</p>
<ul>
<li>随意线索被称为查询 query</li>
<li>每个输入是一个值 value 和不随意线索 key 的对</li>
<li><strong>通过注意力池化层来对有偏向性的选择某些输入</strong></li>
</ul>
<p>非参(不需要任何先验参数)注意力池化层</p>
<p>给定数据(环境, 先验, context) <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(x_i,y_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p>
<p>查询: 给定一个 x, 求对应的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">y=f(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></p>
<p>注意力: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mo>∑</mo><mi>i</mi></msub><mi>α</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">f(x)=\sum_i \alpha(x,x_i)y_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.0497em;vertical-align:-0.2997em"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.162em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\alpha(x,x_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 就是注意力权重</p>
<p>最简单的方法: 平均池化, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><msub><mo>∑</mo><mi>i</mi></msub><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">f(x)=\frac{1}{n}\sum_i y_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.162em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></p>
<p>更好的方案是 60 年代的 Nadaraya-Watson 核回归</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mo>∑</mo><mi>i</mi></msub><mfrac><mrow><mi>K</mi><mo stretchy="false">(</mo><mi>x</mi><mo>−</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mrow><msub><mo>∑</mo><mi>j</mi></msub><mi>K</mi><mo stretchy="false">(</mo><mi>x</mi><mo>−</mo><msub><mi>x</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow></mfrac><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">f(x)=\sum_{i} \frac{K(x-x_i)}{\sum_j K(x-x_j)}y_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.6772em;vertical-align:-0.6672em"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.162em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1496em"><span style="top:-2.1786em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4603em"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.1952em"></span><span class="mord mathnormal mtight" style="margin-right:0.07153em">K</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.485em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em">K</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6672em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></p>
<p>高斯核 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><msqrt><mrow><mn>2</mn><mi>π</mi></mrow></msqrt></mfrac><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy="false">(</mo><mo>−</mo><mfrac><msup><mi>u</mi><mn>2</mn></msup><mn>2</mn></mfrac><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">K(u)=\frac{1}{\sqrt{2\pi}}exp(-\frac{u^2}{2})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.07153em">K</span><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.5559em;vertical-align:-0.538em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.551em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9128em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mtight" style="padding-left:0.833em"><span class="mord mtight">2</span><span class="mord mathnormal mtight" style="margin-right:0.03588em">π</span></span></span><span style="top:-2.8728em"><span class="pstrut" style="height:3em"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.08em"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1272em"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.538em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0179em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em"><span style="top:-2.931em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mo>∑</mo><mi>i</mi></msub><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mo>−</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">(</mo><mi>x</mi><mo>−</mo><msub><mi>x</mi><mi>i</mi></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo stretchy="false">)</mo><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">f(x)= \sum_{i} softmax(-\frac{1}{2}(x-x_i)^2)y_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.162em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">so</span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></p>
<p>参数化:</p>
<p>再引入可以学习的 w</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mo>∑</mo><mi>i</mi></msub><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mo>−</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">(</mo><mo stretchy="false">(</mo><mi>x</mi><mo>−</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mi>w</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo stretchy="false">)</mo><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">f(x)= \sum_{i} softmax(-\frac{1}{2}((x-x_i)w)^2)y_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.162em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">so</span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mopen">((</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></p>
<p>相较非参的注意力, 变得更不平滑</p>
<p>拓展到高维度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo stretchy="false">(</mo><mi>q</mi><mo separator="true">,</mo><msub><mi>k</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\alpha(q, k_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0315em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p>
<ol>
<li>Additive Attention: 可学参数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>k</mi></msub><mo>∈</mo><msup><mi>R</mi><mrow><mi>h</mi><mo>×</mo><mi>k</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W_k \in R^{h\times k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8491em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>q</mi></msub><mo>∈</mo><msup><mi>R</mi><mrow><mi>h</mi><mo>×</mo><mi>q</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W_q \in R^{h\times q}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8491em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right:0.03588em">q</span></span></span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi><mo>∈</mo><msup><mi>R</mi><mi>h</mi></msup></mrow><annotation encoding="application/x-tex">v \in R^{h}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em"></span><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8491em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span></span></span></span></span></span></span></span></span></span></span></span></li>
</ol>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo stretchy="false">(</mo><mi>k</mi><mo separator="true">,</mo><mi>q</mi><mo stretchy="false">)</mo><mo>=</mo><msup><mi>v</mi><mi>T</mi></msup><mi>t</mi><mi>a</mi><mi>n</mi><mi>h</mi><mo stretchy="false">(</mo><msub><mi>W</mi><mi>k</mi></msub><mi>k</mi><mo>+</mo><msub><mi>W</mi><mi>q</mi></msub><mi>q</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">a(k,q) = v^{T}tanh(W_kk + W_qq)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">a</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.0913em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span><span class="mord mathnormal">t</span><span class="mord mathnormal">anh</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="mclose">)</span></span></span></span></p>
<p>等价于将 kv 合并之后放入一个隐藏大小为 h, 输出大小为 1 的单隐藏层 MLP</p>
<p>也是当 q, k 不一样长的时候最常用的做法</p>
<p>如果 q, k 都是同样长度的</p>
<p>2.Scaled Dot-Product Attention</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo stretchy="false">(</mo><mi>q</mi><mo separator="true">,</mo><msub><mi>k</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mo>&lt;</mo><mi>q</mi><mo separator="true">,</mo><msub><mi>k</mi><mi>i</mi></msub><mo>&gt;</mo><mi mathvariant="normal">/</mi><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mrow><annotation encoding="application/x-tex">a(q,k_i)=&lt;q,k_i&gt;/\sqrt{d_k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">a</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0315em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=&lt;</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0315em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.1072em;vertical-align:-0.25em"></span><span class="mord">/</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8572em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord" style="padding-left:0.833em"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span><span style="top:-2.8172em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1828em"><span></span></span></span></span></span></span></span></span>, 相当于 q 在 k 基上的分量+归一化</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo stretchy="false">)</mo><mo>=</mo><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup><mi mathvariant="normal">/</mi><msqrt><mi>d</mi></msqrt></mrow><annotation encoding="application/x-tex">a(Q,K)=QK^{T}/\sqrt{d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">a</span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.07153em">K</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.1822em;vertical-align:-0.25em"></span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span><span class="mord">/</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9322em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord" style="padding-left:0.833em"><span class="mord mathnormal">d</span></span></span><span style="top:-2.8922em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1078em"><span></span></span></span></span></span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo>=</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mi>V</mi></mrow><annotation encoding="application/x-tex">f=softmax(a(Q,K))V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">so</span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.07153em">K</span><span class="mclose">))</span><span class="mord mathnormal" style="margin-right:0.22222em">V</span></span></span></span></p>
<p>Q, K, V 是一个矩阵？self-attention 自注意力 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo>=</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mi>X</mi><msup><mi>X</mi><mi>T</mi></msup><mi mathvariant="normal">/</mi><msqrt><mi>d</mi></msqrt><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mi>X</mi></mrow><annotation encoding="application/x-tex">f=softmax(XX^{T}/\sqrt d))X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.1822em;vertical-align:-0.25em"></span><span class="mord mathnormal">so</span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span><span class="mord">/</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9322em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="padding-left:0.833em">d</span></span><span style="top:-2.8922em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1078em"><span></span></span></span></span></span><span class="mclose">))</span><span class="mord mathnormal" style="margin-right:0.07847em">X</span></span></span></span></p>
<p>但实际运用会给 X 做不同线性线性变换后再输入</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo>=</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mi>X</mi><msub><mi>W</mi><mi>Q</mi></msub><msup><mi>X</mi><mi>T</mi></msup><msub><mi>W</mi><mi>K</mi></msub><mi mathvariant="normal">/</mi><msqrt><mi>d</mi></msqrt><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mi>X</mi><msub><mi>W</mi><mi>V</mi></msub></mrow><annotation encoding="application/x-tex">f=softmax(XW_QX^{T}W_K/\sqrt d))XW_V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.2183em;vertical-align:-0.2861em"></span><span class="mord mathnormal">so</span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord">/</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9322em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="padding-left:0.833em">d</span></span><span style="top:-2.8922em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1078em"><span></span></span></span></span></span><span class="mclose">))</span><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em">V</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="attention-机制的-seq2seq">Attention 机制的 seq2seq<a class="hash-link" aria-label="Direct link to Attention 机制的 seq2seq" title="Direct link to Attention 机制的 seq2seq" href="https://ayanami1314.github.io/blog/AI%20limu#attention-%E6%9C%BA%E5%88%B6%E7%9A%84-seq2seq">​</a></h3>
<p>翻译的词可能相关于原始句子之中不同的值</p>
<p>原始 seq2seq 只能看到单一词的输入, 虽然有隐藏层, 但长距离丢失信息</p>
<ul>
<li>
<p>encoder 的对每个词的输出作为 key 和 value（key = value）</p>
</li>
<li>
<p>decoder RNN 对上一个词的输出是 query</p>
</li>
<li>
<p>attention 的输出和下一个词的 embedding 合并进入 decoder</p>
</li>
</ul>
<p>原始的 seq2seq 相当于是只将上一个词的 state+t-1 时刻的 encoder 输出丢到了 decoder 里面</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mi>e</mi><mi>c</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>r</mi><mo stretchy="false">(</mo><mi>s</mi><mi>t</mi><mi>a</mi><mi>t</mi><msub><mi>e</mi><mi>t</mi></msub><mo separator="true">,</mo><mi>e</mi><mi>o</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><msub><mi>t</mi><mi>t</mi></msub><mo separator="true">,</mo><mi>o</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><msub><mi>t</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">decoder(state_{t}, eoutput_{t}, output_{t-1})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">eco</span><span class="mord mathnormal">d</span><span class="mord mathnormal" style="margin-right:0.02778em">er</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">eo</span><span class="mord mathnormal">u</span><span class="mord mathnormal">tp</span><span class="mord mathnormal">u</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">tp</span><span class="mord mathnormal">u</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p>
<p>现在拓展其表达力, 认为 decoder 应该获取的不是单单最后一个词的输出, 而是和之前的词输出(更长的上下文)都有点关系, 具体关系用 attention 学习, 以编码器的 output 作为 query key, 获取这个 output 最相关的上下文, 并认为翻译的文本之中也应该有类似的上下文关系</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mi>e</mi><mi>c</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>r</mi><mo stretchy="false">(</mo><mi>s</mi><mi>t</mi><mi>a</mi><mi>t</mi><msub><mi>e</mi><mi>t</mi></msub><mo separator="true">,</mo><mi>a</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false">(</mo><mi>o</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><msub><mi>t</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><mi>e</mi><mi>o</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi><mi>s</mi><mo separator="true">,</mo><mi>e</mi><mi>o</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi><mi>s</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">decoder(state_t, attention(output_{t-1}, eoutputs, eoutputs))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">eco</span><span class="mord mathnormal">d</span><span class="mord mathnormal" style="margin-right:0.02778em">er</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">a</span><span class="mord mathnormal">tt</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">tp</span><span class="mord mathnormal">u</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">eo</span><span class="mord mathnormal">u</span><span class="mord mathnormal">tp</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">eo</span><span class="mord mathnormal">u</span><span class="mord mathnormal">tp</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mord mathnormal">s</span><span class="mclose">))</span></span></span></span></p>
<p>tokenizer: sentencepiece</p>
<p>embedding: 专业词, 需要调整 tokenizer, 需要添加词 pair, 需要训练新添加的 embedding, 正常领域 frozen 不动, 加 LoRA/Adapter</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="自注意力">自注意力<a class="hash-link" aria-label="Direct link to 自注意力" title="Direct link to 自注意力" href="https://ayanami1314.github.io/blog/AI%20limu#%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B">​</a></h3>
<p>self-attention</p>
<p>序列长度是 n, 卷积核大小 k</p>
<table><thead><tr><th></th><th>CNN</th><th>RNN</th><th>self-attention</th></tr></thead><tbody><tr><td>计算复杂度</td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>k</mi><mi>n</mi><msup><mi>d</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(knd^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.02778em">O</span><span class="mopen">(</span><span class="mord mathnormal">kn</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><msup><mi>d</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(nd^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.02778em">O</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mi>d</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n^2d)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.02778em">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span></span></td></tr><tr><td>并行度</td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.02778em">O</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span></td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.02778em">O</span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span></span></span></span></td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.02778em">O</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span></td></tr><tr><td>最长路径</td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mi mathvariant="normal">/</mi><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n/k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.02778em">O</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mclose">)</span></span></span></span></td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.02778em">O</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span></td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.02778em">O</span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span></span></span></span></td></tr></tbody></table>
<p>自注意力适合处理长文本</p>
<p>代价: 计算代价 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>n</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">n^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> 增长</p>
<p>位置编码:</p>
<p>和 CNN, RNN 不同, 自注意力没有记录位置的信息, 位置编码将位置信息注入到输入里</p>
<ul>
<li>输入 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>∈</mo><msup><mi>R</mi><mrow><mi>n</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding="application/x-tex">X\in R^{n\times d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em"></span><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8491em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span>, 叠加位置编码 P, X+P 作为自编码输入</li>
</ul>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mrow><mi>i</mi><mo separator="true">,</mo><mn>2</mn><mi>j</mi></mrow></msub><mo>=</mo><mi>s</mi><mi>i</mi><mi>n</mi><mo stretchy="false">(</mo><mfrac><mi>i</mi><mrow><mn>1000</mn><msup><mn>0</mn><mrow><mn>2</mn><mi>j</mi><mi mathvariant="normal">/</mi><mi>d</mi></mrow></msup></mrow></mfrac><mo stretchy="false">)</mo><mo separator="true">,</mo><msub><mi>p</mi><mrow><mi>i</mi><mo separator="true">,</mo><mn>2</mn><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>c</mi><mi>o</mi><mi>s</mi><mo stretchy="false">(</mo><mfrac><mi>i</mi><mrow><mn>1000</mn><msup><mn>0</mn><mrow><mn>2</mn><mi>j</mi><mi mathvariant="normal">/</mi><mi>d</mi></mrow></msup></mrow></mfrac><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p_{i,2j}=sin(\frac{i}{10000^{2j/d}}),p_{i,2j+1}=cos(\frac{i}{10000^{2j/d}})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.2411em;vertical-align:-0.3854em"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">in</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8557em"><span style="top:-2.6146em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1000</span><span class="mord mtight"><span class="mord mtight">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.822em"><span style="top:-2.822em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span><span class="mord mtight">/</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3854em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.2411em;vertical-align:-0.3854em"></span><span class="mord mathnormal">cos</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8557em"><span style="top:-2.6146em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1000</span><span class="mord mtight"><span class="mord mtight">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.822em"><span style="top:-2.822em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span><span class="mord mtight">/</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3854em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span></p>
<p>为什么这么设计</p>
<p>记 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ω</mi><mi>j</mi></msub><mo>=</mo><mn>1</mn><mi mathvariant="normal">/</mi><mn>1000</mn><msup><mn>0</mn><mrow><mn>2</mn><mi>j</mi><mi mathvariant="normal">/</mi><mi>d</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\omega_j = 1/10000^{2j/d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.138em;vertical-align:-0.25em"></span><span class="mord">1/1000</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span><span class="mord mtight">/</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mrow><mi>i</mi><mo>+</mo><mi>δ</mi></mrow></msub><mo>=</mo><mi>R</mi><mi>o</mi><mi>t</mi><mi>a</mi><mi>t</mi><mi>e</mi><mi>M</mi><mi>a</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>x</mi><mo stretchy="false">(</mo><mi>δ</mi><msub><mi>ω</mi><mi>j</mi></msub><mo stretchy="false">)</mo><mo>×</mo><msub><mi>p</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>δ</mi></mrow></msub></mrow><annotation encoding="application/x-tex">p_{i+\delta} = RotateMatrix(\delta \omega_j) \times p_{i,\delta}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.2083em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.03785em">δ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em"></span><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="mord mathnormal">o</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.10903em">M</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03785em">δ</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03785em">δ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></p>
<p>所以实际上是相对位置的编码</p>
<p>也就是对于同一个序列 j, 位置 i 有 <code>&lt;i, i+k&gt;</code> 的关系的 pair 始终是一个相同的关系</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="transformer">Transformer<a class="hash-link" aria-label="Direct link to Transformer" title="Direct link to Transformer" href="https://ayanami1314.github.io/blog/AI%20limu#transformer">​</a></h3>
<p>纯基于(self-)attention</p>
<p>encoder-decoder 架构</p>
<p>multi-head attention</p>
<p>对同一的 QKV, 希望抽取不同的信息</p>
<p>使用 h 个独特的注意力池化</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/01/22/u1Y2HMZhOi3z7eT.png" alt="image-20250122150747190" class="img_ev3q"></p>
<p>attention 没有时序信息, encoder 无所谓</p>
<p>decoder 不应该看到不该看到的信息, 需要加入掩码</p>
<p>计算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> 输出时, 假装当前序列长度为 i</p>
<p>基于位置的前馈网络 Positionwise FFN</p>
<p>将输入形状 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>b</mi><mo separator="true">,</mo><mi>n</mi><mo separator="true">,</mo><mi>d</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(b, n, d)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord mathnormal">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">n</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span></span> 变换成 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>b</mi><mi>n</mi><mo separator="true">,</mo><mi>d</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(bn, d)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord mathnormal">bn</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span></span>, 输出再换回来</p>
<p>两层全连接, 添加非线性, 做更多的特征融合</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mi>F</mi><mi>N</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><msubsup><mi>W</mi><mn>1</mn><mi>T</mi></msubsup><mo stretchy="false">)</mo><msub><mi>W</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">FFN(x)=f(xW^{T}_{1})W_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.10903em">FFN</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.0913em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-2.4519em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2481em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></p>
<p>Add&amp;Norm: 残差+归一化</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/01/22/MI26dfrL1vuJe4c.png" alt="image-20250122152949678" class="img_ev3q"></p>
<p>编码器的输出 y_1, ... y_n</p>
<p>作为解码器之中第 i 个 transformer 块之中多头注意力的 key 和 value</p>
<p>预测, t+1 输出</p>
<p>decoder 输入前 t 个预测值作为 key, value, 第 t 个预测还作为 query</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="bert">Bert<a class="hash-link" aria-label="Direct link to Bert" title="Direct link to Bert" href="https://ayanami1314.github.io/blog/AI%20limu#bert">​</a></h3>
<p>nlp 的迁移学习</p>
<p>使用 pretrain 的模型抽取词句的特征</p>
<p>不更新 pretrain 模型</p>
<p>问题: 1. 做 embedding 的话忽略了时序信息 2.后续模型还要自己设计, 只有 embedding 似乎没有很大用处</p>
<p>Bert: 能不能也通过改最后一层复用?</p>
<p>只有编码器的 transformer</p>
<p>对输入的修改:</p>
<ul>
<li>
<p>每个样本都是一个句子对</p>
</li>
<li>
<p>加入额外的片段嵌入</p>
</li>
<li>
<p>位置编码可学习</p>
</li>
</ul>
<p>三种 embedding: position, segment, token</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/01/22/YZ7fXDl4LiQ2BNp.png" alt="image-20250122155938538" class="img_ev3q"></p>
<p>通用的任务?</p>
<p>任务 1: 带掩码的语言模型</p>
<p>带掩码的语言模型每次随机(15%概率)将一些词元换成 <code>&lt;mask&gt;</code></p>
<p>微调任务之中不出现 <code>&lt;mask&gt;</code></p>
<blockquote>
<p>微调任务是没有 <code>&lt;mask&gt;</code> 标记的，如果设计方案是：只要 token 被选中 mask 处理，并且处理方法只要一种就是 token 别替换为 <code>&lt;mask&gt;</code>，这样的话，预训练任务和微调任务的数据太不一样了。BERT 的 3 种 mask 方法，可以使得，有 20%情况，句子对没有 <code>&lt;mask&gt;</code> 标记。</p>
</blockquote>
<blockquote>
<p>我理解的说白了就是不仅仅是因为看到了 <code>&lt;mask&gt;</code> 才去找上下文的信息，而是一直保持联系上下文的“习惯”</p>
</blockquote>
<ul>
<li>80%下, 变成 <code>&lt;mask&gt;</code></li>
<li>10%, 随机(错误的结果)</li>
<li>10%, 原有(正确的结果)</li>
</ul>
<blockquote>
<p>10%的词会被替换成随机词元的原因： 作者在论文中谈到了采取上面的 mask 策略的好处。大致是说采用上面的策略后，Transformer encoder 就不知道会让其预测哪个单词，或者说不知道哪个单词会被随机单词给替换掉，那么它就不得不保持每个输入 token 的一个上下文的表征分布(a distributional contextual representation)。也就是说如果模型学习到了要预测的单词是什么，那么就会丢失对上下文信息的学习，而如果模型训练过程中无法学习到哪个单词会被预测，那么就必须通过学习上下文的信息来判断出需要预测的单词，这样的模型才具有对句子的特征表示能力。另外，由于随机替换相对句子中所有 tokens 的发生概率只有 1.5%(即 15%的 10%)，所以并不会影响到模型的语言理解能力。（网上复制的，这是我找到的可以说服我自己的一个解释）</p>
</blockquote>
<p>任务 2: 下一句子预测:</p>
<p>训练样本之中, 50%选择相邻句子对, 50%选择随机句子对</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="微调-bert">微调 Bert<a class="hash-link" aria-label="Direct link to 微调 Bert" title="Direct link to 微调 Bert" href="https://ayanami1314.github.io/blog/AI%20limu#%E5%BE%AE%E8%B0%83-bert">​</a></h3>
<p>bert 对每一个次元返回抽取了上下文信息的特征向量</p>
<p>不同的任务取不同的特征</p>
<ul>
<li>句子分类, 将 <code>&lt;cls&gt;</code> 对应的向量输入到 MLP 分类</li>
<li>命名实体识别, 识别一个词元是不是命名实体, 例如人名机构位置<!-- -->
<ul>
<li>把每一个非特殊词元(不是 <code>&lt;cls&gt;&lt;sep&gt;...</code>)放进 MLP 分类</li>
</ul>
</li>
<li>问题回答: 给定一个问题和描述文字, 找一个片段作为回答<!-- -->
<ul>
<li>对片段的每一个词元预测是不是回答的开头或者结束</li>
</ul>
</li>
</ul>
<p>实用机器学习</p>
<p>不讲模型, 讲数据</p>
<p>知识积累, 学会读论文, 经典论文需要读懂每一句话</p>
<p>结合代码了解细节</p>
<p>对读过的论文做整理</p>]]></content:encoded>
            <category>ai</category>
            <category>dl</category>
        </item>
        <item>
            <title><![CDATA[paper-reading, code&rl方向]]></title>
            <link>https://ayanami1314.github.io/blog/llm for code paper notes</link>
            <guid>https://ayanami1314.github.io/blog/llm for code paper notes</guid>
            <pubDate>Mon, 01 Sep 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[Effi-code Enhancing Code Generation in Large Language Models through Efficiency-Aware Fine-tuning]]></description>
            <content:encoded><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="effi-code-unleashing-code-efficiency-in-language-modelsswiftcoder-enhancing-code-generation-in-large-language-models-through-efficiency-aware-fine-tuning">Effi-code: Unleashing code efficiency in language modelsSWIFTCODER: Enhancing Code Generation in Large Language Models through Efficiency-Aware Fine-tuning<a class="hash-link" aria-label="Direct link to Effi-code: Unleashing code efficiency in language modelsSWIFTCODER: Enhancing Code Generation in Large Language Models through Efficiency-Aware Fine-tuning" title="Direct link to Effi-code: Unleashing code efficiency in language modelsSWIFTCODER: Enhancing Code Generation in Large Language Models through Efficiency-Aware Fine-tuning" href="https://ayanami1314.github.io/blog/llm%20for%20code%20paper%20notes#effi-code-unleashing-code-efficiency-in-language-modelsswiftcoder-enhancing-code-generation-in-large-language-models-through-efficiency-aware-fine-tuning">​</a></h2>
<p>问题：以前的方法主要关注正确性忽略效率(effibench，gpt4 代码执行时间是标准解决方案的1.69与45.49倍(avg, worst))</p>
<p>衡量效率：本地测量执行时间和内存</p>
<p>具体来说是三个指标：</p>
<ul>
<li>执行时间ET</li>
<li>最大内存使用量MU</li>
<li>总内存使用量TMU</li>
</ul>
<p>这篇论文并没有用RL的方法去激发LLM生成更高效率代码的能力，而是”优化“训练数据集的代码效率，并证明了训练集代码效率高也会让LLM生成更高效率的代码（ET 的相关性为 0.972，MU 的相关性为 0.950，TMU 的相关性为 0.986）</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/8ODW2a1x7r9bFUC.png" alt="Refer to caption" class="img_ev3q"></p>
<p>效果：<code>qwen2.5-coder-7b-instruct pass@1 44.8 -&gt; 57.7</code>，正确任务的执行时间减少48.4%</p>
<p>方法：构建代码生成数据集，进行微调</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/ecP8JdFNAkaCwVr.png" alt="Refer to caption" class="img_ev3q"></p>
<p>具体来说，先拉下来开源数据集，过滤一遍后，直接让更强的LLM生成更好的解决方案，然后本地跑一遍得到效率</p>
<p>不同效率的代码示例 <img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/njUJ3lsdbSM2v9e.png" alt="Refer to caption" class="img_ev3q"></p>
<p>文章认为的效果提升来源：</p>
<ol>
<li>多语言数据集</li>
<li>数据准备阶段过滤充分</li>
<li>数据量（有超过 70,000 个训练示例，比先前的mercury 1.8k要大很多）</li>
</ol>
<p>简评：大体上感觉是工作量密集型的工作，比如finetune多个llm和在多个数据集上进行相关评测，但方法上并没有创新之感，洗的数据是高效率代码的自然输出的结果效率也会变高，并不令人感觉新奇，只是讲好了我们需要同时看重代码质量（这里是效率）这一指标的故事</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="effibench-benchmarking-the-efficiency-of-automatically-generated-code">EffiBench: Benchmarking the Efficiency of Automatically Generated Code<a class="hash-link" aria-label="Direct link to EffiBench: Benchmarking the Efficiency of Automatically Generated Code" title="Direct link to EffiBench: Benchmarking the Efficiency of Automatically Generated Code" href="https://ayanami1314.github.io/blog/llm%20for%20code%20paper%20notes#effibench-benchmarking-the-efficiency-of-automatically-generated-code">​</a></h2>
<p>问题：现在衡量代码正确性的文章已经有很多了，但是兼顾正确和效率的相对少</p>
<p>如果要考虑效率的话，一个问题是原先的代码数据集的任务太简单了，很难区分效率；同时很多任务也不是效率密集型的，并且效率相关的测试也不够</p>
<p>数据集构建：leetcode</p>
<p>“标准解决方案”: stackoverflow最多star/leetcode top answer</p>
<p>测试用例：LLM生成</p>
<p>简评：典型的benchmark工作</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="diversity-aware-policy-optimization-for-large-language-model-reasoning">Diversity-Aware Policy Optimization for Large Language Model Reasoning<a class="hash-link" aria-label="Direct link to Diversity-Aware Policy Optimization for Large Language Model Reasoning" title="Direct link to Diversity-Aware Policy Optimization for Large Language Model Reasoning" href="https://ayanami1314.github.io/blog/llm%20for%20code%20paper%20notes#diversity-aware-policy-optimization-for-large-language-model-reasoning">​</a></h2>
<p>问题：diversity在reasoning能力中扮演重要角色，但缺乏定量的研究</p>
<p>动机：传统RL认为，多样性有助于策略探索（例如，SAC等算法），帮助跳出局部最优、加速训练收敛，但对于LLM呢？</p>
<p>方法：</p>
<p>直接增加熵，长度bias, 较长的响应 <code>-&gt;</code> 引入token level diversity</p>
<p>tradeoff 质量和多样性 <code>-&gt;</code> 仅对正样本用多样性增强，确保以性能标准为主导</p>
<p>贡献：</p>
<ul>
<li>多样性的Potential@k指标和LLM reasoning存在正相关关系</li>
<li>token-level diversity objective, selectively applied to positive samples</li>
</ul>
<p>奖励：和R1一致，acc reward和format reward，前者和ground truth 比较，后者让答案以 <code>\boxed{}</code>格式呈现</p>
<p>多样性度量：response中不同方程的比例</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi><mi>i</mi><mi>v</mi><mi>E</mi><mi>q</mi><mi>u</mi><mo>:</mo><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><msub><mo>∑</mo><mi>k</mi></msub><mfrac><mi>U</mi><mi>A</mi></mfrac></mrow><annotation encoding="application/x-tex">DivEqu :=  \frac{1}{N} \sum_k \frac{U}{A}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="mord mathnormal" style="margin-right:0.03588em">Eq</span><span class="mord mathnormal">u</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">:=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.2173em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1864em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">A</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">U</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<p>其中，U是k个采样中的独立方程数量，A是总方程数量</p>
<p>Potential@k： 衡量模型在第一次失败后，在k次（k=16 in paper）内纠正答案的能力</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mi>o</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>a</mi><mi>l</mi><mi mathvariant="normal">@</mi><mi>k</mi><mo>:</mo><mo>=</mo><mfrac><mrow><mo>∑</mo><mi>P</mi><mi>a</mi><mi>s</mi><mi>s</mi><mi mathvariant="normal">@</mi><mi>k</mi><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>P</mi><mi>a</mi><mi>s</mi><mi>s</mi><mi mathvariant="normal">@</mi><mn>1</mn><mo stretchy="false">)</mo></mrow><mrow><mo>∑</mo><mn>1</mn><mo>−</mo><mi>P</mi><mi>a</mi><mi>s</mi><mi>s</mi><mi mathvariant="normal">@</mi><mn>1</mn></mrow></mfrac></mrow><annotation encoding="application/x-tex">Potential@k := \frac{\sum Pass@k (1 - Pass@1)}{ \sum 1 - Pass@1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mord mathnormal">o</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ia</span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord">@</span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">:=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.53em;vertical-align:-0.52em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:0em">∑</span><span class="mspace mtight" style="margin-right:0.1952em"></span><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.13889em">P</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">ss</span><span class="mord mtight">@1</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.485em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:0em">∑</span><span class="mspace mtight" style="margin-right:0.1952em"></span><span class="mord mathnormal mtight" style="margin-right:0.13889em">P</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">ss</span><span class="mord mtight">@</span><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.13889em">P</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">ss</span><span class="mord mtight">@1</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<p>（为啥定义这样一个指标？这个分子分母分别求和挺怪异的，也不是类似条件概率的算法）</p>
<p>结果：对于推理能力有限的LLM(<code>Pass@1&lt;0.4</code>) 多样性和Potential@k没什么关系，但对于更好的LLM，就有明显的正相关关系</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/KN2ZTl3WHbAfotv.png" alt="Refer to caption" class="img_ev3q"></p>
<p>定义的token-level熵</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/9zOCUMnTHIdcsA5.png" alt="image-20250817161107663" class="img_ev3q"></p>
<p>在实测中，作者发现直接把这个熵带入训练会增强错误样本的多样性，相当于对错误样本做增强，因此打了只对正样本做的补丁</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/EiW5Io6xJjOgLyp.png" alt="image-20250817161240377" class="img_ev3q"></p>
<p>而对这个式子求导能直观感受到多样性的部分</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/B4GSM6VPi3c2Cml.png" alt="image-20250817161427155" class="img_ev3q"></p>
<p>对于大多数token, 采样概率<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.03588em">π</span></span></span></span>的值都是小于<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>e</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">e^{-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span>的，则前一个乘项小于0 ，熵的梯度和采样概率的梯度成正相关，熵增有利于对稀有Token的采样</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/tuR3Ey7BxJ4sFfi.png" alt="image-20250817161718666" class="img_ev3q"></p>
<p>实际取 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi><mo>=</mo><mn>0.01</mn></mrow><annotation encoding="application/x-tex">\lambda=0.01</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.01</span></span></span></span></p>
<p>简评：</p>
<p>动机非常清晰，实验也比较充分，展示了虽然是 well-known 的需要基模能力达标多样性才有意义的结论。</p>
<p>对于LLM优化目标的改造的说明是合理的。理论说法是GRPO带来的更新依赖于组内样本的差异，（因为是用std/mean来计算优势函数A），所以增强多样性能避免优势消失带来的一些问题，本质上是在避免 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>r</mi><mo>−</mo><mi>m</mi><mi>e</mi><mi>a</mi><mi>n</mi></mrow><mrow><mi>s</mi><mi>t</mi><mi>d</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{r - mean}{std}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1473em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8023em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">d</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">r</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">an</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> 里面的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>t</mi><mi>d</mi></mrow><annotation encoding="application/x-tex">std</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">d</span></span></span></span> 过小导致不稳定的问题</p>
<p>只对正样本应用多样性损失的trick也是有意义的。</p>
<p>但衡量多样性的时候比较草率，首先是局限在数学范围，其次感觉 <code>方程多样性 != 解法多样性</code>，所以多样性指标总感觉欠说服力。</p>
<p>他们自己也在文章中说："许多现实世界的应用需要用户意图的多样性（例如，需要数学问题的代数和算术解，或者生成具有不同算法方法的代码）, 这样的多样性不等于token level的多样性"</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="beyond-the-8020-rule-high-entropy-minority-tokens-drive-effective-reinforcement-learning-for-llm-reasoning">Beyond the 80/20 Rule: High-Entropy Minority Tokens Drive Effective Reinforcement Learning for LLM Reasoning<a class="hash-link" aria-label="Direct link to Beyond the 80/20 Rule: High-Entropy Minority Tokens Drive Effective Reinforcement Learning for LLM Reasoning" title="Direct link to Beyond the 80/20 Rule: High-Entropy Minority Tokens Drive Effective Reinforcement Learning for LLM Reasoning" href="https://ayanami1314.github.io/blog/llm%20for%20code%20paper%20notes#beyond-the-8020-rule-high-entropy-minority-tokens-drive-effective-reinforcement-learning-for-llm-reasoning">​</a></h2>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/EXbKjUpG9tBPO4R.png" alt="Refer to caption" class="img_ev3q"></p>
<p>问题： 现有RL for LLM算法对不同的token一视同仁，没有考虑token自身的异构性</p>
<p>观察： 低熵token主要决定语言结构，高熵token则作为关键的决策点。手动调整forking token的熵，适度增加这些token的熵可以显著提升推理性能，降低熵会导致性能下降。</p>
<p>仅保留20% token的策略梯度更新，剩下的mask掉，性能上能和全量媲美甚至超越，在RL过程中，只有一小部分高熵 token 对探索有实际贡献，而其他 token 则可能中性甚至有害</p>
<p>20%是实验得到的最优比例</p>
<p>另一个发现是32B的性能提升大于14B大于8B</p>
<p>熵定义：</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/dvBLzo681VuCRsa.png" alt="image-20250817165117549" class="img_ev3q"></p>
<p>一个很直观的分布图，高熵Token基本是重要的转折词，而低熵token是一些前后缀等</p>
<p><img decoding="async" loading="lazy" src="https://ar5iv.labs.arxiv.org/html/2506.01939/assets/x2.png" alt="Refer to caption" class="img_ev3q"></p>
<p>另一个稍微不直观的图</p>
<p>可以得到的结论是高熵token配合高温度能够得到好性能，而低熵token在不同温度下都不太影响最终效果</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/xJQaW8wsCp6OT2H.png" alt="Refer to caption" class="img_ev3q"></p>
<p>作者还发现，RLVR的过程基本就是这些高熵token的熵改变的过程，低熵Token的熵相对稳定，初始熵较高的 token 在 RLVR 后往往会经历更大的熵增。</p>
<p>而只对高熵Token进行RLVR能得到更好的效果</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/QsO7VlpMdqhmPKb.png" alt="Refer to caption" class="img_ev3q"></p>
<p>甚至作者在OOD数据（代码数据）上进行评测，发现高熵的token选择后，泛化性也更好</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/8JzUWnoklK5xdS1.png" alt="Refer to caption" class="img_ev3q"></p>
<p>讨论：</p>
<ol>
<li>RL倾向于保持高熵令牌的熵，而SFT倾向于将输出推向one-hot，降低熵，作者表示这可能是RL更能泛化而SFT容易记忆、难以泛化的原因</li>
<li>传统RL假设一整条轨迹上的熵是接近均匀分布的，这对LLM不成立</li>
<li>LLM RL中，之前常用的熵损失鼓励探索可能未必适用，因为可以是低熵token的熵增也可能是高熵token的，而DAPO的clip higher能筛选出高熵token，即重要性比率ratio（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi><mi mathvariant="normal">/</mi><msub><mi>π</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\pi/\pi_{old}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="mord">/</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.01968em">l</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>）更高的token通常对应高熵token，这呼应了前文中，RLVF对高熵token的熵值有较大改变</li>
</ol>
<p>简评：开始的手动把熵调高感觉等价于把奖励调高等价于数据增强，作为一种RL trick细想并不惊奇，是稀有样本情况下的常用技术</p>
<p>从这个角度继续往下想，如何理解这个多数token对训练甚至有害呢，感觉也是能合上现有对LLM RL的state定义不太合理，或者说探索空间太大，采样样本太少，不可能得到正确的Q函数，导致对于一些本来就很无所谓的token，更新的方向也是比较盲目</p>
<p>总之，这篇文章实验非常充足，分析也比较到位，效果也十分亮眼，确实是在当前的SOTA上往前推进的好文章</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="passk-training-for-adaptively-balancing-exploration-and-exploitation-of-large-reasoning-models">Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models<a class="hash-link" aria-label="Direct link to Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models" title="Direct link to Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models" href="https://ayanami1314.github.io/blog/llm%20for%20code%20paper%20notes#passk-training-for-adaptively-balancing-exploration-and-exploitation-of-large-reasoning-models">​</a></h2>
<p>问题：RLVR 通常采用 Pass@1作为奖励，但容易收敛到局部最优；Pass@k则常用于验证，本文用Pass@k直接作为训练，并设计了对应的优势函数，发现效果比Pass@1更好（更高的Pass@k分数，保持的Pass@1分数）</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/U3Ay7amXxpnqcub.png" alt="Refer to caption" class="img_ev3q"></p>
<p>Pass@1 收敛到局部最优的问题在于正向奖励的探索可能路径太长，模型会倾向于利用而不是探索</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/i85Q2WRxPvmazh9.png" alt="Refer to caption" class="img_ev3q"></p>
<p>方法：</p>
<ul>
<li>
<p>Full Sampling: 每组采样的k个rollout计算奖励，之后整组的奖励由每个rollout的<strong>最大值</strong>给出<img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/asnfy7dcjm4UeK3.jpg" alt="Refer to caption" class="img_ev3q"></p>
</li>
<li>
<p>Bootstrap Sampling: Full Sampling虽然提高了性能，但计算量太大。为了减少推理次数，同时保持组数不变，采用bootstrap采样，先生成一个候选池，再从这个池子里面抽取k个答案，就形成了一组（这样允许某个答案被分到多个组里面重用），论文中候选池大小就和正常top1大小相同，也就是平均而言每个样本被重用k次</p>
</li>
</ul>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/mLOqDY2PvnCokEN.jpg" alt="Refer to caption" class="img_ev3q"></p>
<ul>
<li>既然Bootstrap Sampling只不过是对样本的采样重用，那其实可以直接计算对应的优势值的期望，所以可以省去采样这一步，直接计算候选池中正负样本的个数，通过解析解得到期望带入计算</li>
</ul>
<p>其他实验：</p>
<p>Pass@k的熵在训练中是上升的，而Pass@1后期会收敛，支持了前面的探索-利用论</p>
<p>k的值的影响？k的值不是跳出局部解的重要因素，但k值越大，优势越小（因为只有抽样全负才会是负奖励，k值越大正奖励概率越高），步长越小，训练效率降低，这个结论和也可以在改变学习率中得到验证</p>
<p>无论是小规模还是大规模的 LLM，都可以从 Pass@k 训练中受益。此外，模型架构和模型系列不会影响持续 Pass@1 训练的提升，下游任务的领域和形式也不会影响 LLM Pass@k 性能向 Pass@1 性能的迁移</p>
<p>分析：</p>
<p>同样是奖励从0到1，Pass@k的梯度出现在比Pass@1更早的地方（一次做对和K次做对），会使得Pass@k更倾向于解决更难的问题而不是中等难度的问题（由于Pass@k有一个argmax, 所以提高已经会做的题的正确率的效果是不断减小的）</p>
<p>Pass@1</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/kwHnEW4mdQfrZqc.jpg" alt="Refer to caption" class="img_ev3q"></p>
<p>Pass@k</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/d1Rg98LKeMtoNhm.jpg" alt="Refer to caption" class="img_ev3q"></p>
<p>还做了一个对比试验是仅将简单问题的奖励设置为0，不能防止模型过度优化</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/Urpd158SLRyWvaM.jpg" alt="Refer to caption" class="img_ev3q"></p>
<p>为了分析是否全是梯度曲线峰值带来的影响，手动调整奖励曲线，设计了一个这样的曲线</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/pWVjfl1t8JSgyo6.jpg" alt="Refer to caption" class="img_ev3q"></p>
<p>发现太注重困难的样本也不好，模型后期乏力</p>
<p>既然Pass@k 更注重困难样本，Pass@1 更注重一般样本，能否动态结合？</p>
<p>一个样本池中，正样本越多，越需要注重困难样本；反之需要先学会一般样本，因此设计了这样的优势函数</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/gwcpM1DWYLRAonm.png" alt="image-20250818003914103" class="img_ev3q"></p>
<p>发现效果非常好</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/rLXHtQpnTy2Phqc.jpg" alt="Refer to caption" class="img_ev3q"></p>
<p>文章还做了另一个实验是，用熵而不是正样本数量来判断一个问题是否是困难的，熵高的50%认为是困难问题，使用Pass@1, 低的使用Pass@k，也得到了不错的效果</p>
<p>简评：感觉没太多好说的了，他们做的相当好，从最开始的发现topk training可以提升效果，再到用bootstrap sample提高效率，再到公式的推出，自然发现topk就是本质上对应的难度-奖励曲线的不同，再到设计相关的实验验证，最后提出简单的自适应机制来结合Pass@1和Pass@k，也取得了相当好的实验效果，感觉挺一气呵成的，感觉是一个会成为范式的trick</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="structure-aware-fill-in-the-middle-pretraining-for-code">Structure-Aware Fill-in-the-Middle Pretraining for Code<a class="hash-link" aria-label="Direct link to Structure-Aware Fill-in-the-Middle Pretraining for Code" title="Direct link to Structure-Aware Fill-in-the-Middle Pretraining for Code" href="https://ayanami1314.github.io/blog/llm%20for%20code%20paper%20notes#structure-aware-fill-in-the-middle-pretraining-for-code">​</a></h2>
<p>问题：现有的FIM将代码视为字符序列，而忽视句法结构</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/qrSZeCaH1uMOfsI.png" alt="Refer to caption" class="img_ev3q"></p>
<p>方法： 结合AST和FIM， 在训练时，被mask的部分始终是AST的一个或多个完整子树</p>
<p>代码解析：Tree-sitter</p>
<p>mask算法：涵盖不同的AST节点，提高泛化能力，且与具体语言无关</p>
<ul>
<li>单节点mask: 按照对应文本的数量成比例抽样</li>
<li>多节点mask: 先进行一次字符区间的采样，再找到包含这个字符区间的最小3节点的AST子树，子树中再取和原始字符区间有最大交并比的部分</li>
</ul>
<p>评估：字符级别困惑度，文章给出不用实际benchmark的原因是大规模单测太难。</p>
<p>简评：非常直接的想法，就类似word-level BERT对原始BERT的改进，不过它怎么构建AST的倒是可以参考。文章最后的评估用困惑度说服力不高，但考虑到它的数据量确实大（256*H100训练），也可以理解</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-entropy-mechanism-of-reinforcement-learning-for-reasoning-language-models">The Entropy Mechanism of Reinforcement Learning for Reasoning Language Models<a class="hash-link" aria-label="Direct link to The Entropy Mechanism of Reinforcement Learning for Reasoning Language Models" title="Direct link to The Entropy Mechanism of Reinforcement Learning for Reasoning Language Models" href="https://ayanami1314.github.io/blog/llm%20for%20code%20paper%20notes#the-entropy-mechanism-of-reinforcement-learning-for-reasoning-language-models">​</a></h2>
<p>问题：现有RL后训练存在策略熵减小导致模型快速收敛，后期探索较少难以提升的问题</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/G7D8E1Tij9VUvor.png" alt="Refer to caption" class="img_ev3q"></p>
<p>作者发现，在前1/3的epoch中，基本就已经达到了大部分的性能，而熵也进入低值，作者称之为熵崩溃"entropy collapse"</p>
<p>且对于不同的模型大小，对于不同的RL方法，都能拟合近似的定律  <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>=</mo><mo>−</mo><mi>a</mi><msup><mi>e</mi><mi>H</mi></msup><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">R=-a e^{H} + b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.9247em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.08125em">H</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">b</span></span></span></span></p>
<p>有了这样的拟合公式，可以在训练早期估计后期的性能，且ab与算法几乎无关，极限就是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mi>a</mi><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">-a+b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">b</span></span></span></span></p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/U8MvB1IJD5izsQf.png" alt="Refer to caption" class="img_ev3q"></p>
<p>另一个有趣的发现是，ab和模型大小呈对数线性关系</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/Vqo3QmfCA54is7x.png" alt="Refer to caption" class="img_ev3q"></p>
<p>也就是说，不仅可以在训练前期拟合后期，还可以用小模型预测大模型的RL效果</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/DnwJNZRAXuvSlEO.png" alt="image-20250818222517778" class="img_ev3q"></p>
<p>熵变公式如上，直观地讲，如果动作 a 同时获得高/低概率和高/低优势，则熵会降低，反之亦然</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/DRXsvrGAMuIBFOU.png" alt="Refer to caption" class="img_ev3q"></p>
<p>作者还提出，直接使用熵损失的方法，如<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo>=</mo><msub><mi>L</mi><mn>0</mn></msub><mo>−</mo><mi>α</mi><mi>H</mi></mrow><annotation encoding="application/x-tex">L = L_0 - \alpha H</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mord mathnormal" style="margin-right:0.08125em">H</span></span></span></span>， 不仅对超参数敏感，实验效果也并不优于基线</p>
<p>所以作者提出的方法是，针对高协方差的一小部分token做Clip或者KL，就能防止熵崩溃，下面的实验结果也表现很好，熵后期不下降，回答长度增长，正确率大幅度提高</p>
<p><img decoding="async" loading="lazy" src="https://arxiv.org/html/2505.22617v1/x25.png" alt="Refer to caption" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/4iR9K8EvMwGD1no.png" alt="Refer to caption" class="img_ev3q"></p>
<p>作者发现策略熵对超参数设置非常敏感。具体来说，我们的方法仅干预一小部分 token（ 10−4 到 10−3 ），却完全改变了熵曲线。这意味着几个“关键” token 对 LLM 的熵至关重要</p>
<p>简评：搬运作者对clip-higher的讨论，作者认为，clip-higher也有类似的功能，提高重要性采样的上限会带来更多低概率的token，上限阈值仅影响具有正优势的 token，这意味着 clip-higher 实际上在梯度计算中添加了更多低协方差（低概率、高优势）的 token，所以结论殊途同归。而作者直接提出协方差是更胜一筹。</p>
<p>不过作者也说了现在还不清楚熵和模型性能的完整关系，也不清楚最优的熵值</p>
<p>另一个就是这些熵的论文主要还是在math任务上做的，code任务能否有相同的结论还是一个问题 (我认为这两个任务关键在于中间过程是不是重要的，math只有结果可能会得到一些错误的结论)</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="improving-llm-generated-code-quality-with-grpo">Improving LLM-Generated Code Quality with GRPO<a class="hash-link" aria-label="Direct link to Improving LLM-Generated Code Quality with GRPO" title="Direct link to Improving LLM-Generated Code Quality with GRPO" href="https://ayanami1314.github.io/blog/llm%20for%20code%20paper%20notes#improving-llm-generated-code-quality-with-grpo">​</a></h2>
<p>问题：take code quality into consideration，不多赘述</p>
<p>方法：维护了一个库，把现有的一些评估代码质量的方案整合了起来（code complexity, dead code, code structure(linter等)， style&amp;doc, safety, performance...）, 然后质量奖励和正确性奖励一起放到奖励里面丢给GRPO</p>
<p>简评：只是占坑的，很草率的方法（对于奖励参数的设定），定量结果也不足。</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="enhancing-high-quality-code-generation-in-large-language-models-with-comparative-prefix-tuning">Enhancing High-Quality Code Generation in Large Language Models with Comparative Prefix-Tuning<a class="hash-link" aria-label="Direct link to Enhancing High-Quality Code Generation in Large Language Models with Comparative Prefix-Tuning" title="Direct link to Enhancing High-Quality Code Generation in Large Language Models with Comparative Prefix-Tuning" href="https://ayanami1314.github.io/blog/llm%20for%20code%20paper%20notes#enhancing-high-quality-code-generation-in-large-language-models-with-comparative-prefix-tuning">​</a></h2>
<p>问题：take code quality into consideration</p>
<p>方法：比较有新意，将Dynamic Prefix和代码质量结合起来了，并且是使用对比学习的方法做这个前缀</p>
<p>基于Pylint打分，构建了一套数据处理流水线标注大量高、低质量的代码对（相似度高，质量差距大，且都至少通过一项基本测试）</p>
<p>然后在微调Dynamic Prefix的的时候，加上一个排名Loss，希望模型倾向于生成高质量的样本。</p>
<p>里面的掩码是用difflib做的，目标是聚焦于差异的导致质量出现区别的token，而不要考虑重复的token</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/trwUWyP8RMniE5H.png" alt="image-20250818231615372" class="img_ev3q"></p>
<p>然后进行PEFT微调，再加上KL散度来保证不要丢失原始模型的代码生成能力</p>
<p>简评：这篇文章写得特别冗长，实验做的重点不突出，但思想是有意思的，并且明显可以继续挖，例如他们的代码相似度是简单的词频向量，自然挖掘出来的是细微处的代码风格问题，如是用index还是for each的形式遍历循环（只有这样的才会词频上高度相似）。但实际上是否可以用例如bge-code这样的代码语义嵌入呢？值得探究。</p>
<p>还有就是，这个数据收集的方法依赖于大语料库，也只能挖掘常见的代码模式，如果用自生成的方法，例如假设我们已经有一些高质量的代码库作为ground truth，</p>
<p>用llm得到的补全片段当负项，也能构造正负样本对啊，既然都是训练得到一个通用的“code style prefix”，这样数据丰富程度能高很多。他们明显的数据少训练小（2*A6000*3h）。</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="augmenting-large-language-models-with-static-code-analysis-for-automated-code-quality-improvements">Augmenting Large Language Models with Static Code Analysis for Automated Code Quality Improvements<a class="hash-link" aria-label="Direct link to Augmenting Large Language Models with Static Code Analysis for Automated Code Quality Improvements" title="Direct link to Augmenting Large Language Models with Static Code Analysis for Automated Code Quality Improvements" href="https://ayanami1314.github.io/blog/llm%20for%20code%20paper%20notes#augmenting-large-language-models-with-static-code-analysis-for-automated-code-quality-improvements">​</a></h2>
<p>问题：LLM refactor code没结合静态分析</p>
<p>方法：RAG + 静态分析软件 + Prompt 工程</p>
<p>简评：垃圾文章，真要做也是做一个能排序Code Quality的专用BERT，或者对现有的code embedder/reranker做adapter研究怎么把code quality调进去</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="a-hierarchical-and-evolvable-benchmark-for-fine-grained-code-instruction-following-with-multi-turn-feedback">A Hierarchical and Evolvable Benchmark for Fine-Grained Code Instruction Following with Multi-Turn Feedback<a class="hash-link" aria-label="Direct link to A Hierarchical and Evolvable Benchmark for Fine-Grained Code Instruction Following with Multi-Turn Feedback" title="Direct link to A Hierarchical and Evolvable Benchmark for Fine-Grained Code Instruction Following with Multi-Turn Feedback" href="https://ayanami1314.github.io/blog/llm%20for%20code%20paper%20notes#a-hierarchical-and-evolvable-benchmark-for-fine-grained-code-instruction-following-with-multi-turn-feedback">​</a></h2>
<p>只需要看一张图就行了</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/ZOrG26Leygztn5N.png" alt="image-20250818234727444" class="img_ev3q"></p>
<p>现有模型在约束生成时，quality这种抽象的约束是满足最差的</p>
<p>而对于多种约束的组合，现有LLM都很差</p>
<p>而对于有反馈的情况（例如linter之类），在3轮迭代左右就能有很大的提升，但后续再增加轮数也难以获得更高收益</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="training-language-models-on-synthetic-edit-sequences-improves-code-synthesis">Training Language Models on Synthetic Edit Sequences Improves Code Synthesis<a class="hash-link" aria-label="Direct link to Training Language Models on Synthetic Edit Sequences Improves Code Synthesis" title="Direct link to Training Language Models on Synthetic Edit Sequences Improves Code Synthesis" href="https://ayanami1314.github.io/blog/llm%20for%20code%20paper%20notes#training-language-models-on-synthetic-edit-sequences-improves-code-synthesis">​</a></h2>
<p>问题：LLM这样“一口气生成所有代码”和先前的软件工程实践（增量式开发）是相悖的，而现在的code agent又需要增量开发的能力，有绕远路之感，于是研究能不能从预训练的数据侧上解决这个问题，即大规模合成 增量编辑数据</p>
<p>方法: 文章提出了一个LintSeq的方法，对于一段已有的代码，从里面修建某些部分回退，让回退后的代码不会触发linter错误，则构建了一个edit stage</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/kGrRXUvC1Sbs6Pe.png" alt="Refer to caption" class="img_ev3q"></p>
<p>然后这样构建了数据集后自己SFT codellm，发现确有提升</p>
<p>简评：简单有效，或许可以想想这个怎么和RL结合？</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="focused-dpo-enhancing-code-generation-through-focused-preference-optimization-on-error-prone-points">Focused-DPO: Enhancing Code Generation Through Focused Preference Optimization on Error-Prone Points<a class="hash-link" aria-label="Direct link to Focused-DPO: Enhancing Code Generation Through Focused Preference Optimization on Error-Prone Points" title="Direct link to Focused-DPO: Enhancing Code Generation Through Focused Preference Optimization on Error-Prone Points" href="https://ayanami1314.github.io/blog/llm%20for%20code%20paper%20notes#focused-dpo-enhancing-code-generation-through-focused-preference-optimization-on-error-prone-points">​</a></h2>
<p>问题：代码错误很多是中间的“易错点”出错，对于所有token一视同仁的奖励函数在代码任务上可能未必高效</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/1PfxEt2h8gaKnXl.png" alt="image-20250819001722237" class="img_ev3q"></p>
<p>方法：</p>
<ol>
<li>该方法从真实代码库中提取概念，生成问题、代码和测试</li>
<li>由于有了测试，所以可以比较不同的生成代码的相对性能</li>
<li>通过共同前缀和共同后缀，得到中间不一样的中缀，就认为是“易错点”</li>
</ol>
<p>然后DPO专注这一块的优化</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/08/19/BKAtb5MYlhkGoW3.png" alt="image-20250819002037550" class="img_ev3q"></p>
<p>简评：感觉上是更软件工程的熵方法的简化，感觉这个易错点是能从LLM自身状态或者其他软件工程分析技巧中得到的，从前面几篇也可以看出，现在这种广义上的RL ”attention“ mask类工作越来越多了</p>
<p>这个方法要求生成测试，实际生产中感觉并不可用；抛开这个不谈，感觉就单纯对一个大型代码数据集，去分析里面的编码模式，找到相对少的n-gram，或者AST level迅速变化的地方作为易错点重点训都或许可行</p>]]></content:encoded>
            <category>llm</category>
            <category>ai</category>
            <category>code</category>
            <category>RL</category>
        </item>
        <item>
            <title><![CDATA[投机解码简述]]></title>
            <link>https://ayanami1314.github.io/blog/speculative-decode-overview</link>
            <guid>https://ayanami1314.github.io/blog/speculative-decode-overview</guid>
            <pubDate>Mon, 25 Aug 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[动笔的时候会有一种感觉，自己对这个方向了解的还是太少了... 所以大概不会讲得很学术，主打一个轻松愉快，让不了解的人也简单知道一下投机解码speculative decoding]]></description>
            <content:encoded><![CDATA[<p>动笔的时候会有一种感觉，自己对这个方向了解的还是太少了... 所以大概不会讲得很学术，主打一个轻松愉快，让不了解的人也简单知道一下投机解码speculative decoding</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="投机的提出">投机的提出<a class="hash-link" aria-label="Direct link to 投机的提出" title="Direct link to 投机的提出" href="https://ayanami1314.github.io/blog/speculative-decode-overview#%E6%8A%95%E6%9C%BA%E7%9A%84%E6%8F%90%E5%87%BA">​</a></h3>
<blockquote>
<p>当前，大型语言模型（LLM）在推理阶段普遍采用自回归解码策略，其核心特性是<strong>逐步串行生成 token，每一步都依赖前一步的输出</strong>。这一计算模式导致推理过程在系统层面面临严重的<strong>内存带宽瓶颈</strong>：每一步前向计算都需要将<strong>完整的模型参数从高带宽内存（HBM）加载到加速器缓存</strong>，但仅生成一个 token。由于每次只生成一个 token，导致大量的计算资源被闲置，无法充分发挥加速器的算力潜力，最终造成整体推理效率低下。
为解决这一问题，一种加速大型语言模型推理的思路是<strong>提高解码过程的算术强度</strong>（即总浮点运算次数 FLOPs 与数据传输量之间的比值），同时<strong>减少解码步骤</strong>。基于这一理念，研究者们提出了<strong>推测解码/投机解码（Speculative Decoding）</strong> 技术。Speculative Decoding 的核心思路如下图所示，首先以低成本的方式（一般来说是用小模型）快速生成多个候选 token，然后通过一次并行验证阶段快速验证多个 token，进而减少大模型的 decode 次数，从而达到加速的目的。</p>
</blockquote>
<p>上面讲得比较学术，我尝试给一个自己的通俗些的解释：</p>
<p>llm的推理分成两个阶段，prefill 和 decode，prefill处理两个事情，计算输入（prompt）部分的attention和kvcache，输出第一个Token；而decode处理自回归的生成token的后续部分，即输出</p>
<p>为什么这样分呢？实际上是因为他们的计算负载不同，而更本质的原因是现有LLM的主流架构是CasualLM，即三角因果掩码，计算当前token时是无法看到未来token的。这带来了一个结果是，对于输入部分，我们可以并行的计算所有的输入token，但对于输出阶段，由于下一个token依赖于前一个token，所以我们只能串行的计算。</p>
<p>在LLM推理加速方面针对这两种计算的统一和调度有很多很多的研究，例如chunked prefill到新的pd分离、af/am分离等，但直接对这一传统范式发起挑战的大致就是几种：一种尝试换其他架构的模型，比如stable diffusion的dLLM，一种尝试采用多个输出头在训练时就学会“一次预测几个词”（deepseek MTP），剩下的就是投机解码</p>
<p>投机解码的核心思想就是，既然我们的decode阶段是内存密集型的（后面的token依赖于前面的token导致计算不能打满），那我可以把多余的算力利用起来，我用某种机制一次性猜测多个token，然后<strong>LLM从生成变为验证</strong>，就完成了并行化</p>
<p>Q1: 为什么说生成变为验证是并行化？
A1:  因为验证这里有一个关键的地方是，<strong>在验证后一个token的时候，直接假设前面猜测的token都是对的</strong>，以猜测“千早爱音唐得没边”为例子，模型并不是串行的验证“千”对不对，“早”对不对，而是并行地验证这8个字，在验证“唐”的时候直接假设前面的输出“千早爱音”是对的。带来的效果是，如果“唐”被验证是错的，后续的所有token“唐的没边”都会被舍弃。</p>
<p>Q2：如何验证呢？
A2：LLM生成token的最后一步是概率采样，如果猜测的概率是p1, LLM正常推理输出是p2, 如果<code>p1 &lt; p2</code>（这里已经进行了猜测的采样），则选择猜测是对的；如果<code>p1 &gt; p2</code>，则对的概率是 <code>P(p2|p1)=p2/p1</code>, 这样从直觉上就可以理解如何“验证”了，具体输出期望的一致性证明可以参考相关论文</p>
<p>Q3：投机在精度上是不是无损的?
A: 看你如何定义。投机的核心是验证中的拒绝采样，学过rl的同学应该对这个概念很熟悉，拒绝采样带来的后果是，<strong>输出的期望是一样的，方差会变大</strong>。所以llm的期望是一样的，输出方差会变大，可能类似于调大温度。当然投机概率乘的多了还有一些数值精度上的问题。</p>
<p>Q4: 那并行的其他head空算不是更浪费算力和空间吗？一次<code>all-layer</code>的forward时间应该还挺长的
A：传统投机是不接受，但其他head的结果可以加入候选池，就是候选池改进的方法, 实际上不一定会这样验吧。medusa的tree attention就是，我不是序列地验head1，head2，而是尝试在树上直接找到综合接受期望最长的序列，也就是head1并非贪婪采样，不过现在推理引擎不是完全支持这个，据我所知sglang默认是有的，但vllm确实是这种序列的验法。浪费计算你说得对，所以投机work的前提是mem bound，但接受率越高浪费的不就越少吗，本质上还是接受率不够</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="如何生成猜测">如何生成猜测<a class="hash-link" aria-label="Direct link to 如何生成猜测" title="Direct link to 如何生成猜测" href="https://ayanami1314.github.io/blog/speculative-decode-overview#%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E7%8C%9C%E6%B5%8B">​</a></h3>
<p>主流是这几种方法：</p>
<ul>
<li>启发式，如<code>n-gram</code>，在很多任务中，输出会抄写prompt种已经给出的上文，比如总结任务，所以直接在给出的prompt中统计<code>n-gram</code>词频，取以现在输出末尾token开头的最佳选项作为猜测，优势是引入非常简单，劣势是吃任务类型（工作负载），对于很多任务没太大效果</li>
<li>小模型，例如用<code>qwen3-0.6b</code>的输出作为<code>qwen3-8b</code>的输出的猜测</li>
<li>自猜测，如medusa和eagle这种，给模型训练一个额外的附加结构，让其具备类似MTP的推理时猜多个token的能力。这个附加结构早期是放在模型的最后一层，即多个输出头，后来eagle提出最后一层（logits）不如倒数第二层（特征层），并且改造输出头的输入，再加上先前的token(即输入为，之前所有token的倒数第二层+当前token的倒数第二层+之前所有token的实际采样结果)，效果非常好，能够达到7~8倍加速的疯狂数字</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="没有免费的午餐">没有免费的午餐<a class="hash-link" aria-label="Direct link to 没有免费的午餐" title="Direct link to 没有免费的午餐" href="https://ayanami1314.github.io/blog/speculative-decode-overview#%E6%B2%A1%E6%9C%89%E5%85%8D%E8%B4%B9%E7%9A%84%E5%8D%88%E9%A4%90">​</a></h3>
<p>那么古尔丹，代价是什么呢？</p>
<p>注意在开始我们就讲了，投机是一个利用空闲计算的方法，但实际上，利用空闲计算的方法不止投机一个，例如你有100张卡，你完全可以把不同的计算任务调度到不同的卡上，尽可能打满所有卡的计算</p>
<p>实际上这也是投机的痛点，或者说到底什么时候，投机才是有用的。</p>
<p>magicdec一文中已经指出，投机的适用场景常见于两种工作负载模式：</p>
<ol>
<li><strong>端侧推理</strong>，你只有一张卡，只能加载一个模型，这个模型还把你的显存占满了，那显然你无法通过加大batch来缓解memory bound，这时候投机是真有收益，eagle论文里面的7x加速也是batch=1的时候跑出来的</li>
<li><strong>长上下文</strong>，你有大集群可以做不同任务的调度，但你的上下文实在太长，kvcache大小是随上下文线性增长的，上下文过长之后，你的大集群也硬生生被整成memory bound了（热知识：显存不是80G都是平等的，显然显卡也有SRAM/DRAM这样的高速低速区，更不提上下文太长之后有些kvcache直接就被offload到内存了）</li>
</ol>
<p>端侧推理很好理解，那长上下文具体是多长呢？</p>
<p>magicdec给了一个指标是：对于接受率为0.8的投机，在实际的大batch size下（256），大概在3.2k token上下文开始投机能够取得收益（对于GQA这种模型而言，由于其在mem上较优，sd能加速的临界prefill长度会更高，对于非GQA模型是大概1.3k）</p>
<p>（关于端侧推理，我在我自己的一个项目上也试验过投机解码，平均输入长度大概是2k tokens，<code>n-grams</code>投机大概能加速30%，eagle由于我的训练数据等问题，也差不多）</p>
<p>当然以上只是一个最最简单的认识，实际上投机的很多算法相当复杂：</p>
<ul>
<li>
<p>能否快速剪枝某些置信度低的序列，不然预测k个token，可能的组合数指数增长吃不消？——medusa等</p>
</li>
<li>
<p>剪枝之后如何高效计算？—— tree attention</p>
</li>
<li>
<p>投机算法中，当出现拒绝验证时，后续的猜测token全部被丢弃，这些猜测token有没有可能被重用？——一系列维护候选池的方法</p>
</li>
<li>
<p>小模型猜大模型很美好，但不是所有大模型都有对应的小模型，能否支持异构（大小模型词表不同）？—— huggingface uag tli等方法</p>
</li>
<li>
<p>投机的超参数（例如一次猜几个token等）难以确认，能否用RL等方法优化超参选择？ —— banditspec等</p>
</li>
<li>
<p>能否通过LLM的置信度或者外部的一些规则等来动态开关投机，避免额外浪费的计算量？</p>
</li>
<li>
<p>能否把投机也用到prefill过程中（选取kv）？—— specprefill</p>
</li>
<li>
<p>在多模态场景中，如何使用投机，如果能的话，又该怎么做？——vllm roadmap(雾)</p>
</li>
<li>
<p>eagle还是太吃训练了，training方法如何做数据集选择？</p>
</li>
<li>
<p>除了从prompt中选取候选，能否从参考资料等其他文本中选取猜测？—— snowflakes suffix decoding</p>
</li>
<li>
<p>投机如何和现有大规模并行融合？（在vllm的投机集成中，投机的模型的并行都是简单的1，即投机模型不做tp来降低实现复杂度）—— 最新的 字节swiftspec</p>
</li>
<li>
<p>...</p>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="展望">展望?<a class="hash-link" aria-label="Direct link to 展望?" title="Direct link to 展望?" href="https://ayanami1314.github.io/blog/speculative-decode-overview#%E5%B1%95%E6%9C%9B">​</a></h3>
<p>最近投机是真的很火，aaai26中好像就有30篇投机的文章</p>
<p>如果从一个应用者的视角来说的话，现有推理框架（比如vllm&amp;sglang）基本都有投机的集成了，只是集成多少的问题</p>
<p>而训练投机的话，sglang的specForge项目把它变得相当傻瓜化了，现在正在快速发展中</p>]]></content:encoded>
            <category>speculative decoding</category>
            <category>llm</category>
            <category>ai infra</category>
        </item>
        <item>
            <title><![CDATA[Paper reading - Context Pruning and beyond hard pruning]]></title>
            <link>https://ayanami1314.github.io/blog/Paper reading Context Pruning and beyond hard pruning</link>
            <guid>https://ayanami1314.github.io/blog/Paper reading Context Pruning and beyond hard pruning</guid>
            <pubDate>Tue, 29 Jul 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[引子]]></description>
            <content:encoded><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="引子">引子<a class="hash-link" aria-label="Direct link to 引子" title="Direct link to 引子" href="https://ayanami1314.github.io/blog/Paper%20reading%20Context%20Pruning%20and%20beyond%20hard%20pruning#%E5%BC%95%E5%AD%90">​</a></h2>
<p>我们知道，在现在Agent需要处理的一大问题是长上下文下性能的开销问题，对此infra团队有非常多的优化，从attention架构的优化如各种windowed attention到kv的压缩重用如cacheblend和megicdec等都提出了一系列的解决方案，但有一个最本质的方法是：有没有可能直接减少上下文的长度(去掉不必要的上下文?) ，这就是Context Pruning的出发点。</p>
<p>而截止2025年8月，相关的方法已经发展了两三年了，大体上可以分成几个类别，本文会对此做一些简单的介绍和总结。</p>
<p>借用naver lab最新的相关论文里面的<a href="https://europe.naverlabs.com/blog/efficient-online-text-compression-for-rag/" target="_blank" rel="noopener noreferrer">说法</a>，现在的方法可以被一个四方格归纳：</p>
<p><img decoding="async" loading="lazy" src="https://europe.naverlabs.com/wp-content/uploads/2025/05/5-OnlineOfflineHardSoft.png" alt="" class="img_ev3q"></p>
<p>其中，Hard和Soft代表裁剪方法是直接作用于token上（hard，相当于裁剪结束后，输入的是一个新的prompt），还是作用于token的embedding上（soft，相当于裁剪结束后，输入的是一个新的qkv和其他东西，无法还原出“原始”的token输入）</p>
<p>在线和离线一般代表着这个裁剪方案是否依赖于用户查询q，依赖q的方案是在线的，不依赖q的方案是离线的，可以提前做好。但传统上，如果你的裁剪方法也需要用到和原始模型一样大的LLM，也一般称之为离线，或许“是否会对在线推理造成明显时延影响”做划分更好一些</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="离线硬裁剪">离线硬裁剪<a class="hash-link" aria-label="Direct link to 离线硬裁剪" title="Direct link to 离线硬裁剪" href="https://ayanami1314.github.io/blog/Paper%20reading%20Context%20Pruning%20and%20beyond%20hard%20pruning#%E7%A6%BB%E7%BA%BF%E7%A1%AC%E8%A3%81%E5%89%AA">​</a></h3>
<p>在最早期的时候，就有相关的一些朴素方法，例如直接对查询文本段做一次总结摘要，再用总结后的文本段去做后续的任务，这种方法是离线硬裁剪的典型代表。如果用的是llm就是离线的，如果用轻量级模型做摘要或者总结就是在线的</p>
<p>而在后面的时候，出现了例如微软的llmlingua这样的工作，直接用一个小模型(gpt2 small，llama-7b, etc)去预测哪些token是重要的，哪些token是不重要的，然后把不重要的token直接裁剪掉，这种方法也是离线硬裁剪的典型代表。(llmlingua2 换成了微调的 BERT 来做这个事情，所以可以说在线的)， 其出发点和常规的硬裁剪可能有部分地方不同，例如llmlingua认为，裁剪本身是可以得到一些人类不可读但是大模型可以理解的token序列的，所以可解释性上可能并没有想象的那么强。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="离线软裁剪">离线软裁剪<a class="hash-link" aria-label="Direct link to 离线软裁剪" title="Direct link to 离线软裁剪" href="https://ayanami1314.github.io/blog/Paper%20reading%20Context%20Pruning%20and%20beyond%20hard%20pruning#%E7%A6%BB%E7%BA%BF%E8%BD%AF%E8%A3%81%E5%89%AA">​</a></h3>
<p>和硬裁剪同时推进的是软裁剪相关的工作，其想法很简单: 如果我牺牲解释性，直接调整prompt的embedding这类，即使产生的是不对应任何token的"fake embedding"，其在高维空间中也应该融合了多个token的语义，理应得到更高的压缩率(可以理解为，在训练过程中为llm 扩充为无限词表，然后定义了一些高效的"额外语言")</p>
<p>比较早期的工作是 xRAG， 其裁剪策略非常极端，将整个段落都压缩成1个embedding X，怎么训练呢？一个在此类论文中经常出现的是重建loss，即</p>
<p>压缩前<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi><mi>o</mi><mi>c</mi><mo>+</mo><mi>q</mi><mi>u</mi><mi>e</mi><mi>r</mi><mi>y</mi><mo>→</mo><mi>x</mi></mrow><annotation encoding="application/x-tex">Doc + query \to x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em"></span><span class="mord mathnormal">Doc</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.03588em">ery</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">x</span></span></span></span></p>
<p>压缩后<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi><mi>o</mi><msup><mi>c</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>+</mo><mi>q</mi><mi>u</mi><mi>e</mi><mi>r</mi><mi>y</mi><mo>→</mo><msup><mi>x</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">Doc' + query \to x'</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8352em;vertical-align:-0.0833em"></span><span class="mord mathnormal">Do</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.03588em">ery</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7519em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo>=</mo><mi>L</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo separator="true">,</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi>D</mi><mrow><mi>K</mi><mi>L</mi></mrow></msub><mo stretchy="false">(</mo><msup><mi>x</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo separator="true">,</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L=L(x',x)=D_{KL}(x',x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.0019em;vertical-align:-0.25em"></span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.0019em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em">K</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span>，  即自蒸馏，希望压缩后依然能重建原始的输出，论文实际中可能会用变体版本来实现指令遵循等</p>
<p>xRAG的做法是，使用一个通用编码器E，把这个编码器E视作一个新的模态，仿照CLIP的方法直接用MLP projector做通用编码器和实际使用的LLM token embedding的模态对齐</p>
<p>但[大家实测下来](笔记：RAG 的相关优化方法之六（xRAG/PISCO） - 刀刀宁的文章 - 知乎
<a href="https://zhuanlan.zhihu.com/p/29292925032)%EF%BC%8CxRAG%E7%9A%84%E6%95%88%E6%9E%9C%E5%B9%B6%E4%B8%8D%E5%A5%BD%EF%BC%8C%E8%80%8C%E7%9B%B8%E5%AF%B9%E8%BE%83%E5%A5%BD%E7%9A%84%E6%98%AF%E6%9B%B4%E6%96%B0%E7%9A%84Pisco%E6%96%B9%E6%B3%95" target="_blank" rel="noopener noreferrer">https://zhuanlan.zhihu.com/p/29292925032)，xRAG的效果并不好，而相对较好的是更新的Pisco方法</a></p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/09/07/qYgLrSRHVJj4P5x.png" alt="Refer to caption" class="img_ev3q"></p>
<p>Pisco将检索到的文档D和memory tokens一起送到LLM中，产生embeddings</p>
<p>再将embeddings +query送到相同的LLM中，产生输出，这个 q+E 和原始的 q+D 比较， 计算交叉熵损失</p>
<p>这里有一些复杂的地方:</p>
<ul>
<li>
<p>虽然叫解码和编码，但是Student LLM都是同一个LLM, 只是训练不同LoRA模块</p>
</li>
<li>
<p>交叉熵是怎么得出的? teacher模型和student模型都是采用的最大长度128的贪婪解码，就可以直接令 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo>=</mo><mo>−</mo><mo>∑</mo><mn>1</mn><mi>l</mi><mi>o</mi><mi>g</mi><mi>p</mi><mo>+</mo><mn>0</mn><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>p</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><msub><mo>∑</mo><mi>i</mi></msub><mi>l</mi><mi>o</mi><mi>g</mi><mi>P</mi><mo stretchy="false">(</mo><msub><mi>a</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><mi>q</mi><mo separator="true">,</mo><mi>e</mi><mo separator="true">,</mo><msub><mi>a</mi><mrow><mo>&lt;</mo><mi>i</mi></mrow></msub><mo separator="true">,</mo><msub><mi>θ</mi><mi>c</mi></msub><mo separator="true">,</mo><msub><mi>θ</mi><mi>d</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L=-\sum 1logp + 0log(1-p) = - \sum_i log P(a_i|q,e,a_{&lt;i},\theta_c,\theta_d) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1</span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em">g</span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">0</span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em">g</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">p</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.0497em;vertical-align:-0.2997em"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.162em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em">g</span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">e</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>， 优化目标是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>θ</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">\theta_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>θ</mi><mi>d</mi></msub></mrow><annotation encoding="application/x-tex">\theta_d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> 还有 memory_tokens</p>
</li>
<li>
<p>如何理解memory token? 我觉得文章是借用了之前的一些研究比如ICAE, 在这些文章之中，训练的压缩机制是，将上下文压缩成一个定长的memory slot, 这里的memory token实际上只是多个embedding向量而已，而更关键的是LoRA微调的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>θ</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">\theta_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>，我的理解是，memory tokens只是一个后置的、可以看到Documents的所有信息（假设它没有魔改注意力）的语义位置，叫tokens也可以理解为直接扩了词表加入了l个特殊token，类似BERT里面的<code>[BOS]</code> ，只是decoder llm需要后置。</p>
<ul>
<li>文章并没有细说这里的注意力是怎么设置的，但从后文中发现的memory tokens具有明显的位置特性（例如1位mem token主要注意最开头一段），感觉应该是没改过</li>
</ul>
</li>
<li>
<p>文章的另一个重要的实验结论是，微调student llm(<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>θ</mi><mi>d</mi></msub></mrow><annotation encoding="application/x-tex">\theta_d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>)是必要的，之前的研究中没有相关模块，会导致性能的大幅度下降。这细想其实是一个很有趣的事情，可以注意到，压缩的时候是没有接触到query信息的（这也是为什么称为离线的原因），可以理解为某种意义上的LLM as an embedder，而加入了query和embedding再训练的时候，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>θ</mi><mi>d</mi></msub></mrow><annotation encoding="application/x-tex">\theta_d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>一边学会了如何理解自己产生的embedding，另一方面学会了如何根据query去选择embedding，整体上类似于ColBERT架构的Reranker（前面是multi-vec embed, 后面是maxsim）</p>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="在线硬裁剪">在线硬裁剪<a class="hash-link" aria-label="Direct link to 在线硬裁剪" title="Direct link to 在线硬裁剪" href="https://ayanami1314.github.io/blog/Paper%20reading%20Context%20Pruning%20and%20beyond%20hard%20pruning#%E5%9C%A8%E7%BA%BF%E7%A1%AC%E8%A3%81%E5%89%AA">​</a></h3>
<p>Provence</p>
<p>之前的裁剪方案只注重于“自然语言是有冗余的”，所以主要做的都是token-level的pruning，而provence则更注重实际一些，它发掘了一个问题是，其实现在RAG里面的 “Chunk” 是一个特别微妙的概念</p>
<p>如果chunk切得大了，那上下文自然就长了，甚至效果也会明显下降（详见ground truth在chunk中的不同位置的position bias相关的研究，现有embedder对这个bias耐受性不佳，会狠狠掉点）；但如果chunk切得小了，语义信息的丢失、检索的困难又是很恼人的事情（先不论检索，检索到了多个小块之后信息不够怎么办？一种是合并，但策略怎么定？另一种是Anthropic的Contextual Retrieval，把上下文放进来，本质上还是变成大块（我说这个a一串真是炒作勾啊.jpg））。</p>
<p>而Provence给了一个折中的方案，既然我们有句子级别的语义，为什么不用呢？分几步走</p>
<ol>
<li>训练一个接受q,d的BERT，给每一个token打0~1分，并根据用户指定的阈值进行二值化变为0/1, 表示删除/留下</li>
<li>进行句子级别的聚类，裁剪掉0的token数量大于1的token数量的句子</li>
</ol>
<p>如何训练呢？选取有5~10个句子的段（可以多次选取来拓展到更长的上下文），标上句子序号，让LLM选择相关句子来产生label，从而训练模型</p>
<p>这里其实做了很有意思的工程设计，</p>
<ul>
<li>
<p>如果让LLM来打token-level的标，肯定是收集不到足够的样本的，并且真的无所谓多出来的几个token，更在意句意的完整性</p>
</li>
<li>
<p>BERT带来了相当多的好处:</p>
<ul>
<li>
<p>这样进行的句子裁剪，每个句子都可以和整个chunk里面的所有上下文交互，使得一个句子的保留与否不仅取决于这个句子和查询的相关性，还取决于其于其他（和查询相关性高的）句子的相关性，这就使得这个方法必然会优于按句子切分的朴素方法</p>
</li>
<li>
<p>我们的 reranker 也就是个BERT啊，完全可以训裁剪和训rerank一起进行，推的时候也一样，相当于和rerank overlap了</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/09/07/yxnpqQOfW6lv8zg.png" alt="image/png" class="img_ev3q"></p>
</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="在线软裁剪">在线软裁剪<a class="hash-link" aria-label="Direct link to 在线软裁剪" title="Direct link to 在线软裁剪" href="https://ayanami1314.github.io/blog/Paper%20reading%20Context%20Pruning%20and%20beyond%20hard%20pruning#%E5%9C%A8%E7%BA%BF%E8%BD%AF%E8%A3%81%E5%89%AA">​</a></h3>
<p>Oscar</p>
<p>Pisco为代表的离线软裁剪有一个问题是，它的压缩需要微调，并且受限于难以对齐encoder-only架构的预训练编码器模态和实际推理使用的decoder LLM的模态，难以把压缩这一步在线做</p>
<p>Oscar就提出了一种方法是，我的对齐既然难做，我直接不对齐了，使用LLM的前L层 + memory token(他们也做了用Llama硬对齐的版本)，足以得到够好的embedding，文章最大的贡献其实是实验证明了这样表达能力已经足够，能训出来（太神奇了LLM）。当然，L越大效果越好</p>
<p>而还是复用Provence的工程技巧，把裁剪和rerank overlap起来，OSCAR的compressor留了一个RR头，在这个头和Teacher Reranker对齐，整体的Loss就是rerank loss + generation loss</p>
<p>而令LLM理解embedding这件事情还是通过LoRA adapter来做，这篇文章其实像是序列工作的延申，综合了PISCO的训练方法，把PISCO的压缩部分从LLM + LoRA换成目标模型的前N层transformer，然后压缩器全参微调、生成器LoRA微调，再使用和Provence相同的技巧进行rerank的overlap</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/09/07/pDRSe2sCwFabN8X.png" alt="image-20250907213839337" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="异曲同工">异曲同工<a class="hash-link" aria-label="Direct link to 异曲同工" title="Direct link to 异曲同工" href="https://ayanami1314.github.io/blog/Paper%20reading%20Context%20Pruning%20and%20beyond%20hard%20pruning#%E5%BC%82%E6%9B%B2%E5%90%8C%E5%B7%A5">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="从hyde到投机解码">从HyDE到“投机解码”<a class="hash-link" aria-label="Direct link to 从HyDE到“投机解码”" title="Direct link to 从HyDE到“投机解码”" href="https://ayanami1314.github.io/blog/Paper%20reading%20Context%20Pruning%20and%20beyond%20hard%20pruning#%E4%BB%8Ehyde%E5%88%B0%E6%8A%95%E6%9C%BA%E8%A7%A3%E7%A0%81">​</a></h4>
<p>另一个有趣的工作是广义上的“裁剪”，或者就是更好的搜索吧。我们知道HyDE的思想是原始query一般都比较短，而生成的假设文档可能会更好地与索引文档对齐，所以使用 q‘ = q + generated d 来进行搜索。</p>
<p>而智谱的<a href="https://arxiv.org/abs/2409.05591" target="_blank" rel="noopener noreferrer">memorag</a> 则提出了这样一种场景，我们是否能以低成本训练一个小模型，来根据源文本生成这个假设答案呢？（例如，使用Llama3-8B在哈利波特上训练比用Deepseek-R1在哈利波特上训练成本要低廉的多，将HyDE的生成方从R1自己换成小模型）这就非常像是投机解码的思想了</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="外接模块-memory-decoder-catridges">外接模块: memory decoder, catridges<a class="hash-link" aria-label="Direct link to 外接模块: memory decoder, catridges" title="Direct link to 外接模块: memory decoder, catridges" href="https://ayanami1314.github.io/blog/Paper%20reading%20Context%20Pruning%20and%20beyond%20hard%20pruning#%E5%A4%96%E6%8E%A5%E6%A8%A1%E5%9D%97-memory-decoder-catridges">​</a></h4>
<p>其实这种将memory训为embedding的方法确实不少，如果说前面的压缩器是在训一个meta network，能够从doc生成embedding的话，外接模块的工作就是在训练embedding本身 -&gt; 我能否直接从一个大的文档库中训练出一个参数化的memory?</p>
<p>最近的<a href="https://www.arxiv.org/abs/2508.09874" target="_blank" rel="noopener noreferrer">memory decoder</a>选择的是直接扭曲生成过程，将一个小模型在目标适配数据集上训练，在大模型生成token时，将小模型的概率和大模型的概率相加（再重归一化），认为这样会带来领域知识的纠正（比较暴力www）</p>
<p>而另一篇<a href="https://arxiv.org/abs/2506.06266" target="_blank" rel="noopener noreferrer">catridges</a> 则是在使用类似P-tuning的方式训一个Prefix KVCache，在推理时实时加载，而希望这个KV中有相关的memory</p>
<p>包括一系列的kvcache evict的工作也是在做类似的东西，为了决定evict哪些甚至都把搜索又搬上来了，比如clusterKV的knn(笑)</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="总结">总结<a class="hash-link" aria-label="Direct link to 总结" title="Direct link to 总结" href="https://ayanami1314.github.io/blog/Paper%20reading%20Context%20Pruning%20and%20beyond%20hard%20pruning#%E6%80%BB%E7%BB%93">​</a></h3>
<p>总体而言，我感觉相关工作已经进入了深水区了，硬裁剪可能在某些程度上到头了，现在主流在探索一些牺牲解释性的，更能scale out的方法来进行参数化memory来解决长上下文、领域适配等一系列问题</p>
<p>而大家方法逐渐趋向于无标签学习的统一也再次证明了scale out能力在广义embedding能力的训练上的重要性</p>
<p>另一个很有意思的是，可以看到搜索中的多向量和多memory token有一些很有趣的相似性，或许在后续的一些工作中，我们能看到一些多向量的方法被用到memory之中，希望会让memory这个很多时候靠prompt编故事的领域更多可验证性吧</p>
<p>而从另一个方面，正如这里列出的部分文章说的，自从eagle在投机解码中得到了确实很好的效果之后，大家都开始用 token + embedding的混合来捕捉更强的信息了，还有HyDE和投机解码这种很有趣的对应</p>]]></content:encoded>
            <category>rag</category>
            <category>ai</category>
            <category>llm</category>
            <category>agent</category>
            <category>embedding</category>
        </item>
        <item>
            <title><![CDATA[结构化输出与AI工具与Agent]]></title>
            <link>https://ayanami1314.github.io/blog/结构化输出</link>
            <guid>https://ayanami1314.github.io/blog/结构化输出</guid>
            <pubDate>Tue, 29 Jul 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[假如大伙接到一个需求，需要把claude code接入jupyter前端（例如，在jupyter前端直接输入魔法指令和claude code交互，而后台claude code展示claude code的一些关键节点，工具调用，费用开销，输出结果等），会怎么做？]]></description>
            <content:encoded><![CDATA[<p>假如大伙接到一个需求，需要把claude code接入jupyter前端（例如，在jupyter前端直接输入魔法指令和claude code交互，而后台claude code展示claude code的一些关键节点，工具调用，费用开销，输出结果等），会怎么做？</p>
<p>一种想法是，将claude code的输出塞到一个文件里面去，起一个后台线程读取这个文件，尝试解析之中的某些部分，再以插件的形式加载到jupyter前端</p>
<p>但带来了一个问题是，效果（尤其是工具数量upup，上下文长度upup后的效果）不稳定，纯prompt的形式约束claude code及时向这个文件中写入以向前端通信，在经过长的交互过程后，claude经常会把这个文件忘掉</p>
<p>那claude code直接全塞前端呢？</p>
<p>在claude code里面问一个问题，可能就是几千上万token的交互，全塞前端，那用户体验就烂掉了。</p>
<p>另一个很容易想到的方案是，那我们不要让他输出文件了，直接当场处理把，定义一些特殊块叫
display 之类的东西，在prompt里面指定这个块里面是什么格式，让他如果想要和前端输出的话，放到这个块里面</p>
<p>这样看起来比文件好一些，但带来了新的问题没解决，长上下文下，display块的结构偶尔会有不稳定，会有不少特殊的渲染格式如html等由于几个字符的差异退化成了纯文本</p>
<p>如何修复这个呢？一个简单的方法，也是你能在任意一个现在的agent中看到的，是及时判错，再把把错误的部分发给模型让他修复一下，但又带来了额外的开销，并且前端的呈现也收到影响</p>
<p>有没有更优雅的办法呢？</p>
<p>如果你做AI应用比较多的话，肯定注意到了这实际上是一个结构化输出(约束解码)的场景，但现在的问题是，输出不止是一个json，而是正常文本块和display块的交错</p>
<p>（对于不了解约束解码的简单介绍一下，就是把上层的json等约束编译成状态机之后，用于动态建立llm output logits的mask，从而杜绝输出非法输出的技术）</p>
<p>看起来似乎不能约束解码？但display块本身是可以约束解码的，好恶心。</p>
<p>让我们打开vllm文档，翻到 Structured Outputs，你会发现，除了常见的regex约束解码之外，还有两种更强语义的解决方案，救赎之道就在其中，ebnf解码和structure tags解码</p>
<p>实际上，json解码只不过是ebnf解码的特殊情况罢了，毕竟实际都是状态机
（不知道ebnf是什么的同学，可以搜索一下编译前端，BNF范式，就能看懂下面的示例啦）</p>
<p>官方给的一个ebnf解码的例子如下, 用于执行一个简化sql的约束解码以提升sql正确率</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">simplified_sql_grammar </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token triple-quoted-string string" style="color:#e3116c">"""</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    root ::= select_statement</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="display:inline-block;color:#e3116c"></span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    select_statement ::= "SELECT " column " from " table " where " condition</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="display:inline-block;color:#e3116c"></span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    column ::= "col_1 " | "col_2 "</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="display:inline-block;color:#e3116c"></span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    table ::= "table_1 " | "table_2 "</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="display:inline-block;color:#e3116c"></span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    condition ::= column "= " number</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="display:inline-block;color:#e3116c"></span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    number ::= "1 " | "2 "</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">"""</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">completion </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> client</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">chat</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">completions</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">create</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    messages</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token string" style="color:#e3116c">"role"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"user"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token string" style="color:#e3116c">"content"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"Generate an SQL query to show the 'username' and 'email' from the 'users' table."</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    extra_body</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">{</span><span class="token string" style="color:#e3116c">"guided_grammar"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> simplified_sql_grammar</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">completion</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">choices</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">message</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">content</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>如果放到这个问题，我们可以快乐地写出类似这样的定义</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">output := (display | normal text) *</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">display := (```display json ```)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">json = ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">normal text = others</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>其中，display, json都是容易得到的，但恶心的地方在于什么是“others”
未拓展的ebnf是没有“非”定义的，从实操上虽然感觉可行（mask token取反），但这下已经没有支持了</p>
<p>（但ebnf解码肯定是有大用的，还是以Text2SQL举例，任何一个数据库都会给你他们的解析引擎的ebnf定义，都不需要你写）</p>
<p>怎么办呢，就带来了最后一个冷门工具，structured tags，
我先上代码，</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">get_structural_tag_params</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tags</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token builtin">list</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">StructuralTag</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> triggers</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token builtin">list</span><span class="token punctuation" style="color:#393A34">[</span><span class="token builtin">str</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token builtin">dict</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token string" style="color:#e3116c">"type"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"structural_tag"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token string" style="color:#e3116c">"structures"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model_dump</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> model </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> tags</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token string" style="color:#e3116c">"triggers"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> triggers</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_v2 </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> ChatOpenAI</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        base_url</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">base_url</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        model</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">model_name</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        api_key</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">api_key</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        temperature</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.15</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        top_p</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.9</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        extra_body</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token string" style="color:#e3116c">"response_format"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> get_structural_tag_params</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                tags</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    StructuralTag</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                        begin</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"&lt;block=text&gt;"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                        end</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"&lt;/block&gt;"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                        schema</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">TextMsgSchema</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model_json_schema</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    StructuralTag</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                        begin</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"&lt;block=image&gt;"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                        end</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"&lt;/block&gt;"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                        schema</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">ImageMsgSchema</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model_json_schema</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    StructuralTag</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                        begin</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"&lt;block=tool_use&gt;"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                        end</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"&lt;/block&gt;"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                        schema</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">ToolUseMsgSchema</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model_json_schema</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    StructuralTag</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                        begin</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"&lt;block=todo_list&gt;"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                        end</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"&lt;/block&gt;"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                        schema</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">TodoListMsgSchema</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model_json_schema</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    StructuralTag</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                        begin</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"&lt;block=html&gt;"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                        end</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"&lt;/block&gt;"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                        schema</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">HTMLMsgSchema</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model_json_schema</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                </span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                triggers</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">"&lt;block="</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>这个tags + triggers, 就是structured output的关键之处，它允许我们在trigger触发的时候才开始约束解码，在end结束的时候停止约束解码</p>
<p>至此，这个工作已经做完了</p>
<hr>
<p>那约束解码和不约束带来的效果差距有多大呢，我在24B的Mistral-Small上做了个实验
最后的结果直接尝试解析后渲染到前端</p>
<p>Prompt如下，</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sys_prompt = f"""</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">你是一个agent模型，你负责处理用户的问题，发起工具调用, 绘制图片、html、获取文本等。</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">由于你的token交互量很大，不是所有信息都需要展示给前端。</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">你可以正常思考和输出，但你需要将你认为需要展示给用户的有效信息包裹在 `&lt;block={{tag}}&gt; {{schema}} &lt;/block&gt;` 中。</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">前端会将这部分内容进行渲染，交给用户。</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">你现在可用的tag有:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tags: "text", "image", "tool_use", "todo_list", "html"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">对应的schema(pydantic格式)如下:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- {schemas_str}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">例如，你可以先产生一个todo list，然后不断执行子任务，并更新todo list，直到所有任务完成。</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">由于你现在没有接入工具调用，所以对于所有工具调用交互，你只需要“假装”执行了工具调用并得到一个合理的响应就行，这是一个debug环境，</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">你需要根据用户的问题尽可能多的展示不同的block，并给出一个合理的响应。</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">"""</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>这个prompt下，<code>&lt;block=text&gt;111&lt;/block&gt;</code> 这种就取代了上文所述的display块的效果</p>
<p>只定义了五种特殊的前端展示格式，文本，图片，TODO list，工具调用和HTML块</p>
<p>效果对比如下：</p>
<p>用户：帮我完成编写一个论坛帖子，打开浏览器的水源社区论坛，登录之后在discourse发帖的流程。</p>
<p><img decoding="async" loading="lazy" alt="alt text" src="https://ayanami1314.github.io/assets/images/image-10-57a8fd70dc61313b1baa8538ab00ca8f.png" width="1035" height="705" class="img_ev3q">
<img decoding="async" loading="lazy" alt="alt text" src="https://ayanami1314.github.io/assets/images/image-11-fea313f95fa94fb03b64d9ffb986bcdd.png" width="1035" height="742" class="img_ev3q">
<img decoding="async" loading="lazy" alt="alt text" src="https://ayanami1314.github.io/assets/images/image-12-fea313f95fa94fb03b64d9ffb986bcdd.png" width="1035" height="742" class="img_ev3q">
<img decoding="async" loading="lazy" alt="alt text" src="https://ayanami1314.github.io/assets/images/image-13-8da20497ce50bd4b1c67a14c8618f6ec.png" width="1035" height="744" class="img_ev3q"></p>
<p>可以看到，左侧没有约束解码的模型，在这样的任务负载下，json 参数就已经频频出现失误了，而右边的即使是24B模型的fp8量化非思考版本，却跑出了几百B agent的气势，并且token开销是来回倒腾的几分之一</p>
<hr>
<p>一点感想：
我们常说一个子领域的知识对于另一个子领域是用处寥寥的，然而，这不是拒绝新领域知识的理由啊，vllm和xgrammer、outlines这种框架都把几种更强大的结构化解码方法摆到人们的脸上了，还是能在知乎看到“ebnf好像是编译原理的内容，（作为后端程序员）跳过”，或者是在各种开源仓库中还在广泛使用的拿prompt指导llm输出，完全不考虑（甚至不知道）结构化输出这样的东西</p>
<p>现在的后端、infra、算法，又有多少更深的优化方案是独立的呢？今天在看snowflakes优化方案，真是把上层算法和底层infra相辅相成，只是缺乏探索性的人们，会拿"这不是我的工作，这是专攻模型/infra/算法的人的工作"搪塞，最后又堆起来一个prompt史山罢了</p>
<p>在现在的agent框架中，充斥的也是prompt的兜底方案，带来的是qwen3-coder几个问题爆掉用户百万token，带来的是claude code问个“你是谁”都要花一角钱，但有没有一种可能，我们本可以用更确定的东西呢？LLM是一种万能的模糊推理，但好钢也要用在刀刃上啊。</p>
<p>参考完整代码如下</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># ruff: noqa: E501</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># SPDX-License-Identifier: Apache-2.0</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># SPDX-FileCopyrightText: Copyright contributors to the vLLM project</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> argparse</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> asyncio</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> enum</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> json</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> os</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> re</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> pathlib </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> Path</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> typing </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> Any</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> colorlog</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> openai</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> langchain_core</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">messages </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> HumanMessage</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> SystemMessage</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> langchain_openai </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> ChatOpenAI</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> pydantic </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> BaseModel</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> Field</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> dotenv </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> load_dotenv</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">load_dotenv</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">class</span><span class="token plain"> </span><span class="token class-name">StructuralTag</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">BaseModel</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    begin</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token builtin">str</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    end</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token builtin">str</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    schema</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token builtin">dict</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token builtin">str</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> Any</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># JSON schema for validation, model_dump by pydantic model</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">class</span><span class="token plain"> </span><span class="token class-name">TextMsgSchema</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">BaseModel</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    text</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token builtin">str</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> Field</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> description</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"Text message"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">to_html</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token builtin">str</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token triple-quoted-string string" style="color:#e3116c">"""Render text message as HTML"""</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> </span><span class="token string-interpolation string" style="color:#e3116c">f'&lt;div class="text-message"&gt;</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">self</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">.</span><span class="token string-interpolation interpolation">text</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">&lt;/div&gt;'</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">class</span><span class="token plain"> </span><span class="token class-name">HTMLMsgSchema</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">BaseModel</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    raw_html</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token builtin">str</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> Field</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> description</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"raw html str, like &lt;div&gt;&lt;/div&gt;"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">to_html</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token builtin">str</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token triple-quoted-string string" style="color:#e3116c">"""Render HTML message as HTML"""</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> </span><span class="token string-interpolation string" style="color:#e3116c">f'&lt;div class="html-message"&gt;</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">self</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">.</span><span class="token string-interpolation interpolation">raw_html</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">&lt;/div&gt;'</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">class</span><span class="token plain"> </span><span class="token class-name">ImageMsgSchema</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">BaseModel</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    image_url</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token builtin">str</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> Field</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> description</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"Image URL"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    image_name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token builtin">str</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> Field</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> description</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"Image name"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">to_html</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token builtin">str</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token triple-quoted-string string" style="color:#e3116c">"""Render image message as HTML"""</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> </span><span class="token string-interpolation string" style="color:#e3116c">f"""&lt;div class="image-message"&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">            &lt;img src="</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">self</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">.</span><span class="token string-interpolation interpolation">image_url</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">" alt="</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">self</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">.</span><span class="token string-interpolation interpolation">image_name</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">" style="max-width: 100%; height: auto;"&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">            &lt;p class="image-caption"&gt;</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">self</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">.</span><span class="token string-interpolation interpolation">image_name</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">&lt;/p&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">        &lt;/div&gt;"""</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">class</span><span class="token plain"> </span><span class="token class-name">ToolUseMsgSchema</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">BaseModel</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tool_name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token builtin">str</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> Field</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> description</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"Tool name"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    args</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token builtin">dict</span><span class="token punctuation" style="color:#393A34">[</span><span class="token builtin">str</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> Any</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> Field</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> description</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"Tool args"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tool_output</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token builtin">dict</span><span class="token punctuation" style="color:#393A34">[</span><span class="token builtin">str</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> Any</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> Field</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> description</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"Tool output"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">to_html</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token builtin">str</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token triple-quoted-string string" style="color:#e3116c">"""Render tool use message as HTML"""</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        args_html </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> json</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">dumps</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">args</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> indent</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> ensure_ascii</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">False</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        output_html </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> json</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">dumps</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">tool_output</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> indent</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> ensure_ascii</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">False</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> </span><span class="token string-interpolation string" style="color:#e3116c">f"""&lt;div class="tool-use-message"&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">            &lt;h4&gt;Tool: </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">self</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">.</span><span class="token string-interpolation interpolation">tool_name</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">&lt;/h4&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">            &lt;div class="tool-args"&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">                &lt;strong&gt;Arguments:&lt;/strong&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">                &lt;pre&gt;</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">args_html</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">&lt;/pre&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">            &lt;/div&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">            &lt;div class="tool-output"&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">                &lt;strong&gt;Output:&lt;/strong&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">                &lt;pre&gt;</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">output_html</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">&lt;/pre&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">            &lt;/div&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">        &lt;/div&gt;"""</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">class</span><span class="token plain"> </span><span class="token class-name">TodoListMsgSchema</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">BaseModel</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    todo_list</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token builtin">list</span><span class="token punctuation" style="color:#393A34">[</span><span class="token builtin">tuple</span><span class="token punctuation" style="color:#393A34">[</span><span class="token builtin">bool</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token builtin">str</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> Field</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> description</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"Todo list"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">to_html</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token builtin">str</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token triple-quoted-string string" style="color:#e3116c">"""Render todo list message as HTML"""</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        items </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> done</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> item </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">todo_list</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            checked </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"checked"</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> done </span><span class="token keyword" style="color:#00009f">else</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">""</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            item_class </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"completed"</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> done </span><span class="token keyword" style="color:#00009f">else</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"pending"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            items</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">append</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                </span><span class="token string-interpolation string" style="color:#e3116c">f'&lt;li class="</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">item_class</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">"&gt;&lt;input type="checkbox" </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">checked</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c"> disabled&gt; </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">item</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">&lt;/li&gt;'</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        items_html </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"\n"</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">join</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">items</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> </span><span class="token string-interpolation string" style="color:#e3116c">f"""&lt;div class="todo-list-message"&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">            &lt;h4&gt;Todo List&lt;/h4&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">            &lt;ul class="todo-list"&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">                </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">items_html</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c"></span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">            &lt;/ul&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">        &lt;/div&gt;"""</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">get_structural_tag_params</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tags</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token builtin">list</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">StructuralTag</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> triggers</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token builtin">list</span><span class="token punctuation" style="color:#393A34">[</span><span class="token builtin">str</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token builtin">dict</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token string" style="color:#e3116c">"type"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"structural_tag"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token string" style="color:#e3116c">"structures"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model_dump</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> model </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> tags</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token string" style="color:#e3116c">"triggers"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> triggers</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">parse_structured_response</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">response</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token builtin">str</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token builtin">str</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token triple-quoted-string string" style="color:#e3116c">"""Parse structured response and convert blocks to HTML"""</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># Schema mapping</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    schema_classes </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token string" style="color:#e3116c">"text"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> TextMsgSchema</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token string" style="color:#e3116c">"image"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ImageMsgSchema</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token string" style="color:#e3116c">"tool_use"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ToolUseMsgSchema</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token string" style="color:#e3116c">"todo_list"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> TodoListMsgSchema</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token string" style="color:#e3116c">"html"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> HTMLMsgSchema</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">replace_block</span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">match</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        tag_type </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">match</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">group</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        content </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">match</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">group</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">strip</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> tag_type </span><span class="token keyword" style="color:#00009f">not</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> schema_classes</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">match</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">group</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># Return original if unknown tag</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">try</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token comment" style="color:#999988;font-style:italic"># Parse JSON content</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            data </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> json</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">loads</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">content</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token comment" style="color:#999988;font-style:italic"># Create schema instance</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            schema_instance </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> schema_classes</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">tag_type</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">(</span><span class="token operator" style="color:#393A34">**</span><span class="token plain">data</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token comment" style="color:#999988;font-style:italic"># Return HTML</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> schema_instance</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">to_html</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">except</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">json</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">JSONDecodeError</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> ValueError</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> e</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                </span><span class="token string-interpolation string" style="color:#e3116c">f'&lt;div class="error"&gt;Error parsing </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">tag_type</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c"> block: </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">e</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">&lt;/div&gt;'</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># Replace all &lt;block=type&gt;content&lt;/block&gt; with HTML</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    pattern </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">r"&lt;block=(\w+)&gt;\s*(.*?)\s*&lt;/block&gt;"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> re</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">sub</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">pattern</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> replace_block</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> response</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> flags</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">re</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">DOTALL</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">create_comparison_html</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">response1</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token builtin">str</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> response2</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token builtin">str</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token builtin">str</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token triple-quoted-string string" style="color:#e3116c">"""Create a comparison HTML page with both responses"""</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    parsed_response2 </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> parse_structured_response</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">response2</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    css </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token triple-quoted-string string" style="color:#e3116c">"""</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    &lt;style&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        body {</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            margin: 0;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            padding: 20px;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            background-color: #f5f5f5;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        .container {</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            max-width: 1200px;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            margin: 0 auto;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            background: white;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            border-radius: 8px;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            box-shadow: 0 2px 10px rgba(0,0,0,0.1);</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            overflow: hidden;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        .header {</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            background: #2563eb;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            color: white;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            padding: 20px;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            text-align: center;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        .comparison {</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            display: flex;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            min-height: 600px;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        .column {</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            flex: 1;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            padding: 20px;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            border-right: 1px solid #e5e5e5;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        .column:last-child {</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            border-right: none;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        .column h3 {</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            margin-top: 0;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            color: #1f2937;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            border-bottom: 2px solid #e5e5e5;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            padding-bottom: 10px;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        .content {</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            line-height: 1.6;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            color: #374151;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        </span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        /* Schema-specific styles */</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        .text-message {</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            background: #f8fafc;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            padding: 15px;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            border-radius: 8px;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            margin: 10px 0;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            border-left: 4px solid #3b82f6;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        .image-message {</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            background: #f0fdf4;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            padding: 15px;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            border-radius: 8px;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            margin: 10px 0;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            border-left: 4px solid #10b981;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            text-align: center;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        .image-caption {</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            margin: 10px 0 0 0;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            font-style: italic;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            color: #6b7280;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        .tool-use-message {</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            background: #fefce8;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            padding: 15px;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            border-radius: 8px;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            margin: 10px 0;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            border-left: 4px solid #eab308;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        .tool-use-message h4 {</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            margin: 0 0 10px 0;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            color: #92400e;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        .tool-args, .tool-output {</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            margin: 10px 0;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        .tool-args pre, .tool-output pre {</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            background: #1f2937;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            color: #f9fafb;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            padding: 10px;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            border-radius: 4px;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            overflow-x: auto;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        .todo-list-message {</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            background: #fdf2f8;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            padding: 15px;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            border-radius: 8px;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            margin: 10px 0;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            border-left: 4px solid #ec4899;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        .todo-list-message h4 {</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            margin: 0 0 10px 0;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            color: #be185d;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        .todo-list {</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            list-style: none;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            padding: 0;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        .todo-list li {</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            margin: 5px 0;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            padding: 5px 0;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        .todo-list li.completed {</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            text-decoration: line-through;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            opacity: 0.7;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        .html-message {</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            background: #f5f3ff;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            padding: 15px;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            border-radius: 8px;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            margin: 10px 0;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            border-left: 4px solid #8b5cf6;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        .error {</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            background: #fef2f2;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            color: #dc2626;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            padding: 15px;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            border-radius: 8px;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            margin: 10px 0;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            border-left: 4px solid #dc2626;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        pre {</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            white-space: pre-wrap;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">            word-wrap: break-word;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    &lt;/style&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    """</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> </span><span class="token string-interpolation string" style="color:#e3116c">f"""</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">    &lt;!DOCTYPE html&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">    &lt;html lang="zh-CN"&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">    &lt;head&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">        &lt;meta charset="UTF-8"&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">        &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">        &lt;title&gt;模型响应对比&lt;/title&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">        </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">css</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c"></span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">    &lt;/head&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">    &lt;body&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">        &lt;div class="container"&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">            &lt;div class="header"&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">                &lt;h1&gt;模型响应对比&lt;/h1&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">                &lt;p&gt;左侧：无结构化标签 | 右侧：带结构化标签（已渲染）&lt;/p&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">            &lt;/div&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">            &lt;div class="comparison"&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">                &lt;div class="column"&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">                    &lt;h3&gt;无 Structure Tag&lt;/h3&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">                    &lt;div class="content"&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">                        &lt;pre&gt;</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">response1</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">&lt;/pre&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">                    &lt;/div&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">                &lt;/div&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">                &lt;div class="column"&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">                    &lt;h3&gt;Structure Tag（已渲染）&lt;/h3&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">                    &lt;div class="content"&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">                        </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">parsed_response2</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c"></span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">                    &lt;/div&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">                &lt;/div&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">            &lt;/div&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">        &lt;/div&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">    &lt;/body&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">    &lt;/html&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">    """</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> __name__ </span><span class="token operator" style="color:#393A34">==</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"__main__"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    base_url </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"localhost:8000/v1"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> openai</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">OpenAI</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">base_url</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">base_url</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> api_key</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"sk-"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    schemas </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        TextMsgSchema</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model_json_schema</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ImageMsgSchema</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model_json_schema</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ToolUseMsgSchema</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model_json_schema</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        TodoListMsgSchema</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model_json_schema</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        HTMLMsgSchema</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model_json_schema</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    schemas_str </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"\n- "</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">join</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">json</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">dumps</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">s</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> indent</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">4</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> s </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> schemas</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    sys_prompt </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string-interpolation string" style="color:#e3116c">f"""</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">你是一个agent模型，你负责处理用户的问题，发起工具调用, 绘制图片、html、获取文本等。</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">由于你的token交互量很大，不是所有信息都需要展示给前端。</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">你可以正常思考和输出，但你需要将你认为需要展示给用户的有效信息包裹在 `&lt;block={{tag}}&gt; {{schema}} &lt;/block&gt;` 中。</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">前端会将这部分内容进行渲染，交给用户。</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="display:inline-block;color:#e3116c"></span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">你现在可用的tag有:</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">tags: "text", "image", "tool_use", "todo_list", "html"</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">对应的schema(pydantic格式)如下:</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">- </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">schemas_str</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c"></span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="display:inline-block;color:#e3116c"></span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">例如，你可以先产生一个todo list，然后不断执行子任务，并更新todo list，直到所有任务完成。</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">由于你现在没有接入工具调用，所以对于所有工具调用交互，你只需要“假装”执行了工具调用并得到一个合理的响应就行，这是一个debug环境，</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">你需要根据用户的问题尽可能多的展示不同的block，并给出一个合理的响应。</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="display:inline-block;color:#e3116c"></span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">    """</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    base_url </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"http://localhost:8000/v1"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_name </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"stelterlab/Mistral-Small-3.2-24B-Instruct-2506-FP8"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    api_key </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"sk-"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> ChatOpenAI</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        base_url</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">base_url</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        model</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">model_name</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        api_key</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">api_key</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        temperature</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.15</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        top_p</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.9</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"-"</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">50</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    logger </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> colorlog</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">getLogger</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"Agent"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    msgs </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        SystemMessage</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">content</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">sys_prompt</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        HumanMessage</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            content</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"帮我完成编写一个论坛帖子，打开浏览器的水源社区论坛，登录之后在discourse发帖的流程。"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_v2 </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> ChatOpenAI</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        base_url</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">base_url</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        model</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">model_name</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        api_key</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">api_key</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        temperature</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.15</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        top_p</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.9</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        extra_body</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token string" style="color:#e3116c">"response_format"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> get_structural_tag_params</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                tags</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    StructuralTag</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                        begin</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"&lt;block=text&gt;"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                        end</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"&lt;/block&gt;"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                        schema</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">TextMsgSchema</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model_json_schema</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    StructuralTag</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                        begin</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"&lt;block=image&gt;"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                        end</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"&lt;/block&gt;"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                        schema</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">ImageMsgSchema</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model_json_schema</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    StructuralTag</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                        begin</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"&lt;block=tool_use&gt;"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                        end</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"&lt;/block&gt;"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                        schema</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">ToolUseMsgSchema</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model_json_schema</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    StructuralTag</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                        begin</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"&lt;block=todo_list&gt;"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                        end</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"&lt;/block&gt;"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                        schema</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">TodoListMsgSchema</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model_json_schema</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    StructuralTag</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                        begin</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"&lt;block=html&gt;"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                        end</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"&lt;/block&gt;"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                        schema</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">HTMLMsgSchema</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model_json_schema</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                </span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                triggers</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">"&lt;block="</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    logger</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">info</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"=== 测试开始 ==="</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    response1 </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">invoke</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">msgs</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">content</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    logger</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">info</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string-interpolation string" style="color:#e3116c">f"=== 测试结束 ===\n</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">response1</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    logger</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">info</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"=== 测试开始 ==="</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    response2 </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> model_v2</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">invoke</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">msgs</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">content</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    logger</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">info</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string-interpolation string" style="color:#e3116c">f"=== 测试结束 ===\n</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">response2</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># 生成对比HTML文件</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    comparison_html </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> create_comparison_html</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">response1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> response2</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Path</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"tmp/test_comparison.html"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">write_text</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        comparison_html</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> encoding</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"utf-8"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    logger</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">info</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"已生成对比HTML文件: tmp/test_comparison.html"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># 保留原有的Markdown文件</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">with</span><span class="token plain"> Path</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"tmp/test_diff.md"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token builtin">open</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"w"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> encoding</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"utf-8"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> f</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        f</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">write</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"无structure tag: \n"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        f</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">write</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">response1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        f</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">write</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"\n\nstructure tag: \n"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        f</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">write</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">response2</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>]]></content:encoded>
            <category>rag</category>
            <category>ai</category>
            <category>llm</category>
            <category>agent</category>
        </item>
        <item>
            <title><![CDATA[context-engineering]]></title>
            <link>https://ayanami1314.github.io/blog/context-engineering</link>
            <guid>https://ayanami1314.github.io/blog/context-engineering</guid>
            <pubDate>Sun, 13 Jul 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[rag那边最近看到的新的概念，现在prompt工程不叫prompt工程了，叫上下文工程 （context engineering）,笑]]></description>
            <content:encoded><![CDATA[<p>rag那边最近看到的新的概念，现在prompt工程不叫prompt工程了，叫上下文工程 （context engineering）,笑</p>
<p>上下文工程概念的兴起主要是两个方面，一是更关注多轮和工具，prompt无法很好地概括这些部分，二是模型的能力并不能做到和声称的上下文一样（支持1M长度的模型，可能长度超过32K指标就会严重下滑）</p>
<p>上下文失败的几种情况，参考 How Long Contexts Fail | Drew Breunig</p>
<ul>
<li>上下文中毒: 幻觉和错误进入上下文，并反复引用，这个主要来源于google在用智能体玩游戏时出现的一些现象（超长程规划）</li>
</ul>
<blockquote>
<p>An especially egregious form of this issue can take place with “context poisoning” – where many parts of the context (goals, summary) are “poisoned” with misinformation about the game state, which can often take a very long time to undo. As a result, the model can become fixated on achieving impossible or irrelevant goals.</p>
</blockquote>
<ul>
<li>上下文干扰 &amp; 混淆
<strong>上下文干扰是指上下文变得太长，以致模型过度关注上下文，而忽略了在训练期间学到的内容。</strong></li>
</ul>
<blockquote>
<p>The Berkeley Function-Calling Leaderboard is a tool-use benchmark that evaluates the ability of models to effectively use tools to respond to prompts. Now on its 3rd version, the leaderboard shows that every model performs worse when provided with more than one tool4. Further, the Berkeley team, “designed scenarios where none of the provided functions are relevant…we expect the model’s output to be no function call.” Yet, all models will occasionally call tools that aren’t relevant.</p>
</blockquote>
<p>随着模型变小，问题变得越来越严重
<img decoding="async" loading="lazy" alt="alt text" src="https://ayanami1314.github.io/assets/images/image-1-bd7382632002af17cdb7cd3080d000f9.png" width="1033" height="451" class="img_ev3q"></p>
<p>问题是：<strong>如果你把某些东西放入上下文中, 模型就必须注意它。</strong> 它可能是无关的信息或不必要的工具定义，但模型会将其考虑在内。大型模型，尤其是推理模型，在忽略或丢弃多余上下文方面做得越来越好，但我们仍然看到无用的信息绊倒了智能体</p>
<p>关于信息之间和信息与问题的交互，google和其他机构都有不少的research paper，现在广泛认为，信息自己有几个“原子事实”不太重要，但信息之间的的一致性和独立性（相互cover不同部分以从根本解决信息冲突的问题）以及信息和query的相关性很重要</p>
<ul>
<li>上下文冲突
A Microsoft and Salesforce team documented this brilliantly in a <a href="https://arxiv.org/pdf/2505.06120" target="_blank" rel="noopener noreferrer">recent paper</a>.</li>
</ul>
<p><strong>分阶段提供信息，模型的表现严重下降</strong></p>
<blockquote>
<p>We find that LLMs often make assumptions in early turns and prematurely attempt to generate final solutions, on which they overly rely. In simpler terms, we discover that when LLMs take a wrong turn in a conversation, they get lost and do not recover. 我们发现，LLM 们经常在早期阶段做出假设，并过早地尝试得出最终解决方案，而他们过度依赖这些解决方案。简而言之，我们发现，当 LLM 们在对话中走错方向时，他们会迷失方向，无法恢复。</p>
</blockquote>
<p>Andrew Karpathy依然擅长炒作，他的观点是LLM as a new OS. Context is RAM</p>
<p>上下文工程：在上下文窗口中为下一步填充恰到好处的信息的科学</p>
<p>有哪些呢？</p>
<ul>
<li>Instructions</li>
<li>Knowledge</li>
<li>Tools</li>
</ul>
<p>上下文工程策略：写入上下文，选择上下文，压缩上下文，隔离上下文</p>
<p>写入上下文：</p>
<ul>
<li>临时笔记板，可以是会话的状态对象，也可以是简单的工具调用写文件
Anthropic 的研究表明，将“笔记板”工具与特定领域的提示配对使用可以带来显著的收益，与专业代理的基准相比，最高可提高 54%。这也称作上下文卸载（Context Offload）, 参考 The "think" tool: Enabling Claude to stop and think \ Anthropic</li>
</ul>
<p>Anthropic identified three scenarios where the context offloading pattern is useful:
Anthropic 确定了上下文卸载模式有用的三种场景：</p>
<blockquote>
<p>Tool output analysis. When Claude needs to carefully process the output of previous tool calls before acting and might need to backtrack in its approach;
Policy-heavy environments. When Claude needs to follow detailed guidelines and verify compliance; and
Sequential decision making. When each action builds on previous ones and mistakes are costly (often found in multi-step domains).</p>
</blockquote>
<ul>
<li>记忆：跨模型、跨会话，独立存储。Reflexion + 定期整理记忆</li>
</ul>
<p>选择上下文：</p>
<ul>
<li>记忆选择：Langchain将记忆归为几种类别：Semantic, Episodic, Procedural 对应 Facts，Experiences和Instructions，一个挑战是选择相关记忆。Claude Code使用CLAUDE.md，Cursor和Windsurf使用规则文件</li>
<li>工具管理：例如对工具list用RAG，这个在现在的MCP中很多都在尝试，比如OSPP就有这样的项目</li>
</ul>
<p>压缩上下文：Claude Code当交互占用超过上下文的95%之后，会自动压缩，总结用户-Agent的完整轨迹。可以是递归或者分层摘要。也可以在一些特定点添加摘要（如某些工具调用），Cognition为此使用微调模型
上下文修剪：启发式删除旧信息，provence作为上下文修剪器</p>
<p>隔离上下文：</p>
<ul>
<li>拆分到子Agent之间，OpenAI Swarm动机是关注点分离，一组Agent完成各自的子任务</li>
<li>工具代码沙箱</li>
</ul>
<p>LangGraph &amp; LangSmith</p>
<p>LangGraph 在记忆（状态）上面做了努力，选择 上下文也通过这个State获取，压缩上下文通过状态对象进行自定义逻辑，隔离通过子图和节点</p>
<p>LangGraph基于状态机的实现倒是<strong>暗合了OS=状态机的观点，从一个比较底层的视角上为各种上层应用提供了可能，也可以复用业界关于状态机的一系列优化已有实践</strong></p>
<hr>
<p>而关于上下文管理的评估侧，一个比较热门的评估和观测系统Galieo设置了四种指标来评估一个RAG应用: Adherence,Completness, Utilization,Attribution 对上文的忠实度，上文本身对解答这个问题的完整性，答案对于上文的利用度，答案对于不同chunk的归因</p>
<p>在它的博客之中，给了一个非常真知灼见的观点是，<strong>过多的指标本身没什么意义，它选择这四个指标的原因是能定位出是链路的哪一块出现了问题</strong>，这个指标也只有low, medium, high三级，不做复杂的打分，倒是有点像是推荐系统里面的分桶离散特征</p>
<p>例如，如果整体利用度低，但完整度高，那么冗余信息太多了，减少chunk size和输入LLM的chunk数量N；如果整体忠实度高，但完整度低，则需要考虑是搜索的问题（多样性考虑不够）还是数据的问题（根本就没有足够多的文档）；而归因性可以用来调整chunk size，裁剪等参数；忠实度不够则主要从prompt和chunk数量入手......</p>
<p>与其他一切最终被广泛利用的策略相同，Galieo也蒸馏了一个小BERT来代替昂贵的LLM进行打分，以此提供一个本地托管的方案</p>
<hr>
<p>另一个上下文管理的有趣的工作是直接进行暴力的token-level prompt压缩，来自微软的LLMLingua论文，其基于两个观察</p>
<ul>
<li>自然语言有冗余</li>
<li>传统的信息熵指标只有单向上下文, 且与提示压缩指标不一致
<img decoding="async" loading="lazy" alt="alt text" src="https://ayanami1314.github.io/assets/images/image-2-5a6fdb9c8bbde857712eaf96b6456ddb.png" width="1035" height="375" class="img_ev3q">
因此，开蒸！总之也是训了XLM-RoBERTa-large &amp; mBERT的模型替代LLM（可以发现现在的RAG基本就是 <code>寻找问题-大模型蒸馏训练-用专业小模型代替-形成nlp管道</code> 的范式，在几乎每一个组件都是如此，效果也好）</li>
</ul>]]></content:encoded>
            <category>llm</category>
            <category>rag</category>
        </item>
        <item>
            <title><![CDATA[从微调reranker到搜推工程实践]]></title>
            <link>https://ayanami1314.github.io/blog/从微调reranker到搜推</link>
            <guid>https://ayanami1314.github.io/blog/从微调reranker到搜推</guid>
            <pubDate>Sun, 13 Jul 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[如何进行reranker微调？]]></description>
            <content:encoded><![CDATA[<p>如何进行reranker微调？</p>
<p>之前我曾经花了一定时间找这个问题的经验，结果发现大部分reranker模型对于这个问题是一个回避状态，不愿意开源自己的训练集，更不提像OpenAI/Cohere的rerank/embed服务本身就在卖钱，而兜售rag解决方案的公司，更不肯将如何做领域适配这一赚钱核心逻辑公之于众</p>
<p>也就BAAI以一个非常开放的态度，公开了自己的微调方法和相关脚本和训练数据，但他们也更侧重与如何训练一个通用的模型，对于怎么微调，只知道构造正负样本，query，pos，neg，然后InfoNCE，至于为什么能work，pos/neg怎么选，可能觉得大家都知道，也没有多说</p>
<p>而兜兜转转的楼主最后在传统搜推里面找到了一整套硬负例挖掘方面的方案，rag整套方案其实都是抄搜推的一个劣化版本罢了 <!-- -->🤣</p>
<p>为什么采用的是正负对而不是交叉熵或者其他有label的损失？核心在于，搜推本身就是一个弱label的场景</p>
<p>乍一想，在有正负对的情况下的时候，交叉熵似乎也很自然，以01为例，两种损失项就是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>&lt;</mo><mi>u</mi><mi>s</mi><mi>e</mi><mi>r</mi><mo separator="true">,</mo><mi>i</mi><mi>t</mi><mi>e</mi><msub><mi>m</mi><mo>+</mo></msub><mo separator="true">,</mo><mn>1</mn><mo>&gt;</mo><mtext>，</mtext><mo>&lt;</mo><mi>u</mi><mi>s</mi><mi>e</mi><mi>r</mi><mo separator="true">,</mo><mi>i</mi><mi>t</mi><mi>e</mi><msub><mi>m</mi><mo>−</mo></msub><mo separator="true">,</mo><mn>0</mn><mo>&gt;</mo></mrow><annotation encoding="application/x-tex">&lt;user, item_+, 1&gt;， &lt;user, item_-, 0&gt;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8679em;vertical-align:-0.2083em"></span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.02778em">ser</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2583em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em"></span><span class="mord cjk_fallback">，</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8679em;vertical-align:-0.2083em"></span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.02778em">ser</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2583em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&gt;</span></span></span></span> ? 但一个随之而来的问题是哪来的01 label?</p>
<p>也就是说，这样做的前提是label的准确性，而在搜推场景中，负样本 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>&lt;</mo><mi>u</mi><mi>s</mi><mi>e</mi><mi>r</mi><mo separator="true">,</mo><mi>i</mi><mi>t</mi><mi>e</mi><msub><mi>m</mi><mo>−</mo></msub><mo separator="true">,</mo><mn>0</mn><mo>&gt;</mo></mrow><annotation encoding="application/x-tex">&lt;user, item_-, 0&gt;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8679em;vertical-align:-0.2083em"></span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.02778em">ser</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2583em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&gt;</span></span></span></span> 的一个设置是<strong>曝光过</strong>但没被user选择的真负样本</p>
<p><strong>但召回层的大部分样本根本没被曝光过，label噪声很大</strong>（召回层是一个<code>几亿-&gt;几千-&gt;几十条</code>的过程，只有最后的几十被曝光了），如果只依赖这样的负样本的话，根本无法支撑模型训练。所以正负样本的设计某种意义上是无奈之举，我无法知道这个样本和用户的真实关系，但我可以从用户的行为中得到一些偏好信号，召回算法往往采用Pairwise LearningToRank （LTR），建模排序的相对准确性，模型的优化目标变成正样本匹配度高于负样本匹配度</p>
<hr>
<p>现在我们知道了为什么采用正负样本，但真正上手就会发现，正负样本这一件事并没有想象中的简单。</p>
<p>如果你采用随机的语料作为负样本，带来的一个问题是这个负样本对模型太easy了，模型只能区分猫和狗，但无法区分哈士奇和狼狗，即忽视了细节信息，也即是我们所说的rag的领域细节的缺失</p>
<p>而解决的方法，也在搜推里面早就提出了，硬负样本挖掘，即设置一部分的硬负样本，这部分是有难度的，来迫使模型学会根据细节进行区分</p>
<p>而在rag里面大家常常是拍脑门的硬负样本设计，让reranker带上一些业务目标，在搜推里面也早是被玩烂的东西了。</p>
<p>先说业务目标：
比起rag中，大部分的应用还局限在文本相似度，搜推早就进入到多个因素的融合和全链路目标指向的优化，例如，很多搜推业务需要考虑地域性（如外卖，酒店等），于是其正负样本会这样设计:
有基于业务逻辑的，核心是增强某个指标的相似性，让模型考虑其他指标做出区分，以房屋销售为例</p>
<ul>
<li>增加与正样本同城的房间作为负样本，增强了正负样本在地域上的相似性，加大了模型的学习难度</li>
<li>增加“被房主拒绝”作为负样本，增强了正负样本在“匹配用户兴趣爱好”上的相似性，加大了模型的学习难度</li>
</ul>
<p>针对模型只学地域特征信息就可以进行打分的easy neg，设计了同城的hard neg强迫考虑其他特征</p>
<blockquote>
<p>绝大部分负样本还是随机采样生成的。但是，Airbnb发现，用户点击序列中的listing多是同城的，导致正样本多是同城listing组成，而随机采样的负样本多是异地的，这其中存在的bias容易让模型只关注“地域”这个粗粒度特征。</p>
</blockquote>
<p>为此，Airbnb在全局随机采样生成的负样本之外，还在与中心listing同城的listing中随机采样一部分listing作为hard negative，以促使模型能够关注除“地域”外的更多其他细节。</p>
<p>在电商场景下，负样本的业务构造也有很多：</p>
<ul>
<li>正样本：<strong>充足曝光</strong>下<strong>高点击ctr</strong>样本(如：ctr大于同query下商品点击率平均值)</li>
<li>负样本：<!-- -->
<ul>
<li>同父类目的<strong>邻居子类目</strong>负采样。</li>
<li><strong>高曝光低点击</strong>类目样本：同一个query搜索下，根据全局点击商品的类目分布，取相对超低频类目样本作为负样本。</li>
<li>充足曝光情况下，低于相应query平均曝光点击率一定百分比的样本做负样本。</li>
<li><strong>基于query核心term替换构造负样本</strong>：如，对于“品牌A+品类”结构的Query，使用“品牌B+品类”结构的query做其负样本。（这个lz当时在propilot构造领域词替换负样本的时候还觉得自己想到了个好方法，后来发现是早有之事）</li>
<li>随机构造负样本：为增加随机性，该部分实现可在训练时使用同batch中其他样本做负样本，同时也可以引入经典的Hard Sample机制。（这部分涉及到很有趣的一个问题，后面讲）</li>
</ul>
</li>
</ul>
<p>不局限于业务，搜推还对RAG很少涉及的“如何选择hard neg”上面有非常久远的研究，如</p>
<ul>
<li>
<p><strong>高置信样本挖掘</strong>，避免搜索点击行为日志“点击但不相关”的问题。</p>
</li>
<li>
<p>**定制化的负样本构造，避免模型收敛过快，**只能判断简单语义相关性，对难样本无法很好的区分。</p>
</li>
<li>
<p>关于短文本的定制化需求， 如美团提到的他们实践的一些难Case，“大提琴”→“小提琴”以及“葡萄酒”→“葡萄”这类字面编辑距离小的case，会根据搜索结果做分析，以搜索无结果作为bad case进行负样本生成
<img decoding="async" loading="lazy" alt="alt text" src="https://ayanami1314.github.io/assets/images/image-3-1080a39cbad8a7c3ac098ea6b66b06ea.png" width="1035" height="472" class="img_ev3q"></p>
</li>
<li>
<p>知识图谱也是被玩烂的东西
<img decoding="async" loading="lazy" alt="alt text" src="https://ayanami1314.github.io/assets/images/image-4-f1570be63e9ddb8c41317a41f2d6178d.png" width="1035" height="513" class="img_ev3q"></p>
</li>
<li>
<p>图结构也是被玩烂的东西，如在Pinterest中，基于GCN的PinSAGE</p>
</li>
</ul>
<blockquote>
<p>和Airbnb一样，我们可以认为被同一个user消费过的两个item是相似的，但是这样的<strong>排列组合太多了</strong>。</p>
<p>为此，PinSAGE采用<strong>随机游走的方式进行采样</strong>：在原始的user-item二部图上，以某个item作为起点，进行一次二步游走（<strong>item→user→item</strong>），首尾两端的item构成一条边。将以上二步游走反复进行多次，就构成了item-item同构图。</p>
<p><strong>在这个新构建出来的item-item同构图上，每条边连接的两个item，因为被同一个user消费过，所以是相似的，构成了训练中的正样本。</strong></p>
</blockquote>
<blockquote>
<ul>
<li>在训练开始前，<!-- -->
<ul>
<li>从item-item图上的某个节点u，随机游走若干次。</li>
<li>游走过程中遍历到的每个节点v，都被赋予一个分数L1-normalized visit count=该节点被访问到的次数 / 随机游走的总步数。</li>
<li>这个分数，被视为节点v针对节点u的重要性，即所谓的Personal PageRank（PPR）。</li>
</ul>
</li>
<li>训练过程中<!-- -->
<ul>
<li>针对item-item同构图上的某一条边u→v，u和v就构成了一条正样本，它们的embedding应该相近</li>
<li>在图上所有节点中随机采样一部分ne，u和每个ne就构成了一条负样本，它们的embedding应该比较远。因为是随机采样得到的，所以ne是easy negative。</li>
<li>除此之外，还将u所有的邻居，按照它们对u的重要性（PPR）从大到小排序，筛选出排名居中（e.g.论文中是2000~5000名）的那些item。<strong>这些item与u有几分相似，但是相似性又没那么强</strong>，从中再抽样一批item，作为"u"的hard negative。</li>
</ul>
</li>
</ul>
</blockquote>
<p>....</p>
<ul>
<li>利用传统nlp思路的</li>
</ul>
<p>在airbnb中，用户的点击序列，如果用类似word2vec+窗口的想法看成是一个“共现”问题的话，<strong>用户点击序列中的项的不像语言那样有一个很明显的长程衰减，embedding都应该是相近的</strong>。
但这样的组合太多，所以回退到窗口的方式，拿中心项和邻居项组成正样本对。<strong>但因为最后一次下单的点击有最强的业务信号，所以拿它和整个序列的每一项组成正样本对</strong>，“增加final booked listing作为global context加入每个滑窗”</p>
<hr>
<p>解决了如何构造硬负样本的问题，那应该选择多少硬负样本呢？如果自己跑过reranker的微调就会知道，<strong>过高的硬负样本比例甚至会让模型崩掉</strong>。而<strong>更是有拿调reranker的数据集拿来调embedder的神人</strong>（<strong>没错，就是我自己）</strong>，BAAI官方的脚本中，这俩也没啥区别 <!-- -->🤣</p>
<p>然而，早在N年前Facebook的文章中，就给出了他们的经验教训</p>
<ol>
<li><strong>将比例维持在easy<!-- -->:hard<!-- -->=100:1</strong></li>
<li><strong>将rerank的数据拿来训embed</strong>(在搜推场景中是拿曝光未点击数据（rerank前列但未收到信号）来当召回（embed）的负样本)是<strong>完全错误的实践</strong>，离线数据可能不错但一上线就是一坨</li>
</ol>
<p>这是为什么呢？因为<strong>召回不同于排序</strong>，在rag层要处理的文档没有那么多可能无感知，很多rag甚至没有排序层拿召回当排序，先下结论</p>
<blockquote>
<p><strong>如果说排序是特征的艺术，那么召回就是样本的艺术，特别是负样本的艺术</strong>。样本选择错了，那么上述的模型设计、特征工程，只能是南辕北辙，做得越卖力，错得越离谱。</p>
</blockquote>
<p><img decoding="async" loading="lazy" alt="alt text" src="https://ayanami1314.github.io/assets/images/image-5-f3c6027317adb48531c852e8957f15df.png" width="1035" height="639" class="img_ev3q">
<img decoding="async" loading="lazy" alt="alt text" src="https://ayanami1314.github.io/assets/images/image-6-e3a69dcc67eccd69df285e7afbd85b32.png" width="1035" height="679" class="img_ev3q"></p>
<p>明白了这个数据分布的区别之后，就会对前面硬负样本和简单样本的比例在不同阶段是不同的这一个特点有更深的理解，对于召回而言</p>
<blockquote>
<p><strong>hard negative并非要替代easy negative，而是easy negative的补充。在数量上，负样本还是以easy negative为主，文章中经验是将比例维持在easy<!-- -->:hard<!-- -->=100:1。毕竟线上召回时，库里绝大多数的物料是与用户八杆子打不着的easy negative，保证easy negative的数量优势，才能hold住模型的及格线。</strong></p>
</blockquote>
<p>所以，全样本随机采样的负例才会很重要</p>
<p>而推荐甚至走的更远好几步，例如，随机采样不等于等概率采样，推荐系统中会出现放大的效应，即热门的样本会更容易被点击，进而各种指标特征表现更高，变得更热门，为了不然模型退化到只推荐一类样本，<strong>在实践之中会对热门正样本降采样，对热门负样本升采样</strong></p>
<p>还有对硬负样本带来的<strong>左脚踩右脚</strong></p>
<blockquote>
<p>当业务逻辑没有那么明显的信号的时候，就需要依赖模型自己挖掘, <strong>都是用上一版本的召回模型筛选出没那么相似的对，作为额外负样本，训练下一版本召回模型。怎么定义“没那么相似”？文章中是拿召回位置在101~500上的物料</strong></p>
</blockquote>
<blockquote>
<p>Q: 这样选择出来的hard negative已经被当前模型判断为“没那么相似”了，那拿它们作为负样本训练模型，还能提供额外信息吗
A: 上一版本中，这批样本只是相似度靠后，现在直接划为负样本，能更迫使模型进行区分</p>
</blockquote>
<p>而rag在玩的全链路RL优化，是推荐系统几年前玩了一波后来又扔到垃圾桶的东西 <!-- -->🤣<!-- -->性能不稳定，模拟和实测差距大，等等问题</p>
<p>包括现在在rag系统的reranker中还未广泛见到的刷点技巧，对不同难度级别的负例单独训小模型，然后做embedding融合</p>
<hr>
<p>在工程性上，RAG的路也更像是把所有搜推的路再走一遍，</p>
<ul>
<li>
<p>如何解决冷启动问题？搜推已经证明了LR,FM这种一二阶特征就能得到一个不错的基线，并且可以将实数特征离散化，排0存储，排0计算进行O(N^2)到O(N)再二值化化乘为加得到在线级别的性能（用户每一次交互都是一次特征计算）</p>
</li>
<li>
<p>如何解决系统效率问题？网络上参数服务器+只传递特征id，实数特征的分桶离散化，特征的Field级别合并减少NN的维度，log的一套大数据系统+redis冷热缓存+bloomfilter+......</p>
</li>
<li>
<p>如何解决模型性能问题？在召回层禁止特征交叉，在排序层卷一系列现代架构，根据短文本特点进行深度语义层的裁剪，量化和蒸馏</p>
</li>
<li>
<p>如何解决可解释性问题？用加权的ML模型做基线，bad case定位和迭代，先把神经网络丢一边......</p>
</li>
<li>
<p>意图识别？训练NER任务，对查询做成分识别，丢掉不重要的词，在少无结果的时候做多级检索，甚至能把时延卷到10ms量级。BERT结合KG做领域词级别的mask而不是字符级别的mask，来达到对整个实体级别语义的理解效果
<img decoding="async" loading="lazy" alt="alt text" src="https://ayanami1314.github.io/assets/images/image-7-f390a8b5f5a101e61e0033fdff5b2103.png" width="1035" height="445" class="img_ev3q"></p>
</li>
<li>
<p>多样性？召回通道的消重系统
<img decoding="async" loading="lazy" alt="alt text" src="https://ayanami1314.github.io/assets/images/image-8-c365ab97b0f1b9dafc9bff82dc4c8058.png" width="1035" height="510" class="img_ev3q"></p>
</li>
<li>
<p>商业化？精排的广告插入......</p>
</li>
<li>
<p>规模化? 一键训推平台，业务算法提交数据后集群分卡自动运行和效果验证</p>
</li>
<li>
<p>稀疏样本？酒店这种看重订单率而不是相关性的就是最好的参考实践
<img decoding="async" loading="lazy" alt="alt text" src="https://ayanami1314.github.io/assets/images/image-9-18d5c0f90233ec3b9291ca350e43aec7.png" width="1035" height="433" class="img_ev3q"></p>
</li>
</ul>
<p>现在传统RAG发现一个问题就是半结构化数据很难被embedding模型处理，但如果从这个角度反向想回去的话，搜推一直就是在处理结构化数据啊，还是走同一套特征离散化的逻辑，后面做Pooling和特征融合又可以复用各种实践，</p>
<blockquote>
<ul>
<li>普通的Mean/Max Pooling，代表算法YoutubeNet，先embedding再pooling</li>
<li>Neural FM中，让属于同一field的feature embedding两两交叉，完成所谓的Bi-Interaction Pooling</li>
<li>加权平均 - Attention, 阿里Deep Intereset Network (DIN)，计算candidate item和用户各历史item的attention score，再根据这个score加权历史item的embedding，表示用户的历史偏好，<strong>使得用户的向量表达随着不同的candidate变化</strong></li>
<li>加权+时序，DIEN</li>
</ul>
</blockquote>
<hr>
<p><strong>所以，我们真的需要一个劣化的RAG系统吗？很多时候只是我们维护不起一套完整的搜推系统罢了，没有人力和体系力量去维护一个结构化的数据组，AB test和实时的线上反馈，又不在意系统的时延，吹嘘着LLM神话，消耗着大量的token，最后效果也就那样，还得根据线上信号进行优化，做来做去发现前人早就做过了（笑）</strong>。</p>
<p>但是anyway，如果你需要做点rag的话，搜推这边的方法可能需要大规模人力物力不一定能用得上，但这边踩过的坑，再踩一次就是猪头了,也算是理解了为啥网上有做搜推的转RAG讲说从LLM转过来的完全不理解上线难点在哪里，会踩很多坑，或者永远停留在离线的状态</p>]]></content:encoded>
            <category>rag</category>
            <category>搜广推</category>
        </item>
        <item>
            <title><![CDATA[部分llm技术报告的阅读]]></title>
            <link>https://ayanami1314.github.io/blog/llm-tech-report</link>
            <guid>https://ayanami1314.github.io/blog/llm-tech-report</guid>
            <pubDate>Mon, 30 Jun 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[Qwen]]></description>
            <content:encoded><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="qwen">Qwen<a class="hash-link" aria-label="Direct link to Qwen" title="Direct link to Qwen" href="https://ayanami1314.github.io/blog/llm-tech-report#qwen">​</a></h2>
<p>base model: 3 trillion tokens 三万亿</p>
<p>数据处理</p>
<p>预训练：公共文档，书籍，代码</p>
<p>HTML中提取文本，语言识别工具确定语言</p>
<p>增加多样性: MinHash/LSH 模糊去重</p>
<p>过滤低质量数据：rule-base/ML方法（语言模型，文本质量评分模型，内容审查模型）</p>
<p>进一步提高性能：高质量instruction数据集</p>
<p>tokenization: BPE byte pair encoding</p>
<p>cl100k base作为起点</p>
<p>最终152k词汇量</p>
<ul>
<li>embedding: 解绑定的embedding方法，而不是绑定embedding和输出projection的权重 <code>-&gt;</code> 内存换性能(why)</li>
<li>position embedding: RoPE fp32精度</li>
<li>Bias: 只有attention的QKV有</li>
<li>PreNorm &amp; RMSNorm 提高训练稳定性，替代传统layer norm, <code>prenorm &gt; post-norm</code></li>
<li>activation function: SwiGLU</li>
</ul>
<p>训练：上下文2048， flash attn, AdamW, 余弦学习率，最小为10%峰值，bf16混合精度训练</p>
<p>上下文长度拓展：在推理时做，训练时长上下文O(N^2)开销太大，NTK-aware interpolation</p>
<p>另外两个注意力机制： LogN-Scaling and window attention</p>
<p>sft对齐： ChatML-style format</p>
<blockquote>
<p>该模型的训练过程采用AdamW优化器，具有以下超参数：β1设置为0.9，β2设置为0.95，(<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">ϵ</span></span></span></span>)设置为(<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>8</mn></mrow></msup></mrow><annotation encoding="application/x-tex">10^{-8}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">8</span></span></span></span></span></span></span></span></span></span></span></span>).
序列长度限制为2048，batch size为128.
该模型总共经过4000步，学习率在前1430步逐渐增加，达到峰值<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>2</mn><mo>×</mo><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>6</mn></mrow></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(2 \times 10^{-6})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">6</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>.
为了防止过拟合，应用权重衰减，值为0.1，dropout设置为0.1，梯度裁剪强制限制为1.0.</p>
</blockquote>
<p>sft泛化和创造性的限制，容易过拟合 <code>-&gt;</code> RLHF</p>
<p>PPO</p>
<p>tool-use造数据：左脚踩右脚，让Qwen生成更多示例相关的查询、特定格式的输出，应用规则+人工过滤产生训练样本，之后SFT</p>
<p>代码模型：继续预训练，900亿tokens + 8192长上下文</p>
<p>数学模型：1024上下文，数学问题较短加快训练速度</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="qwen25">Qwen2.5<a class="hash-link" aria-label="Direct link to Qwen2.5" title="Direct link to Qwen2.5" href="https://ayanami1314.github.io/blog/llm-tech-report#qwen25">​</a></h2>
<p><img decoding="async" loading="lazy" alt="下载" src="https://ayanami1314.github.io/assets/images/%E4%B8%8B%E8%BD%BD-1745649858627-2-b6ea4d70a606a49448fe3b259d76d0d8.png" width="942" height="314" class="img_ev3q"></p>
<p>预训练 18万亿tokens</p>
<p>大于100w样本的sft，多阶段强化学习</p>
<p>有效KVcache利用：GQA Group Query Attention</p>
<p>MoE架构：将标准FFN层替换为专门MoE层，每一层包括多个FFN专家和一个路由，路由将tokens分派给topk专家</p>
<p>tokenization从BPE升级到BBPE, 控制token增加</p>
<p>做数据：</p>
<ol>
<li>
<p>更好的数据过滤</p>
</li>
<li>
<p>更好的数学和代码数据，在预训练就加</p>
</li>
<li>
<p>更好的合成数据，数学/代码/知识模型生成 + 奖励模型过滤</p>
</li>
<li>
<p>平衡样本分布</p>
</li>
</ol>
<blockquote>
<p>电子商务、社交媒体和娱乐等领域在网络规模数据中明显过度表示，通常包含重复的、基于模板的或机器生成的内容。
相反，技术、科学和学术研究等领域虽然包含更高质量的信息，但传统上代表性不足。
通过对过度表示的领域进行战略性降采样，以及对高价值领域进行升采样</p>
</blockquote>
<p>长上下文拓展：</p>
<p>最终预训练 4k <code>-&gt;</code> 32k， RoPE 10k<code>-&gt;</code>1000k</p>
<p>渐进式拓展</p>
<p>32k<code>-&gt;</code>64k<code>-&gt;</code>128k<code>-&gt;</code>256k</p>
<p>每一个截断包含40%的长序列和60%的短序列，避免遗忘</p>
<p>YARN + Dual Chunk Attention 降低困惑度来改善长序列推理性能</p>
<p>两阶段RL：</p>
<blockquote>
<p>• Offline RL：此阶段侧重于开发奖励模型难以评估的能力，例如推理、事实性和 instruction-following。
通过对训练数据进行细致的构建和验证，我们确保 Offline RL 信号既可学习又可靠 (Xiang et al., 2024)，使模型能够有效地获得这些复杂技能。</p>
<p>• Online RL：Online RL 阶段利用奖励模型检测输出质量细微差别的能力，包括真实性、helpfulness、简洁性、相关性、harmlessness 和 debiasing。
它使模型能够生成精确、连贯且结构良好的响应，同时保持安全性和可读性。
因此，模型的输出始终符合人类的质量标准和期望。</p>
</blockquote>
<p>长上下文：准备long-response dataset：从pre-training data中生成long-text数据对应的长查询，并使用Qwen2过滤低质量data</p>
<p>数学：CoT + 拒绝采样 + reward model/annotated answer</p>
<p>编码：code-related QA web 合成示例，github收集snippet, sandbox code checking， 自动单元测试保证正确性</p>
<p>指令准随：利用可严格验证的code来做，拒绝采样</p>
<p>结构化数据：table QA/fact verification/error correct... 造数据集然后训</p>
<p>逻辑推理：70000个新query迭代改进</p>
<p>回复过滤：多智能体协作评分系统</p>
<p>离线rl， 客观查询领域，数学/编码/逻辑推理/指令追随， 确保回复的质量，只有通过质量检查的才是正示例，其他回答全是负示例</p>
<p>在线rl,  真实性，帮助性，简洁性，相关性，无害性和去偏见</p>
<p>GRPO, 先训response分数方差较高的query</p>
<p>当前的reward model评估benchmark无法准确预测在其指导下训练的RL模型的性能</p>
<hr>
<h1>Qwen3 Embedding</h1>
<p>多阶段训练流程: 大规模无监督训练, 高质量数据集有监督微调</p>
<p>qwen3 产生高质量、多语言、多任务的文本相关性数据集，在无监督阶段利用，筛选出部分高质量用于有监督训练</p>
<p>Embedding， Instruction + query，之后直接**[EOS]**， 最后的嵌入是这个EOS对应的最后一层隐藏状态</p>
<p>Reranking, Instruction + query + doc，之后是<strong>Assistant:</strong></p>
<p><img decoding="async" loading="lazy" alt="image-20250629132905912" src="https://ayanami1314.github.io/assets/images/image-20250629132905912-4b2e0912d969098d3ab83a4caa1913cd.png" width="1209" height="490" class="img_ev3q"></p>
<p>为了嵌入的统一，instruction和query会拼接成同一个输入，<code>{Instruction} {Query}&lt;|endoftext|&gt;</code></p>
<p>重排: **pointwise，二分类问题，**遵循以下模板，实际相关性分数是<code>yes|no</code>的logits</p>
<p><img decoding="async" loading="lazy" alt="image-20250629133305609" src="https://ayanami1314.github.io/assets/images/image-20250629133305609-e9f8eac0c1593ef94e84cb3023f2b998.png" width="1302" height="481" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" alt="image-20250629133428708" src="https://ayanami1314.github.io/assets/images/image-20250629133428708-89f8ca290a70627bd64f65846edf30d8.png" width="634" height="154" class="img_ev3q"></p>
<p>使用InfoNCE作为损失函数</p>
<p><img decoding="async" loading="lazy" alt="image-20250629133536398" src="https://ayanami1314.github.io/assets/images/image-20250629133536398-9e7b7acd00845f4e2f591ea722bab3e4.png" width="1323" height="421" class="img_ev3q"></p>
<p><strong>qwen3采用批内负采样</strong></p>
<p>即，在实际对比学习（尤其是检索任务）中，为了训练出区分能力强的模型，负样本非常关键。但生成或采样足够丰富且高质量的负样本往往代价很高或不现实。</p>
<p>因此，常用的做法是：</p>
<ul>
<li><strong>批内负采样（In-batch Negative Sampling）</strong>：利用当前训练批次中其他样本的 query <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">q_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span>、正样本 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mrow><mi>j</mi><mo>+</mo></mrow></msub></mrow><annotation encoding="application/x-tex">d_{j+}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span><span class="mord mtight">+</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span>以及负样本 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mrow><mi>j</mi><mo>−</mo></mrow></msub></mrow><annotation encoding="application/x-tex">d_{j-}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span><span class="mord mtight">−</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span>作为当前样本<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">q_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>的负样本补充。</li>
</ul>
<p>因为batch是随机取的，所以为了避免批内负采样形成错误信号，需要在<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mi>j</mi></msub><mo separator="true">,</mo><msub><mi>d</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">{q_j,d_j}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span>中把实际是正样本的部分筛选掉，就是下面的掩码因子</p>
<p><img decoding="async" loading="lazy" alt="image-20250629133751623" src="https://ayanami1314.github.io/assets/images/image-20250629133751623-d307f26a0bb9875f6cb7abbce687087e.png" width="1320" height="328" class="img_ev3q"></p>
<p>减轻false negative的影响</p>
<p>认为是错负例的：</p>
<ol>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>j</mi></msub><mi mathvariant="normal">/</mi><msub><mi>q</mi><mi>j</mi></msub><mo>=</mo><msub><mi>d</mi><mrow><mi>i</mi><mo>+</mo></mrow></msub></mrow><annotation encoding="application/x-tex">d_j/q_j = d_{i+}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mord">/</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.9028em;vertical-align:-0.2083em"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mtight">+</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span></span></span></span>的</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>i</mi><mi>m</mi><mo stretchy="false">(</mo><msub><mi>d</mi><mi>j</mi></msub><mi mathvariant="normal">/</mi><msub><mi>q</mi><mi>j</mi></msub><mo separator="true">,</mo><msub><mi>q</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>&gt;</mo><mi>s</mi><mi>i</mi><mi>m</mi><mo stretchy="false">(</mo><msub><mi>d</mi><mrow><mi>i</mi><mo>+</mo></mrow></msub><mo separator="true">,</mo><msub><mi>q</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mn>0.1</mn></mrow><annotation encoding="application/x-tex">sim(d_j/q_j, q_i) &gt; sim(d_{i+}, q_i) + 0.1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">im</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mord">/</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">im</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mtight">+</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.1</span></span></span></span>的，即这个批内负样本比正样本还相似度高0.1以上，这个0.1可能是考虑到初期时数值的稳定性加的</li>
</ol>
<p>此时掩码为0，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>e</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>d</mi><mi>d</mi><mi>i</mi><mi>n</mi><mi>g</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{embedding}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">mb</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">dd</span><span class="mord mathnormal mtight">in</span><span class="mord mathnormal mtight" style="margin-right:0.03588em">g</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span>的这一项是0，即不考虑这一项作为负样本</p>
<p>比起用if-else等前筛选方法，这个后筛选方法方便并行化，由于预计假负样本应该是比较少的，所以能提高效率</p>
<p>对于rerank, 定义SFT loss <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>r</mi><mi>e</mi><mi>r</mi><mi>a</mi><mi>n</mi><mi>k</mi><mi>i</mi><mi>n</mi><mi>g</mi></mrow></msub><mo>=</mo><mo>−</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>p</mi><mo stretchy="false">(</mo><mi>l</mi><mi mathvariant="normal">∣</mi><mi>P</mi><mo stretchy="false">(</mo><mi>q</mi><mo separator="true">,</mo><mi>d</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L_{reranking} = -log p(l| P(q,d)) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">rer</span><span class="mord mathnormal mtight">ankin</span><span class="mord mathnormal mtight" style="margin-right:0.03588em">g</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">−</span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em">g</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">d</span><span class="mclose">))</span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.01968em">l</span></span></span></span>对正面文档是"yes", 负面是"no"</p>
<p>创新点：</p>
<ol>
<li>大规模合成数据，直接使用qwen3的合成数据而不是收集qa pair</li>
<li>高质量合成数据在SFT中的利用</li>
<li>模型合并：基于球面线性插值(slerp)对微调的多个ckpt进行合并，提升不同数据分布下的鲁棒性和泛化</li>
</ol>
<p><img decoding="async" loading="lazy" alt="image-20250629140122099" src="https://ayanami1314.github.io/assets/images/image-20250629140122099-a86b9cdf5b4d29fe2889ed87f4dcd2ea.png" width="1265" height="274" class="img_ev3q"></p>
<p>数据集合成：</p>
<p>Qwen3-32B, <strong>利用检索模型从角色库中，识别出（文档可能对应的）前五个角色候选</strong></p>
<p>然后，将文档+候选角色作为prompt，令模型输出最适合的角色配置</p>
<p>再将角色配置给到模型，生成查询</p>
<ul>
<li>多样性：使用<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>查询类型</mtext><mo stretchy="false">(</mo><mtext>关键词、事实、摘要、判断、</mtext><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo stretchy="false">)</mo><mo>×</mo><mtext>查询长度</mtext><mo>×</mo><mtext>查询语言</mtext><mo>×</mo><mtext>查询难度</mtext><mo>×</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">查询类型(关键词、事实、摘要、判断、...) \times 查询长度 \times 查询语言 \times 查询难度 \times ...</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord cjk_fallback">查询类型</span><span class="mopen">(</span><span class="mord cjk_fallback">关键词、事实、摘要、判断、</span><span class="mord">...</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em"></span><span class="mord cjk_fallback">查询长度</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em"></span><span class="mord cjk_fallback">查询语言</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em"></span><span class="mord cjk_fallback">查询难度</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.1056em"></span><span class="mord">...</span></span></span></span> 作为模型合成数据的状态空间</li>
</ul>
<p>最后产生了1.5亿对数据</p>
<p>高质量对：简单的余弦相似度计算，保留相似度大于0.7的，得到1200w对</p>
<p>结果 SOTA</p>
<p>两个分析：</p>
<ol>
<li>不做合成数据训练，明显掉点</li>
<li>不做模型合并，也掉点</li>
</ol>
<hr>
<h1>Qwen3</h1>
<p>GQA, SwiGLU， RoPE, RSMNorm，Pre-Norm</p>
<p>移除QKV的bias， 在attn中引入QK-Norm</p>
<p>MoE, 128专家，激活8个，去除共享专家，采用全局批次负载平衡损失</p>
<p>预训练：36T tokens，100+语言，代码、STEM、推理、书籍、合成数据</p>
<p><strong>部分数据是Qwen-2.5-VL对大量pdf做OCR再Qwen2.5进行文本优化得到的高质量文本数据</strong></p>
<p>三阶段预训练：</p>
<ol>
<li>通用阶段，30T tokens，4k max length，获取语言能力和世界知识</li>
<li>推理阶段，增加STEM, 代码，推理和合成数据的比例，5T tokens，4k max length，<strong>加速学习率衰减</strong></li>
<li>长上下文阶段，32K，4k-16k 25% + 16k-32k 75%，RoPE 基础频率10000-&gt;1000000, 引入YARN和双向块注意力</li>
</ol>
<p>后训练</p>
<p><img decoding="async" loading="lazy" alt="image-20250629142730991" src="https://ayanami1314.github.io/assets/images/image-20250629142730991-d4b42b61828cafffe14e38312db7ac01.png" width="1405" height="550" class="img_ev3q"></p>
<ol>
<li>思考控制</li>
<li>强到弱蒸馏</li>
</ol>
<p>CoT冷启动：query response两层过滤</p>
<p>query过滤用2.5-72B<strong>删除不容易验证的query, 如多个子问题和通用问题</strong>，<strong>删除2.5-72B能直接正确回答不需要CoT的问题</strong>，<strong>对每个Query进行领域标注，保持数据平衡</strong></p>
<p>Response过滤用QwQ-32B, 每个问题生成N个response,</p>
<ol>
<li>无法生成正确答案<code>-&gt;</code>人工标注</li>
<li>移除<strong>最后答案不正确的，存在大量重复的，猜测而缺乏推理的，推理和总结不一致的，混用语言的，可能和验证集过于相似的</strong></li>
</ol>
<p>冷启动数据直接SFT，学习基础推理模式，为后续RL打基础</p>
<p>推理RL：<strong>GRPO, 大Batch Size, 每个Query多Rollout</strong></p>
<p><strong>仅仅用了4k个数据</strong>，满足</p>
<ol>
<li>冷启动没用过</li>
<li>冷启动模型可学习（不太难）</li>
<li>有挑战性</li>
<li>广泛子领域</li>
</ol>
<p>235B-A22B进行了170个RL训练步骤</p>
<p>思考模式融合（控制不思考）</p>
<p>SFT数据集融合思考非思考的数据，同时设计聊天模板，非思考保留空思考块</p>
<p><img decoding="async" loading="lazy" alt="image-20250629143421275" src="https://ayanami1314.github.io/assets/images/image-20250629143421275-9b092cab61e3daed2d098e38ea56550b.png" width="808" height="348" class="img_ev3q"></p>
<p>当模型学会在非思考和思考模式之间切换，就可以**处理基于不完整的思考生成答案，就可以让模型在思考过程中根据预算来强行停止思考过程。**即 <strong>当模型的思考长度达到定义的阈值时，插入停止思考指令</strong>：“考虑到用户的时间限制，我必须根据目前的思考直接给出解决方案。<code> \n&lt;/think&gt;.\n\n</code>”。并让模型继续根据其积累的推理生成最终响应。</p>
<p>通用RL</p>
<p>增强能力和稳定性</p>
<p>20多任务：指令遵循，格式遵循，偏好对齐，代理能力，特定场景能力（如RAG）</p>
<p>三种奖励：基于规则的奖励，基于模型的奖励（带参考答案），基于模型的奖励（无参考答案）</p>
<p>蒸馏：离线和在线</p>
<p>离线，教师模型产生输出给学生模型SFT</p>
<p>在线，教师和学生对相同prompt在输出logits对齐（最小KL散度）</p>
<p>Ablation</p>
<ul>
<li>Math &amp; code 做完 reasoning RL 达到顶峰</li>
<li>Agent tool use 能力，general RL 也很关键</li>
<li>通用语言能力，很需要 General RL</li>
</ul>
<p>有一个有趣的是thinking其实损害了长上下文的性能</p>
<p><img decoding="async" loading="lazy" src="https://pic1.zhimg.com/v2-625278c87c3ecfe77eddf6801a132fa0_1440w.jpg" alt="img" class="img_ev3q"></p>
<p>RULER大海捞针，non-thinking mode更高，long CoT甚至掉点</p>
<hr>
<p>GRPO &amp; RLHF</p>
<p>RLHF大致两种，on policy(ppo)和off policy(dpo)</p>
<p>on policy的更耗卡，更耗时，但理论上限更高</p>
<p>ppo的四个模型：actor, critic, reference model, reward model</p>
<p>on policy：top_p = 1.0, top_k=-1，加大探索</p>
<p>critic 得出<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">V(s)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mclose">)</span></span></span></span>，起一个降低方差的作用</p>
<p>ReMax： 用<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mo>−</mo><msub><mi>r</mi><mrow><mi>g</mi><mi>r</mi><mi>e</mi><mi>e</mi><mi>d</mi><mi>y</mi></mrow></msub></mrow><annotation encoding="application/x-tex">r-r_{greedy}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">g</span><span class="mord mathnormal mtight">ree</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight" style="margin-right:0.03588em">y</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span>作为baseline，（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mrow><mi>g</mi><mi>r</mi><mi>e</mi><mi>e</mi><mi>d</mi><mi>y</mi></mrow></msub></mrow><annotation encoding="application/x-tex">r_{greedy}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">g</span><span class="mord mathnormal mtight">ree</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight" style="margin-right:0.03588em">y</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span>不是随机采样, 是状态的函数），解决critic model的开销</p>
<p>能够降低方差的原因是默认认为通常 SFT 模型已经经过一部分对齐，对于同一个 prompt 模型不太会输出差异性过大的答案</p>
<p>GRPO：直接退回PG是否有点原始</p>
<p>虽然Critic不仅占资源，并且在LLM这种全部回答的trajectory才重要的情况下，中间的“价值”也很难界定，但PPO还有别的先进feature可以保留，比如<strong>重要性采样和clip</strong></p>
<p><img decoding="async" loading="lazy" src="https://picx.zhimg.com/80/v2-36327391f191e804dacf602c3d3dc957_1440w.webp?source=2c26e567" alt="img" class="img_ev3q"></p>
<p>只是将 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">A_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> 的计算从<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>r</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>c</mi></mrow><annotation encoding="application/x-tex">critic</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em"></span><span class="mord mathnormal" style="margin-right:0.02778em">cr</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">c</span></span></span></span>的输出换成了group内的相对值 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><msub><mi>r</mi><mi>i</mi></msub><mo>−</mo><mi>m</mi><mi>e</mi><mi>a</mi><mi>n</mi><mo stretchy="false">(</mo><msub><mi>r</mi><mi>g</mi></msub><mo stretchy="false">)</mo></mrow><mrow><mi>v</mi><mi>a</mi><mi>r</mi><mo stretchy="false">(</mo><msub><mi>r</mi><mi>g</mi></msub><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{r_i - mean(r_g)}{var(r_g)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.5746em;vertical-align:-0.5423em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0323em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">v</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.02778em">r</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em"><span style="top:-2.357em;margin-left:-0.0278em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">g</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.5073em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em"><span style="top:-2.357em;margin-left:-0.0278em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">an</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em"><span style="top:-2.357em;margin-left:-0.0278em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">g</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5423em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<p>非常暴力，但非常有效</p>
<p>KL penalty用近似值保证KL始终是正数， <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mo>−</mo><mn>1</mn><mo>−</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>r</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi></mrow><annotation encoding="application/x-tex">ratio - 1 - log ratio</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7429em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em">g</span><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span></span></span></span></p>
<p>LLM中，通常将GAE的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>γ</mi></mrow><annotation encoding="application/x-tex">\gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05556em">γ</span></span></span></span>设置为1，因此也直接将这个得分复制到每一个token训练</p>
<p>尽管这种方法确实可以省掉一个 Critic，但成功需要具备 2 个关键：</p>
<ol>
<li><strong>SFT 对给定的 prompt 不能有着太 diverse 的输出，否则方差会比较大。</strong></li>
<li><strong>对同一个 prmopt 采样的数量要可能大，这样才能降低方差</strong></li>
</ol>
<p>offline方法，DPO</p>
<p>降低不好答案被采样的概率，提升好回答的概率</p>
<p><strong>DPO 有一个非常致命的问题</strong>，</p>
<p>由于 DPO 的训练 loss 目标是「尽可能最大化好答案和坏答案之间的采样概率差」，</p>
<p>一种常见的情况是：<strong>好答案 &amp; 坏答案被采样的概率同时在变低，只不过坏答案降低的比好答案更多</strong>。</p>
<p>这种情况在 <strong>chosen 和 rejected 答案有大部分内容相同，仅有少部分内容不同时较为常见</strong>。</p>
<p>DPOP添加了一个如果choosen答案在SFT模型（ref）中采样概率大于当前policy模型的采样概率，则减去的正则项（policy还没拟合好，少更新点）</p>
<p>TDPO 加上了KL，但是是forward KL(KL非对称，SFT计算采样概率是forward, policy model计算是backward KL)</p>
<blockquote>
<p>由于 backward KL 的目标是拟合整个分布中的「一部分」，而 forward KL 的目标是尽可能 cover 整个分布中的大部分。因此，<strong>TDPO 训练后的模型会比 PPO 训练后的模型，在输出多样性上更加自由</strong>。</p>
</blockquote>
<p>token clipping 操作是导致性能下降的主要原因！尤其是像 "However"、"Recheck"、"Wait"、"Aha" 这类带有反思性质的 token 在初始模型中本就属于低概率 token，在更新过程中容易出现高奖励值继而被裁剪，从而无法继续为后续梯度更新提供贡献。</p>
<p>minimax提出CISPO，不丢弃token梯度，裁剪重要性采样权重</p>
<p>传统方法: 先计算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mo>∗</mo><mi>A</mi></mrow><annotation encoding="application/x-tex">ratio * A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em"></span><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span>, 再裁剪乘积</p>
<p>CISPO: 先裁剪 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi></mrow><annotation encoding="application/x-tex">ratio</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em"></span><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span></span></span></span>, 再乘以 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span></p>
<p>效率显著提高（2x speed）</p>
<p>早停: 目标不是对已经生成的重复文本进行惩罚，而是<strong>在模型进入重复循环前就终止生成</strong>。由于简单的字符串匹配难以应对复杂的重复模式，我们设计了一个<strong>基于 token 概率的启发式方法</strong>。</p>
<p>一旦模型进入重复循环，所生成 token 的概率会大幅上升。因此我们制定了如下早停规则：</p>
<blockquote>
<p>如果连续 3,000 个 token 的生成概率都大于 0.99，就立即终止生成。</p>
</blockquote>]]></content:encoded>
            <category>llm</category>
        </item>
        <item>
            <title><![CDATA[Paper reading-Ask in Any Modality A Comprehensive Survey on Multimodal Retrieval-Augmented Generation]]></title>
            <link>https://ayanami1314.github.io/blog/Ask in Any Modality A Comprehensive Survey on Multimodal Retrieval-Augmented Generation</link>
            <guid>https://ayanami1314.github.io/blog/Ask in Any Modality A Comprehensive Survey on Multimodal Retrieval-Augmented Generation</guid>
            <pubDate>Mon, 02 Jun 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[RAG 抽象来说就是，embed - opitional[rerank] - generate管道]]></description>
            <content:encoded><![CDATA[<p>RAG 抽象来说就是，<code>embed - opitional[rerank] - generate</code>管道</p>
<p>有许多的增强方案，例如 Plan X RAG（将问题分解为子问题的DAG，然后设计一些critic LLM判断流的状态正常与否，一个执行LLM按照拓扑序执行DAG），Agentic RAG,  feedback-driven iterative refinement</p>
<p>局限是：传统RAG主要针对文本，多模态集成还是挑战</p>
<p>流程概述如下图</p>
<hr>
<p><img decoding="async" loading="lazy" src="https://arxiv.org/html/2502.08826v2/extracted/6211743/MM-RAG-500.png" alt="Refer to caption" class="img_ev3q"></p>
<hr>
<h1>Multimodel RAG</h1>
<p>LLM拓展为MLLM带来了多模态RAG的挑战</p>
<ul>
<li><strong>检索哪些模态</strong></li>
<li><strong>数据类型的有效融合</strong></li>
<li><strong>跨模态相关性</strong></li>
</ul>
<p><strong>特定模态的编码器将不同的模态映射到共享语义空间，实现跨模态对齐</strong></p>
<hr>
<h1>现有数据集和基准</h1>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="数据集">数据集<a class="hash-link" aria-label="Direct link to 数据集" title="Direct link to 数据集" href="https://ayanami1314.github.io/blog/Ask%20in%20Any%20Modality%20A%20Comprehensive%20Survey%20on%20Multimodal%20Retrieval-Augmented%20Generation#%E6%95%B0%E6%8D%AE%E9%9B%86">​</a></h2>
<ul>
<li>
<p>图文任务（字幕、检索）：MS-COCO, Flickr30K, LAION-400M</p>
</li>
<li>
<p>利用外部知识的视觉问答: OK-VQA</p>
</li>
<li>
<p>多模态推理：MultimodalQA</p>
</li>
<li>
<p>视频文本任务：ActivityNet，YouCook2</p>
</li>
<li>
<p>医学：MIMIC-CXR</p>
</li>
</ul>
<p>许多数据集都是单模态的，随后与其他模态的互补数据集集成。</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="benchmark">Benchmark<a class="hash-link" aria-label="Direct link to Benchmark" title="Direct link to Benchmark" href="https://ayanami1314.github.io/blog/Ask%20in%20Any%20Modality%20A%20Comprehensive%20Survey%20on%20Multimodal%20Retrieval-Augmented%20Generation#benchmark">​</a></h2>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>M</mi><mn>2</mn></msup><mtext>⁢</mtext><mi>R</mi><mtext>⁢</mtext><mi>A</mi><mtext>⁢</mtext><mi>G</mi></mrow><annotation encoding="application/x-tex">M^2⁢R⁢A⁢G</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em">M</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord">⁢</span><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="mord">⁢</span><span class="mord mathnormal">A</span><span class="mord">⁢</span><span class="mord mathnormal">G</span></span></span></span>:
我们执行以下步骤来处理图像，以确保它们具有高质量并且与用户查询相关：
（1）<strong>缓存和转换</strong>：使用 URL 下载所有图像，并将其转换为广泛接受的格式，例如 JPG、PNG、GIF 或 WEBP。无法成功下载或转换的图像将被丢弃；
（2）<strong>过滤</strong>：小于某个阈值或与查询文本的基于 CLIP 相似度得分较低的图像将被删除。此类图像通常包含非代表性的视觉内容，例如图标、横幅等。
（3）<strong>重复数据删除</strong>：使用 PHash Zauner 算法删除重复或高度相似的图像。</p>
<p>指标设计：<strong>主要靠prompt gpt-4o做评估</strong></p>
<ul>
<li>文本模态指标：流畅性，相关性，忠实度，上下文准确率</li>
<li>多模态指标：图像连贯性（图像和周围文本逻辑的连贯性，图像有用性， 图像引用（验证图像和文本引用的适当性），图像召回率（高度相关图像的召回比例）</li>
<li>取所有指标的平均值用于计算总分</li>
</ul>
<hr>
<h1>两种联合建模策略</h1>
<ul>
<li>single-stage：直接生成多模态输出</li>
<li>multi-stage: <strong>文本生成 - 图像插入 - 文本重润色</strong> 三个阶段</li>
</ul>
<p><img decoding="async" loading="lazy" src="https://arxiv.org/html/2411.16365v3/x1.png" alt="" class="img_ev3q"></p>
<hr>
<p><img decoding="async" loading="lazy" src="https://arxiv.org/html/2411.16365v3/x2.png" alt="Refer to caption" class="img_ev3q"></p>
<hr>
<h1>视觉为中心的评估</h1>
<p>MRAG-Bench, VQAv2, VisDoMBench, Dyn-VQA, ScienceQA</p>
<p><img decoding="async" loading="lazy" src="https://mragbench.github.io/static/images/teaser.png" alt="img" class="img_ev3q"></p>
<hr>
<h1>知识密集型评估</h1>
<p>TriviaQA, RAG Check, Natural Questions</p>
<hr>
<p><img decoding="async" loading="lazy" alt="image-20250528162131659" src="https://ayanami1314.github.io/assets/images/image-20250528162131659-62018707c1a0f00cfba6a516a14268bc.png" width="1590" height="831" class="img_ev3q"></p>
<hr>
<p><img decoding="async" loading="lazy" alt="image-20250528162212109" src="https://ayanami1314.github.io/assets/images/image-20250528162212109-27a90337735939c22a158260b068557b.png" width="1639" height="793" class="img_ev3q"></p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="创新和方法">创新和方法<a class="hash-link" aria-label="Direct link to 创新和方法" title="Direct link to 创新和方法" href="https://ayanami1314.github.io/blog/Ask%20in%20Any%20Modality%20A%20Comprehensive%20Survey%20on%20Multimodal%20Retrieval-Augmented%20Generation#%E5%88%9B%E6%96%B0%E5%92%8C%E6%96%B9%E6%B3%95">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="检索策略">检索策略<a class="hash-link" aria-label="Direct link to 检索策略" title="Direct link to 检索策略" href="https://ayanami1314.github.io/blog/Ask%20in%20Any%20Modality%20A%20Comprehensive%20Survey%20on%20Multimodal%20Retrieval-Augmented%20Generation#%E6%A3%80%E7%B4%A2%E7%AD%96%E7%95%A5">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="高效和精度">高效和精度<a class="hash-link" aria-label="Direct link to 高效和精度" title="Direct link to 高效和精度" href="https://ayanami1314.github.io/blog/Ask%20in%20Any%20Modality%20A%20Comprehensive%20Survey%20on%20Multimodal%20Retrieval-Augmented%20Generation#%E9%AB%98%E6%95%88%E5%92%8C%E7%B2%BE%E5%BA%A6">​</a></h4>
<p>现代MRAG<strong>将不同输入模态编码到统一的embedding空间实现直接跨模态检索</strong></p>
<p>方法上，主要为Maximum inner product search (<strong>MIPS</strong>) 变体：近似MIPS，分布式MIPS，KNN变体，近似KNN，ScaNN</p>
<ul>
<li>ScaNN主要结合了一些数学方法 和 量化方法构建了足够快的向量检索索引，这类方法都是用于海量数据的（如1M）</li>
<li>专注于CPU，例如做了很多量化优化让它能尽量利用现代CPU的simd指令 <a href="https://zilliz.com/blog/faiss-vs-scann-choosing-the-right-tool-for-vector-search" target="_blank" rel="noopener noreferrer">https://zilliz.com/blog/faiss-vs-scann-choosing-the-right-tool-for-vector-search</a></li>
</ul>
<hr>
<p>创新主要在效率提升和精度降低：</p>
<ul>
<li>混合搜索</li>
<li>自适应量化</li>
<li>learned index: 神经网络驱动的索引建立，主要是数据库那边的工作</li>
</ul>
<hr>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="以模态为中心的检索">以模态为中心的检索<a class="hash-link" aria-label="Direct link to 以模态为中心的检索" title="Direct link to 以模态为中心的检索" href="https://ayanami1314.github.io/blog/Ask%20in%20Any%20Modality%20A%20Comprehensive%20Survey%20on%20Multimodal%20Retrieval-Augmented%20Generation#%E4%BB%A5%E6%A8%A1%E6%80%81%E4%B8%BA%E4%B8%AD%E5%BF%83%E7%9A%84%E6%A3%80%E7%B4%A2">​</a></h4>
<p>文本中心</p>
<ul>
<li>BM25</li>
<li>bge-m3</li>
<li>ColBERT</li>
<li>RAFT(混合干扰和ground truth文档微调模型增强抗干扰能力)</li>
<li>...</li>
</ul>
<hr>
<p>视觉中心</p>
<ul>
<li>直接用图像表示进行知识提取</li>
<li>基于参考图像的检索，如EchoSight和ImgRet<!-- -->
<ul>
<li>EchoSight 引入了多模态重排</li>
<li><img decoding="async" loading="lazy" src="https://go2heart.github.io/echosight/static/images/teaser.png" alt="Teaser" class="img_ev3q"></li>
</ul>
</li>
</ul>
<hr>
<p>具体来说，对于一个图文问题query, 先用image视觉相似度找到对应的wiki条目，再将wiki的section与图+文的完整query（经过Q-Former之后）进行文本rerank，最后综合视觉分数和文本rerank分数，选取topk后输入LLM。<strong>专注于问题和知识库都是图+文的情况</strong>，也只是finding, 感觉确实创新度不够
<img decoding="async" loading="lazy" src="https://go2heart.github.io/echosight/static/images/overall.png" alt="Overall Structure h:500" class="img_ev3q"></p>
<hr>
<ul>
<li>组合多张图像特征形成综合查询表示</li>
<li>图文映射：Pic2word 如下图，将视觉映射到文本描述</li>
</ul>
<p><img decoding="async" loading="lazy" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjkH5SDYcnCCNSbv4tyJ7lEaZp4W0SsMVP2rBTx8-AnXGM2eYaY04UX9sczYL07-z9TPvcbKP5wF6huVyWe6SOQqqz_iE9Ove-RupgS0e50E5StD1A_yKF2KQtrVgy01J6WaLUZ4rYatFQqgBEnoltPBRXAqTgcGmuD8hVJ3BBkEi55ASVhMy35-_j1yCjs/s16000/image3.png" alt="img" class="img_ev3q"></p>
<hr>
<p>视频中心</p>
<ul>
<li>iRAG，增量检索</li>
<li>MV-Adapter</li>
<li>Video RAG</li>
<li>RTime: 时间因果关系</li>
<li>OmAgent：分治处理复杂视频理解</li>
<li>DRVideo：基于文档检索处理长视频理解</li>
<li>...</li>
</ul>
<hr>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="文档检索和布局理解">文档检索和布局理解<a class="hash-link" aria-label="Direct link to 文档检索和布局理解" title="Direct link to 文档检索和布局理解" href="https://ayanami1314.github.io/blog/Ask%20in%20Any%20Modality%20A%20Comprehensive%20Survey%20on%20Multimodal%20Retrieval-Augmented%20Generation#%E6%96%87%E6%A1%A3%E6%A3%80%E7%B4%A2%E5%92%8C%E5%B8%83%E5%B1%80%E7%90%86%E8%A7%A3">​</a></h4>
<p>ColPali， ColQwen2: 端到端文档图像检索，动态分辨率处理，整体多页推理，绕过OCR技术，1.9k star</p>
<p>它的想法是这样的</p>
<ul>
<li><strong>OCR的多个组件和分块带来误差传播</strong>，且预处理流程耗时也长，能不能直接端到端一次使用文档截图解决</li>
<li>但是如果将整页的文档编码成一个向量，肯定精度不够</li>
<li>多向量方案最经典的ColBERT, 并且在这样一个视觉的情况下，<strong>视觉patch做多向量比文本token还合理</strong></li>
</ul>
<hr>
<ul>
<li>贡献<!-- -->
<ul>
<li>benchmark ViDoRe</li>
<li>将ColBERT和视觉语言模型结合，利用多向量不仅启发了<strong>文搜文，文搜图，还启发了“给一个文档，查找相似的文档”这样的任务</strong></li>
<li>提供了一个良好的视觉文本融合的范式（例如，解决了CLIP这样的模型缺乏文本细粒度的问题），允许最先进的VLM如Qwen-VL-2B，以相同的训练策略微调后作为嵌入器，+5.3 nDCG@5</li>
</ul>
</li>
</ul>
<hr>
<p><img decoding="async" loading="lazy" src="https://arxiv.org/html/2407.01449v6/extracted/6240861/images/final_architecture.png" alt="Refer to caption" class="img_ev3q"></p>
<hr>
<p><strong>可不可以将这个范式沿用到引用溯源？</strong></p>
<p>已经有一些了，ColPali自己就做了每个词条最显著的图像块</p>
<p><img decoding="async" loading="lazy" src="https://arxiv.org/html/2407.01449v6/extracted/6240861/images/similarity_map_energy.png" alt="Refer to caption h:500" class="img_ev3q"></p>
<p>一些布局理解的新框架：ViTLP, DocLLM, CREAM, mPLUG-DocOwl</p>
<hr>
<blockquote>
<p><em>To our knowledge, no benchmark evaluates document retrieval systems in practical settings; in an end-to-end manner, across several document types and topics, and by evaluating the use of both textual and visual document features.</em></p>
</blockquote>
<blockquote>
<p><a href="https://huggingface.co/blog/fsommers/document-similarity-colpali" target="_blank" rel="noopener noreferrer">https://huggingface.co/blog/fsommers/document-similarity-colpali</a>
基于 OCR 的文本提取，以及随后的布局和边界框分析，仍然是重要文档 AI 模型（例如 LayoutLM）的核心。例如， <a href="https://huggingface.co/microsoft/layoutlmv3-base" target="_blank" rel="noopener noreferrer">LayoutLMv3</a> 对文档文本进行编码，包括文本标记序列的顺序、标记或线段的 OCR 边界框坐标以及文档本身。这在关键的文档 AI 任务中取得了最佳成果，但前提是第一步——OCR 文本提取——能够顺利完成。</p>
<p><strong>但通常情况并非如此。</strong></p>
<p>根据我最近的经验，<strong>OCR 瓶颈导致现实世界生产文档档案中的命名实体识别 (NER) 任务的性能下降近 50%。</strong></p>
</blockquote>
<hr>
<p><img decoding="async" loading="lazy" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/paligemma/paligemma_arch.png" alt="Architecture h:600" class="img_ev3q"></p>
<hr>
<p>为下游任务提供了一系列微调版本</p>
<ul>
<li>Image Caption 加字幕</li>
<li>VQA</li>
<li>Detection (Detect [entity])</li>
<li>图像实体分割</li>
<li>文档理解</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="重排序和选择">重排序和选择<a class="hash-link" aria-label="Direct link to 重排序和选择" title="Direct link to 重排序和选择" href="https://ayanami1314.github.io/blog/Ask%20in%20Any%20Modality%20A%20Comprehensive%20Survey%20on%20Multimodal%20Retrieval-Augmented%20Generation#%E9%87%8D%E6%8E%92%E5%BA%8F%E5%92%8C%E9%80%89%E6%8B%A9">​</a></h3>
<p>多用多步骤检索，整合监督和非监督策略</p>
<ul>
<li>probabilistic control keywords to improve credibility<!-- -->
<ul>
<li>对示例的关键信息进行关键词提取，为关键词赋予概率权重，使用概率进行控制信号，<strong>让模型倾向于选择高概率关键词的示例</strong></li>
</ul>
</li>
<li>RULE 利用<strong>统计方法</strong>(Bonferroni校正)校准相关上下文<!-- -->
<ul>
<li>利用统计方法，将“5%概率<strong>存在</strong>错误上下文”这样的朴素要求通过统计运算转换成单个上下文相关度的硬阈值</li>
</ul>
</li>
<li>视频检索中<strong>基于聚类的关键帧选择</strong>来提高多样性</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="相关性评估">相关性评估<a class="hash-link" aria-label="Direct link to 相关性评估" title="Direct link to 相关性评估" href="https://ayanami1314.github.io/blog/Ask%20in%20Any%20Modality%20A%20Comprehensive%20Survey%20on%20Multimodal%20Retrieval-Augmented%20Generation#%E7%9B%B8%E5%85%B3%E6%80%A7%E8%AF%84%E4%BC%B0">​</a></h3>
<ul>
<li><strong>SSIM (Structural Similarity Index Measure)</strong>
最早用于图像领域，衡量两幅图像间的结构、亮度、对比度相似度。现在常用于多模态信息检索，例如图片和文本联合时的相似性计算。<!-- -->
<ul>
<li>比起传统的均方差等简单像素差，更符合人类对视觉感知的一致性判断，综合考虑亮度对比度等</li>
</ul>
</li>
<li><strong>NCC (Normalized Cross-Correlation)</strong>
标准化互相关，常见于信号处理，也可以衡量不同模态数据间的相关强度。<!-- -->
<ul>
<li>衡量两个向量或数组的<strong>线性相关性</strong></li>
</ul>
</li>
<li><strong>BERTScore</strong>
利用BERT这样的深度语义模型计算文本间的语义相似度，比传统关键词对齐更关注上下文语义一致性</li>
<li>分层后处理：重排、相似度筛选、上下文窗口、合并、...</li>
</ul>
<hr>
<ul>
<li>
<p><strong>LDRE</strong></p>
<p>结合多种特征（如caption描述、上下文语义、实体识别等），通过权重自适应集成，提高不同表示方式下的检索相关性适应能力</p>
</li>
<li>
<p>BM25等传统排名的集成</p>
</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="过滤机制">过滤机制<a class="hash-link" aria-label="Direct link to 过滤机制" title="Direct link to 过滤机制" href="https://ayanami1314.github.io/blog/Ask%20in%20Any%20Modality%20A%20Comprehensive%20Survey%20on%20Multimodal%20Retrieval-Augmented%20Generation#%E8%BF%87%E6%BB%A4%E6%9C%BA%E5%88%B6">​</a></h3>
<ul>
<li>
<p>硬负样本挖掘：比起文本的硬负样本挖掘需要多处理跨模态的问题，如不同模态的bias等</p>
<ul>
<li>GME</li>
<li>MM Embed</li>
</ul>
</li>
<li>
<p>共识过滤、多向量过滤</p>
<ul>
<li>MuRAR</li>
<li>ColPali</li>
</ul>
</li>
<li>
<p>动态模态过滤</p>
<ul>
<li>训练retriever判断哪部分是噪声</li>
<li>RAFT, Img2Loc, MAIN-RAG</li>
</ul>
</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="融合机制">融合机制<a class="hash-link" aria-label="Direct link to 融合机制" title="Direct link to 融合机制" href="https://ayanami1314.github.io/blog/Ask%20in%20Any%20Modality%20A%20Comprehensive%20Survey%20on%20Multimodal%20Retrieval-Augmented%20Generation#%E8%9E%8D%E5%90%88%E6%9C%BA%E5%88%B6">​</a></h3>
<p>分数融合和对齐</p>
<ul>
<li>
<p>训练交叉编码器将多模态转换为文本格式</p>
</li>
<li>
<p>引入交错文本对，合并垂直多张few shot images（?）</p>
</li>
<li>
<p>CLIP分数融合，BLIP特征融合，嵌入到相同的空间</p>
</li>
<li>
<p>VISA 使用文档截图嵌入(DSE)模型，对齐文本查询和视觉文档表示</p>
</li>
<li>
<p>MA-LMM视频文本嵌入</p>
</li>
<li>
<p>LLM-RA 将文本和视觉嵌入连接成联合查询</p>
</li>
<li>
<p>...</p>
</li>
</ul>
<p>注意力机制：</p>
<p>注意力方法动态加权跨模态交互，支持特定任务推理</p>
<p>EMERGE, MORE, Alzheimer RAG,RAMM,RAGTrans, MV-Adapter, M2-RAAP</p>
<hr>
<p>统一的框架和预测</p>
<p>M3DocRAG : 多页文档展平为单个嵌入张量</p>
<p>PDF-MVQA 融合了基于感兴趣区域 (RoI) 和基于块 (CLIP) 的视觉语言模型</p>
<p>DQU-CIR 图像转换为复杂查询的文本标题以及将文本叠加到图像上来统一原始数据，然后通过 MLP 学习的权重融合嵌入</p>
<p>SAM-RAG生成图像的标题来对齐图像-文本模态</p>
<p>UFineBench 利用共享粒度解码器进行超精细文本人物检索</p>
<p>Dense2Sparse 投影，将来自 BLIP/ALBEF Li 等人 ( <a href="https://arxiv.org/html/2502.08826v2#bib.bib111" target="_blank" rel="noopener noreferrer">2022a</a> ) 等模型的密集嵌入转换为稀疏词汇向量，使用层归一化和概率扩展控制来优化存储和可解释性</p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="增强技术">增强技术<a class="hash-link" aria-label="Direct link to 增强技术" title="Direct link to 增强技术" href="https://ayanami1314.github.io/blog/Ask%20in%20Any%20Modality%20A%20Comprehensive%20Survey%20on%20Multimodal%20Retrieval-Augmented%20Generation#%E5%A2%9E%E5%BC%BA%E6%8A%80%E6%9C%AF">​</a></h3>
<p>Context Enrichment</p>
<p>查询 重构为结构化检索请求， Video-RAG,EMERGE 整合实体关系和语义描述</p>
<p>Img2Loc 提示中包含数据库中最相似的和最不相似的点来让模型排除预测中不可信的位置</p>
<p>虽然说只是prompt工作，但想法似乎挺有趣，只是这样的作法能否比简单的几层MLP强呢？</p>
<p><img decoding="async" loading="lazy" src="https://arxiv.org/html/2403.19584v1/extracted/2403.19584v1/figure3.jpg" alt="Refer to caption h:400" class="img_ev3q"></p>
<hr>
<p>动态检索</p>
<ul>
<li>
<p>SKURG 查询复杂度决定跳数</p>
</li>
<li>
<p>MR2AG 动态评估和过滤</p>
</li>
<li>
<p>OmniSearch 分解问题</p>
</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="生成技术">生成技术<a class="hash-link" aria-label="Direct link to 生成技术" title="Direct link to 生成技术" href="https://ayanami1314.github.io/blog/Ask%20in%20Any%20Modality%20A%20Comprehensive%20Survey%20on%20Multimodal%20Retrieval-Augmented%20Generation#%E7%94%9F%E6%88%90%E6%8A%80%E6%9C%AF">​</a></h3>
<ul>
<li>
<p>In context learning</p>
<ul>
<li>
<p>记忆数据 RAG-Driver（可解释的自动驾驶）</p>
<ul>
<li><strong>检索引擎</strong>
接收到当前驾驶场景（如视频帧和对应的车辆控制信号）后，先在专家示范的记忆库中检索出与当前最相似的历史驾驶样本。</li>
<li><strong>多模态大语言模型处理</strong>
将检索到的样本与当前场景一同输入多模态大语言模型（MLLM），利用指令微调（Instruction Tuning），实现三项任务：<!-- -->
<ul>
<li><strong>动作解释</strong>（Driving Action Explanation）：输出当前行为的自然语言解释；</li>
<li><strong>行为理由</strong>（Action Justification）：对决策作出合理性说明；</li>
<li><strong>控制信号预测</strong>（Control Signal Prediction）：给出下一个动作的具体数值（如速度和转角）</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<p><img decoding="async" loading="lazy" src="https://yuanjianhao508.github.io/RAG-Driver/static/images/RAGDriver_main.png" alt="MY ALT TEXT h:600" class="img_ev3q"></p>
<hr>
<ul>
<li>
<p>融合上下文Fusion-in-Context Learning (没太看懂RAVEN这篇论文和融合上下文这一个比较早期的encoder-decoder模型的机制有什么关系)</p>
</li>
<li>
<p>Reasoning</p>
<ul>
<li>CoT RAGAR RAG链和RAG树，迭代方式优化事实核查</li>
<li>VisDoM CoT和证据整理</li>
<li>SAM-RAG 推理链和多阶段验证</li>
</ul>
</li>
</ul>
<p>指令调优：如mR2AG 用 mR2AG-IT的数据调优MLLM</p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="来源归属">来源归属<a class="hash-link" aria-label="Direct link to 来源归属" title="Direct link to 来源归属" href="https://ayanami1314.github.io/blog/Ask%20in%20Any%20Modality%20A%20Comprehensive%20Survey%20on%20Multimodal%20Retrieval-Augmented%20Generation#%E6%9D%A5%E6%BA%90%E5%BD%92%E5%B1%9E">​</a></h3>
<p>VISA 视觉来源归属</p>
<ul>
<li>看了看他的论文，VLM<strong>直接输出</strong>边界框(也就是，输入为文档图片，输出为答案 + Box)的，再<strong>LoRA微调</strong>......</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20250528205321419 h:400" src="https://ayanami1314.github.io/assets/images/image-20250528205321419-2f1eec60f2c657b45d90932b2e0c898a.png" width="956" height="538" class="img_ev3q"></p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="对齐">对齐<a class="hash-link" aria-label="Direct link to 对齐" title="Direct link to 对齐" href="https://ayanami1314.github.io/blog/Ask%20in%20Any%20Modality%20A%20Comprehensive%20Survey%20on%20Multimodal%20Retrieval-Augmented%20Generation#%E5%AF%B9%E9%BD%90">​</a></h3>
<p>主要是对比学习：文档/图片/字幕...</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="噪声管理">噪声管理<a class="hash-link" aria-label="Direct link to 噪声管理" title="Direct link to 噪声管理" href="https://ayanami1314.github.io/blog/Ask%20in%20Any%20Modality%20A%20Comprehensive%20Survey%20on%20Multimodal%20Retrieval-Augmented%20Generation#%E5%99%AA%E5%A3%B0%E7%AE%A1%E7%90%86">​</a></h3>
<p>RagVL 噪声注入训练，数据级别加负样本，token级别加Gauss噪声</p>
<p>RA-CM3  随机删除查询token做query dropout</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="mrag解决的任务">MRAG解决的任务<a class="hash-link" aria-label="Direct link to MRAG解决的任务" title="Direct link to MRAG解决的任务" href="https://ayanami1314.github.io/blog/Ask%20in%20Any%20Modality%20A%20Comprehensive%20Survey%20on%20Multimodal%20Retrieval-Augmented%20Generation#mrag%E8%A7%A3%E5%86%B3%E7%9A%84%E4%BB%BB%E5%8A%A1">​</a></h2>
<ul>
<li>图像字幕</li>
<li>QA</li>
<li>事实验证</li>
<li>视觉叙事连贯性</li>
<li>图文检索</li>
<li>.....</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="未来方向">未来方向<a class="hash-link" aria-label="Direct link to 未来方向" title="Direct link to 未来方向" href="https://ayanami1314.github.io/blog/Ask%20in%20Any%20Modality%20A%20Comprehensive%20Survey%20on%20Multimodal%20Retrieval-Augmented%20Generation#%E6%9C%AA%E6%9D%A5%E6%96%B9%E5%90%91">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="泛化">泛化<a class="hash-link" aria-label="Direct link to 泛化" title="Direct link to 泛化" href="https://ayanami1314.github.io/blog/Ask%20in%20Any%20Modality%20A%20Comprehensive%20Survey%20on%20Multimodal%20Retrieval-Augmented%20Generation#%E6%B3%9B%E5%8C%96">​</a></h3>
<ul>
<li>
<p>领域自适应</p>
</li>
<li>
<p>模态偏差，过度依赖文本</p>
</li>
<li>
<p>可解释性</p>
</li>
<li>
<p>引用来源归属，在视觉/语音等模块更严重，难以识别出对应的小区域</p>
</li>
<li>
<p>多模态的对抗性扰动，误导性信息</p>
</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="推理">推理<a class="hash-link" aria-label="Direct link to 推理" title="Direct link to 推理" href="https://ayanami1314.github.io/blog/Ask%20in%20Any%20Modality%20A%20Comprehensive%20Survey%20on%20Multimodal%20Retrieval-Augmented%20Generation#%E6%8E%A8%E7%90%86">​</a></h3>
<p>多模态融入KG</p>
<p>如何进行实体感知检索</p>
<p>位置敏感性</p>
<p>冗余检索</p>
<p>具身智能</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="长上下文效率可拓展">长上下文，效率，可拓展<a class="hash-link" aria-label="Direct link to 长上下文，效率，可拓展" title="Direct link to 长上下文，效率，可拓展" href="https://ayanami1314.github.io/blog/Ask%20in%20Any%20Modality%20A%20Comprehensive%20Survey%20on%20Multimodal%20Retrieval-Augmented%20Generation#%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%95%88%E7%8E%87%E5%8F%AF%E6%8B%93%E5%B1%95">​</a></h3>
<ul>
<li>带图像的多页文档</li>
<li>视频这种超长上下文</li>
</ul>]]></content:encoded>
            <category>mllm</category>
            <category>ai</category>
            <category>llm</category>
        </item>
        <item>
            <title><![CDATA[Paper reading - Fit and Prune Fast and Training-free Visual Token Pruning for Multi-modal Large Language Models]]></title>
            <link>https://ayanami1314.github.io/blog/精读 AAAI 2025 Fit and Prune Fast and Training-free Visual Token Pruning for Multi-modal Large Language Models</link>
            <guid>https://ayanami1314.github.io/blog/精读 AAAI 2025 Fit and Prune Fast and Training-free Visual Token Pruning for Multi-modal Large Language Models</guid>
            <pubDate>Mon, 02 Jun 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[任务]]></description>
            <content:encoded><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="任务">任务<a class="hash-link" aria-label="Direct link to 任务" title="Direct link to 任务" href="https://ayanami1314.github.io/blog/%E7%B2%BE%E8%AF%BB%20AAAI%202025%20Fit%20and%20Prune%20Fast%20and%20Training-free%20Visual%20Token%20Pruning%20for%20Multi-modal%20Large%20Language%20Models#%E4%BB%BB%E5%8A%A1">​</a></h2>
<p>当前MLLM依赖于<strong>大量的视觉token</strong>做出高精度的视觉推理，例如LLaVa使用576 image patches as visual tokens，这相较于纯文本带来了<strong>6.2</strong>倍的计算时长开销。此外，一些其他工作正在使用提高图像分辨率的方法来缓解MLLM的视觉缺陷，但<strong>进一步加剧了计算量</strong>。</p>
<p>作者想要得到一种方法来在MLLM的<strong>图像token输入</strong>中，进行压缩，从而进行<strong>推理时的加速</strong>，且不能太影响下游任务精度。</p>
<p>同时，作者认为先前的方法依赖于大量的实验来确定超参数，他提出的方法需要具有一定的<strong>泛化能力</strong>，并且<strong>超参数确认简单</strong> <code>can be obtained in about 5 minutes for all VL tasks</code></p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="motivation">motivation<a class="hash-link" aria-label="Direct link to motivation" title="Direct link to motivation" href="https://ayanami1314.github.io/blog/%E7%B2%BE%E8%AF%BB%20AAAI%202025%20Fit%20and%20Prune%20Fast%20and%20Training-free%20Visual%20Token%20Pruning%20for%20Multi-modal%20Large%20Language%20Models#motivation">​</a></h2>
<ol>
<li>大规模视觉token在MLLM中的存在明显的冗余，MLLMs 的多头注意力机制是单向的，而非真正“全局”的。简而言之，MLLMs 仅将信息从前一个标记传递到后一个标记，其视觉标记通常置于文本问题之前。在这种情况下，它们主要作用是为文本标记提供视觉语义，但实际上其中大部分并未被激活。</li>
</ol>
<p><img decoding="async" loading="lazy" src="https://pic4.zhimg.com/v2-8df5d0c2852ba56e89010c2fe91b9bb9_1440w.jpg" alt="img" class="img_ev3q"></p>
<hr>
<p>如图，大部分蓝色部分（不相关语义）实际上几乎不参加推理，图像到文本注意力非常集中。</p>
<p><img decoding="async" loading="lazy" alt="image-20250527131819120" src="https://ayanami1314.github.io/assets/images/image-20250527131819120-c14d369820575726608d4915d598be9a.png" width="813" height="618" class="img_ev3q"></p>
<hr>
<ol start="2">
<li>作者将确定压缩比例这一超参数的问题转换成一个统计问题。将压缩问题转换为这样的问题：<strong>给定一个采样样本集合</strong><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span></span></span></span>, 再给定一个计算开销<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03785em">δ</span></span></span></span> ，设压缩策略为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span></span></span></span>， 目标是找到<strong>一个压缩比够大</strong>（满足计算开销到<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03785em">δ</span></span></span></span>以下）的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span></span></span></span>，<strong>使得在<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span></span></span></span>上整体的注意力分布变化最小</strong></li>
</ol>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="方法">方法<a class="hash-link" aria-label="Direct link to 方法" title="Direct link to 方法" href="https://ayanami1314.github.io/blog/%E7%B2%BE%E8%AF%BB%20AAAI%202025%20Fit%20and%20Prune%20Fast%20and%20Training-free%20Visual%20Token%20Pruning%20for%20Multi-modal%20Large%20Language%20Models#%E6%96%B9%E6%B3%95">​</a></h2>
<p><strong>作者只对多头注意力层进行修剪</strong></p>
<p><img decoding="async" loading="lazy" alt="image-20250527155650905" src="https://ayanami1314.github.io/assets/images/image-20250527155650905-1e815d1abeb04e6857086fe406cca405.png" width="1609" height="741" class="img_ev3q"></p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="得到修剪策略">得到修剪策略<a class="hash-link" aria-label="Direct link to 得到修剪策略" title="Direct link to 得到修剪策略" href="https://ayanami1314.github.io/blog/%E7%B2%BE%E8%AF%BB%20AAAI%202025%20Fit%20and%20Prune%20Fast%20and%20Training-free%20Visual%20Token%20Pruning%20for%20Multi-modal%20Large%20Language%20Models#%E5%BE%97%E5%88%B0%E4%BF%AE%E5%89%AA%E7%AD%96%E7%95%A5">​</a></h2>
<p>对于采样样本集<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span></span></span></span>, 计算每一层的视觉token自注意力和视觉-文本交叉注意力。假设视觉token数N，文本token数M，第i层的第j个视觉token的平均注意力为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>a</mi><mrow><mi>s</mi><mo separator="true">,</mo><mi>c</mi></mrow><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msubsup><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><msubsup><mi>A</mi><mrow><mi>m</mi><mo separator="true">,</mo><mi>j</mi></mrow><mi>i</mi></msubsup></mrow><annotation encoding="application/x-tex">a_{s,c}^{i,j}=\sum_{m=1}^{N}A_{m,j}^{i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2078em;vertical-align:-0.3831em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8247em"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">c</span></span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3831em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.376em;vertical-align:-0.3948em"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8247em"><span style="top:-2.4413em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3948em"><span></span></span></span></span></span></span></span></span></span>, s和c分别代表自注意和交叉注意，A代表是在<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span></span></span></span>上取的平均</p>
<p>移除策略P可以建模成<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><msubsup><mi>t</mi><mn>1</mn><mo>∗</mo></msubsup><mo separator="true">,</mo><msubsup><mi>t</mi><mn>2</mn><mo>∗</mo></msubsup><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msubsup><mi>t</mi><mi>k</mi><mo>∗</mo></msubsup><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[t_1^*, t_2^*,...t_k^*]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0331em;vertical-align:-0.2831em"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6887em"><span style="top:-2.4519em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2481em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6887em"><span style="top:-2.4519em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2481em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">...</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6887em"><span style="top:-2.4169em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831em"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span> (假设模型有k层)</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>t</mi><mi>i</mi><mo>∗</mo></msubsup></mrow><annotation encoding="application/x-tex">t_i^*</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9474em;vertical-align:-0.2587em"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6887em"><span style="top:-2.4413em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2587em"><span></span></span></span></span></span></span></span></span></span>表示在<strong>第i层新移除的token数量</strong>，注意前面层移除的token也不会传递给后面层，也就是说移除的总数是单调增的</p>
<p>采用一个注意力相差阈值<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span></span></span></span>和计算开销<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03785em">δ</span></span></span></span>两者一起控制裁剪，具体来说，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03785em">δ</span></span></span></span>是提前给定的，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span></span></span></span>是二分查找计算出来的值</p>
<hr>
<p><img decoding="async" loading="lazy" alt="height:600 width:500" src="https://ayanami1314.github.io/assets/images/image-20250527153710785-90079defd43229432666e6978e287317.png" width="746" height="932" class="img_ev3q"></p>
<hr>
<p>用通俗的话翻译就是:</p>
<ol>
<li>将注意力分布的差别简化为平均每个token的自注意力/交叉注意力<strong>之和</strong>的差别，即是否删除某个token，注意力和的<strong>相对变化</strong>需要小于阈值<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span></span></span></span></li>
<li>由于只计算和，所以可以对自注意力、交叉注意力两个集合分别按照大小排序 —— 注意力分布变化最小的保证转化为，总是优先考虑删除注意力最小的token</li>
<li>给定一个阈值<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span></span></span></span>, 对于每一层遍历，对于自注意力、交叉注意力分别不断尝试删除token，直到注意力变化达到阈值<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span></span></span></span>, 而这一层最后的策略P，即token删除数量为自注意力删除集合<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">T_s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>和交叉注意力集合<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">T_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>的<strong>交集的大小</strong></li>
<li>现在有了一个删除策略<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span></span></span></span>, 计算它是否满足计算开销约束（文中并没有具体说是怎么计算的，应该是根据模型的删除后token和参数量估算FLOPS，或者是某种直接测量计算量的工具，用的显卡是单张A100）</li>
</ol>
<hr>
<ol start="5">
<li>
<p>如果满足，说明删除策略<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span></span></span></span>是可行的，但说不定<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span></span></span></span>太大删除太多了，需要调小<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span></span></span></span>；如果不满足，说明删除策略<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span></span></span></span>不可行，说明<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span></span></span></span>太小了，需要调大<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span></span></span></span>。因此，二分查找<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span></span></span></span>直到找到一个满足计算开销约束的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span></span></span></span>，且这个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span></span></span></span>的左右区间长度小于阈值<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">ϵ</span></span></span></span>(后文实验是0.01)，则这个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span></span></span></span>对应的删除策略<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span></span></span></span>就是最终的删除策略。</p>
</li>
<li>
<p>最后效果是在满足计算开销约束<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03785em">δ</span></span></span></span>的情况下，尽可能保留更多的视觉token</p>
</li>
</ol>
<hr>
<p>关于这样的算法最后带来的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi><mo>−</mo><mi>α</mi></mrow><annotation encoding="application/x-tex">\delta - \alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.03785em">δ</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span></span></span></span>关系，作者附了这么一个曲线</p>
<p><img decoding="async" loading="lazy" alt="image-20250527162141135" src="https://ayanami1314.github.io/assets/images/image-20250527162141135-8bdddf8722d17a88c421e695dc843834.png" width="534" height="458" class="img_ev3q"></p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="根据策略在推理时修剪">根据策略在推理时修剪<a class="hash-link" aria-label="Direct link to 根据策略在推理时修剪" title="Direct link to 根据策略在推理时修剪" href="https://ayanami1314.github.io/blog/%E7%B2%BE%E8%AF%BB%20AAAI%202025%20Fit%20and%20Prune%20Fast%20and%20Training-free%20Visual%20Token%20Pruning%20for%20Multi-modal%20Large%20Language%20Models#%E6%A0%B9%E6%8D%AE%E7%AD%96%E7%95%A5%E5%9C%A8%E6%8E%A8%E7%90%86%E6%97%B6%E4%BF%AE%E5%89%AA">​</a></h2>
<p>在实际推理时，作者将得到的删除策略<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span></span></span></span>应用到模型中。具体来说，对于每一层的视觉token，按照<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span></span></span></span>中给定的删除数量进行修剪。</p>
<p>具体删除哪些token呢？作者的方法是，</p>
<p>对于第i层</p>
<p>计算第i层<strong>剩余</strong>视觉token j的自注意力和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>a</mi><mi>s</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">a_s^{i,j}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0717em;vertical-align:-0.247em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8247em"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em"><span></span></span></span></span></span></span></span></span></span>和交叉注意力和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>a</mi><mi>c</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">a_c^{i,j}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0717em;vertical-align:-0.247em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8247em"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em"><span></span></span></span></span></span></span></span></span></span>，然后将这两个和的<strong>乘积</strong>作为用于排序的参考，排序之后<strong>去除</strong>最小的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span>个token（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span>是删除数量）</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="实验结果">实验结果<a class="hash-link" aria-label="Direct link to 实验结果" title="Direct link to 实验结果" href="https://ayanami1314.github.io/blog/%E7%B2%BE%E8%AF%BB%20AAAI%202025%20Fit%20and%20Prune%20Fast%20and%20Training-free%20Visual%20Token%20Pruning%20for%20Multi-modal%20Large%20Language%20Models#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C">​</a></h2>
<p>作者使用 LLaVA-655k 数据集（Liu et al. 2023b）中的 655 个样本（0.1%）来生成剪枝策略</p>
<p>在LLaVA, LLaVA-HR,LLaVA-NEXT三个具有不同大小的视觉token（7B模型，576，1024，2880 tokens）的模型上进行测试，十余个下游任务数据集上进行测试</p>
<hr>
<p><img decoding="async" loading="lazy" alt="image-20250527160437182" src="https://ayanami1314.github.io/assets/images/image-20250527160437182-35bb2b550fd308086647c96c255c4f7b.png" width="1789" height="979" class="img_ev3q"></p>
<hr>
<p>可以看到，剪枝之后，在保持准确率几乎不下降的情况下， 能够带来计算量的大幅下降</p>
<p>作者还做了其他几组实验</p>
<ol>
<li>
<p><strong>视觉冗余在不同层级的变化</strong></p>
<p>采用在不同层级上，随机删除裁剪视觉Token的方法。作者发现，深层次token的冗余度更高，裁剪深层次token几乎不影响准确度，可视化图也表明深层次的注意力几乎集中在最关键的元素中。但具体到每一层的最佳剪枝比例，层间也有比较大的不同</p>
</li>
</ol>
<hr>
<p><img decoding="async" loading="lazy" alt="image-20250527161223832" src="https://ayanami1314.github.io/assets/images/image-20250527161223832-a7dedefa5a7d792b5b4df9d98c4c3abb.png" width="916" height="409" class="img_ev3q"></p>
<hr>
<p><img decoding="async" loading="lazy" alt="image-20250527161358014" src="https://ayanami1314.github.io/assets/images/image-20250527161358014-df758aa4a01ac89ba28d6406b516bf03.png" width="689" height="509" class="img_ev3q"></p>
<hr>
<ol start="2">
<li>
<p><strong>与baseline的对比</strong></p>
<p>对比了FastV和ToMe两种裁剪方法，表明了自身的SOTA性质。同时指出，在裁剪程度低的时候大家都差不多，裁剪程度高的时候才显露方法的性能差距</p>
<p><img decoding="async" loading="lazy" alt="image-20250527161538762" src="https://ayanami1314.github.io/assets/images/image-20250527161538762-cf4680fadb2324a68d23a06ed98d886e.png" width="1783" height="806" class="img_ev3q"></p>
</li>
</ol>
<hr>
<ol start="3">
<li>
<p><strong>样本数量的消融实验</strong></p>
<p>作者将"LLaVA-655k 数据集（Liu et al. 2023b）中的 655 个样本（0.1%）来生成剪枝策略" 换成1%的数据，发现性能相当。<strong>作者进一步推测MLLM层间信息交换的模式可能更多地依赖于模型本身的特性</strong>，而在不同的输入样本上有较高的泛化性，FitPrune 方法可以有效地捕捉这种模式。同时下面的表还表明，这个方法有着很强的少样本泛化性，确实是模型的特性而不是样本数据集的特性，在仅有10个样本的时候也能得到非常优秀的策略</p>
</li>
</ol>
<p><img decoding="async" loading="lazy" alt="image-20250527162201012" src="https://ayanami1314.github.io/assets/images/image-20250527162201012-c5d2cddb5c89b8435daf12cf36c90db6.png" width="632" height="316" class="img_ev3q"></p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="结论">结论<a class="hash-link" aria-label="Direct link to 结论" title="Direct link to 结论" href="https://ayanami1314.github.io/blog/%E7%B2%BE%E8%AF%BB%20AAAI%202025%20Fit%20and%20Prune%20Fast%20and%20Training-free%20Visual%20Token%20Pruning%20for%20Multi-modal%20Large%20Language%20Models#%E7%BB%93%E8%AE%BA">​</a></h2>
<p>作者介绍了一种FitPrune的无训练方法，用于对 MLLMs 进行视觉标记剪枝。通过将标记剪枝问题表述为一个统计问题，FitPrune 旨在最小化注意力分布的偏差，从而实现冗余视觉token的高效剪枝，进而提高计算效率。FitPrune 能够基于少量数据生成最优的剪枝策略，避免了昂贵的手动试验。</p>]]></content:encoded>
            <category>mllm</category>
            <category>ai</category>
            <category>llm</category>
        </item>
        <item>
            <title><![CDATA[Paper reading-Eagle Exploring The Design Space for Multi- modal LLMs with Mixture of Encoders]]></title>
            <link>https://ayanami1314.github.io/blog/精读：Eagle Exploring The Design Space for Multi- modal LLMs with Mixture of Encoders</link>
            <guid>https://ayanami1314.github.io/blog/精读：Eagle Exploring The Design Space for Multi- modal LLMs with Mixture of Encoders</guid>
            <pubDate>Mon, 02 Jun 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[nvidia的论文, 主要还是实践训练MLLM上的一堆经验]]></description>
            <content:encoded><![CDATA[<p>nvidia的论文, 主要还是实践训练MLLM上的一堆经验</p>
<hr>
<h1>任务</h1>
<p>探究通过使用<strong>不同的视觉编码器和分辨率</strong>来提高MLLM系统性能的不同设计带来的效果</p>
<hr>
<h1>motivation</h1>
<ol>
<li>解读<strong>高分辨率的精细视觉信息</strong>是MLLM重要的课题，常用的CLIP-ViT 预训练时候的分辨率只有如224*224或者336*336，<strong>对OCR等细粒度信息不够好</strong></li>
<li>近期研究发现<code>enhanced visual perception</code>显著减少幻觉和提高性能，许多近期MLLM用了混合视觉编码器<!-- -->
<ul>
<li>有扩大视觉编码器的预训练量和参数的</li>
<li>有将高分辨率编码器和CLIP融合的</li>
<li>也有更复杂的融合和路由，根据任务选用不同编码器，"视觉MoE"的</li>
</ul>
</li>
<li>但缺乏对此类方法设计的通用考量, 以及综合性的大benchmark</li>
</ol>
<hr>
<h1>方法</h1>
<ol>
<li>对<strong>不同的视觉编码器</strong>进行<strong>基准测试</strong>，寻找更<strong>高分辨率自适应</strong>的方案</li>
<li>对<strong>不同的视觉编码器混合策略</strong>做同类比较(论文将近期的混合策略归为了CC,SA,LH等几类)</li>
<li>寻找多个视觉编码器的<strong>最优组合</strong></li>
<li>改进<strong>pre-alignment</strong>和数据混合</li>
</ol>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="增加输入分辨率的做法">增加输入分辨率的做法<a class="hash-link" aria-label="Direct link to 增加输入分辨率的做法" title="Direct link to 增加输入分辨率的做法" href="https://ayanami1314.github.io/blog/%E7%B2%BE%E8%AF%BB%EF%BC%9AEagle%20Exploring%20The%20Design%20Space%20for%20Multi-%20modal%20LLMs%20with%20Mixture%20of%20Encoders#%E5%A2%9E%E5%8A%A0%E8%BE%93%E5%85%A5%E5%88%86%E8%BE%A8%E7%8E%87%E7%9A%84%E5%81%9A%E6%B3%95">​</a></h2>
<ul>
<li>Tiling 将输入分割为子图，CLIP-ViT单独编码</li>
<li>直接放大输入分辨率，并对位置编码进行进行插值</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="eagle做的实验">Eagle做的实验：<a class="hash-link" aria-label="Direct link to Eagle做的实验：" title="Direct link to Eagle做的实验：" href="https://ayanami1314.github.io/blog/%E7%B2%BE%E8%AF%BB%EF%BC%9AEagle%20Exploring%20The%20Design%20Space%20for%20Multi-%20modal%20LLMs%20with%20Mixture%20of%20Encoders#eagle%E5%81%9A%E7%9A%84%E5%AE%9E%E9%AA%8C">​</a></h2>
<p>预训练，LLaVA-1.5 + CLIP 基础模型，和LLaVA相同的 595k 图文对，<strong>冻结整个模型，只训练projection layer</strong></p>
<p>SFT： 1809k 多模态对话数据</p>
<p>评估：11个任务，包含VQA任务， OCR/文档/图表理解，视觉中心任务，基于知识的任务</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="结果---strong-clip">结果 - Strong CLIP<a class="hash-link" aria-label="Direct link to 结果 - Strong CLIP" title="Direct link to 结果 - Strong CLIP" href="https://ayanami1314.github.io/blog/%E7%B2%BE%E8%AF%BB%EF%BC%9AEagle%20Exploring%20The%20Design%20Space%20for%20Multi-%20modal%20LLMs%20with%20Mixture%20of%20Encoders#%E7%BB%93%E6%9E%9C---strong-clip">​</a></h2>
<ol>
<li>
<p><strong>如果插值，需要unfrozen视觉编码器，否则损害性能</strong>。这个结论和以前实验不同。</p>
</li>
<li>
<p>输入分辨率和预训练分辨率差越大，插值越掉点</p>
</li>
<li>
<p>672分辨率下，插值和子图方法性能差不多，但是考虑效率的话还是插值更好</p>
</li>
<li>
<p>进行分辨率adaption，300M的CLIP-ViT性能接近6B的InternVL</p>
</li>
</ol>
<p><strong>按照下表，nvidia着重提了448*448+解锁视觉编码器的方案，300M就达到非常接近SOTA的性能了。</strong></p>
<hr>
<p><img decoding="async" loading="lazy" alt="image-20250601233933871" src="https://ayanami1314.github.io/assets/images/image-20250601233933871-a091334ceb9515da01d836fd92b8ea12.png" width="1166" height="592" class="img_ev3q"></p>
<hr>
<h1>Vision Encoder</h1>
<p>选取了以下的encoder</p>
<ul>
<li>
<p>视觉语言对比学习的视觉Encoder，比如CLIP的ViT和OpenCLIP的ConxNeXt；</p>
</li>
<li>
<p>以目标检测为中心的任务预训练的视觉Encoder，EVA-02</p>
</li>
<li>
<p>OCR上训练的Pix2Struct</p>
</li>
<li>
<p>分割上预训练的SAM</p>
</li>
<li>
<p>自监督训练的DINO-V2</p>
</li>
</ul>
<p>对不同预训练的视觉encoder输出的特征图进行resize和插值，使得视觉token数量相同.</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="结果">结果：<a class="hash-link" aria-label="Direct link to 结果：" title="Direct link to 结果：" href="https://ayanami1314.github.io/blog/%E7%B2%BE%E8%AF%BB%EF%BC%9AEagle%20Exploring%20The%20Design%20Space%20for%20Multi-%20modal%20LLMs%20with%20Mixture%20of%20Encoders#%E7%BB%93%E6%9E%9C">​</a></h2>
<p><img decoding="async" loading="lazy" alt="image-20250601234936395" src="https://ayanami1314.github.io/assets/images/image-20250601234936395-09f01aa111506ba3b9c5c12a40b0d2e0.png" width="1136" height="643" class="img_ev3q"></p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="分析">分析：<a class="hash-link" aria-label="Direct link to 分析：" title="Direct link to 分析：" href="https://ayanami1314.github.io/blog/%E7%B2%BE%E8%AF%BB%EF%BC%9AEagle%20Exploring%20The%20Design%20Space%20for%20Multi-%20modal%20LLMs%20with%20Mixture%20of%20Encoders#%E5%88%86%E6%9E%90">​</a></h2>
<ul>
<li>在freeze的情况下他们通常能<strong>在和自己预训练任务相近的MLLM benchmark上实现最佳性能</strong>。例如来自CLIP的ConvNeXt进行了图文对齐，因此在TextVQA、SQA任务上时所有编码器里表现的最好的。而Text Recognition任务上训练所得的Pix2Struct视觉编码器，在OCR任务上是表现的最好的。</li>
<li>当跟随CLIP-ViT高分辨率拓展策略，<strong>unfreeze视觉编码器时，基本都能有性能提升</strong>，也有反超对应domain上训练的视觉编码器的可能性，例如CLIP-ConvNeXt微调后在OCR上性能超过了Pix2Struct。</li>
</ul>
<hr>
<h1>融合策略：</h1>
<p><img decoding="async" loading="lazy" src="https://arxiv.org/html/2408.15998v2/x2.png" alt="Refer to caption" class="img_ev3q"></p>
<hr>
<ul>
<li>序列维度拼接：SA sequence append</li>
<li>通道维度拼接：CC concat channel</li>
<li>LLAVA-HR式：LH 将高分辨率特征使用adapter注入低分辨率特征中，维持序列长度、通道维度不变</li>
<li>Mini-Gemini式：MG 将高分辨率特征使用local windows cross attention注入到低分辨率的queries中。</li>
<li>Deformable Attention式：DA 将MG的local windows变成了Deformable Attention</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="结果-1">结果：<a class="hash-link" aria-label="Direct link to 结果：" title="Direct link to 结果：" href="https://ayanami1314.github.io/blog/%E7%B2%BE%E8%AF%BB%EF%BC%9AEagle%20Exploring%20The%20Design%20Space%20for%20Multi-%20modal%20LLMs%20with%20Mixture%20of%20Encoders#%E7%BB%93%E6%9E%9C-1">​</a></h2>
<p><img decoding="async" loading="lazy" alt="image-20250601235208565" src="https://ayanami1314.github.io/assets/images/image-20250601235208565-66c205343b77aadcdafb4b386a8db120.png" width="947" height="415" class="img_ev3q"></p>
<ul>
<li>
<p>融合策略越复杂，性能的提升似乎越差，<strong>简单的SA/CC稳定涨点</strong></p>
</li>
<li>
<p>由于SA需要处理边长的序列长度，所以后面用CC</p>
</li>
</ul>
<hr>
<h1>Pre-Alignment</h1>
<p><img decoding="async" loading="lazy" src="https://arxiv.org/html/2408.15998v2/x3.png" alt="Refer to caption" class="img_ev3q"></p>
<p>考虑对其他的视觉专家进行预先的文本模态对齐，再学会去融合不同视觉专家的特征。因此在目前的两阶段MLLM训练框架之前，添加了一个vision-language pre-alignment training阶段，首先使用next-token prediction监督每个视觉专家的特征+各自<strong>单独的</strong>projector（与LLaVA原始预训练策略不同）训练，让其与一个冻结的较小语言模型对齐。</p>
<hr>
<ul>
<li><strong>进行一个额外的预先对齐，可以比较好提升MLLM性能。</strong></li>
<li>预对齐后，再合并所有的视觉专家，训练projector和encoder</li>
<li>虽然在 SFT 期间解冻视觉专家有助于通过更新视觉专家以适应语言模型来提高性能，但<em>预对齐</em>策略更有效地减轻了每位视觉专家的固有偏差，并稳定了训练过程，从而提高了整体性能 （<strong>unfreeze + pre-align效果加性</strong>）</li>
</ul>
<hr>
<h1>Fusion choice</h1>
<p><img decoding="async" loading="lazy" src="https://arxiv.org/html/2408.15998v2/x4.png" alt="w h:600" class="img_ev3q"></p>
<hr>
<p>采用上述的3阶段训练和最好最简单的Channel concat策略，就可以进一步研究哪种视觉编码器组合最好。组合的策略是依次增加模型视觉编码器的数量，每次的选择基于上一个数量下最好的组合进行进一步添加。<strong>四到五个编码器（X4, X5）目前看来就已经比较合适了。</strong></p>
<p>最佳组合是 <em>CLIP</em> 、 <em>ConvNeXt</em> 、 <em>SAM</em> 、 <em>Pix2Struct</em> 和 <em>EVA-02</em></p>
<hr>
<h1>最终和benchmark的比较</h1>
<p><img decoding="async" loading="lazy" src="https://arxiv.org/html/2408.15998v2/x1.png" alt="Refer to caption" class="img_ev3q"></p>
<hr>
<h1>高分辨率的文档任务的展示: 红色baseline失败，蓝色eagle成功</h1>
<p><img decoding="async" loading="lazy" src="https://arxiv.org/html/2408.15998v2/x5.png" alt="h:600" class="img_ev3q"></p>
<hr>
<h1>结论</h1>
<ol>
<li>MLLM训练期间<strong>解锁视觉编码器</strong>matters</li>
<li>设计<strong>先进的融合策略并不能较简单的通道级联显露优势</strong></li>
<li>更多的视觉专家<strong>MoE能带来持续增益</strong>，是增强MLLM能力的有效途径</li>
<li>视觉专家如果开始时候设计的任务和文本无关（没有对齐），用<strong>冻结的LLM进行预对齐</strong>（+解锁）后再整体训练能显著提升性能</li>
</ol>]]></content:encoded>
            <category>llm</category>
            <category>ai</category>
            <category>mllm</category>
        </item>
        <item>
            <title><![CDATA[RAG的一些思考与细节]]></title>
            <link>https://ayanami1314.github.io/blog/RAG的一些思考和细节</link>
            <guid>https://ayanami1314.github.io/blog/RAG的一些思考和细节</guid>
            <pubDate>Fri, 30 May 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[Langchain needle in haystack 实验]]></description>
            <content:encoded><![CDATA[<h4 class="anchor anchorWithStickyNavbar_LWe7" id="langchain-needle-in-haystack-实验">Langchain needle in haystack 实验<a class="hash-link" aria-label="Direct link to Langchain needle in haystack 实验" title="Direct link to Langchain needle in haystack 实验" href="https://ayanami1314.github.io/blog/RAG%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83%E5%92%8C%E7%BB%86%E8%8A%82#langchain-needle-in-haystack-%E5%AE%9E%E9%AA%8C">​</a></h4>
<p>长上下文之后，越后面的部分的事实性细节越容易找，尤其是多事实的情况下</p>
<p>引发的一个思考是 rerank 时是否需要将最关注的块放在 prompt 的最后面，也就是倒序？</p>
<ul>
<li>后补: 但其实又有attention sink相关的研究，可能还是需要具体任务具体测试分析</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20250417222048515" src="https://ayanami1314.github.io/assets/images/image-20250417222048515-4b8dca1267f9a233e00e99645f943160.png" width="836" height="411" class="img_ev3q"></p>
<p>Maybe <strong>recency bias</strong> in LLMs：只记得最近的了</p>
<p>No retrieval guarantees</p>
<p><img decoding="async" loading="lazy" alt="image-20250417222613216" src="https://ayanami1314.github.io/assets/images/image-20250417222613216-ca6cf44bb533faa8009e9abf8e801437.png" width="1221" height="568" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="query-analysis将-question-联系到正确的文档">query analysis：将 question 联系到正确的文档<a class="hash-link" aria-label="Direct link to query analysis：将 question 联系到正确的文档" title="Direct link to query analysis：将 question 联系到正确的文档" href="https://ayanami1314.github.io/blog/RAG%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83%E5%92%8C%E7%BB%86%E8%8A%82#query-analysis%E5%B0%86-question-%E8%81%94%E7%B3%BB%E5%88%B0%E6%AD%A3%E7%A1%AE%E7%9A%84%E6%96%87%E6%A1%A3">​</a></h4>
<p>routing (to right DB)</p>
<p><code>full doc -&gt; summary -&gt; embedding</code>： doc 中噪声非常大, summary 是必要的，语义层次的保留 level 通过 prompt 保证</p>
<p>self-reflection 听起来很美好，但实际常常用不到，太慢了，并且搜不出来更多是前期处理没做好，再换着花样也很难搜出来</p>
<p>HyDE 对于高度 Domain Knowledge 和抽象性理解的任务基本没用:</p>
<p>一些自己的解释</p>
<ol>
<li>能否生成正确的假设文档， 难</li>
<li>即使通过先行的小批量搜索教导 LLM 根据这些 example 生成假设文档，也很难让 LLM 从这些文档中抽取某个泛化的问题，经常会 <strong>过度 specific 而导致后续漏掉文档</strong></li>
<li>目前实验下来垂域脏文档类型最好的解决方案还是 reranker，embedder 如果不微调分布太接近了，例如全部的 chunk 都在 0.5~0.6 之间，意义寥寥</li>
</ol>
<p>和数据分析的结合:</p>
<p><code>分析波动-&gt;(数据分析)找出波动的阶段-&gt; 对每个波动的阶段做查询</code></p>
<p>GraphRag 这种 KG-based 的方法经常强调“对整个数据集信息的整合”</p>
<p>但这个要分领域，例如，个人知识库之中，这是好的</p>
<p>但垂域的知识文档常常是相似的格式，固定的路由，同时信息的整合关键不在“多实体”的关系上，而是在于“单个实体随时间的变化”上。</p>
<p>又或者说实体关系 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo stretchy="false">(</mo><msub><mi>e</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>e</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">R(e_1, e_2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 本身应该建模成一个包含时间的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo stretchy="false">(</mo><msub><mi>e</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>e</mi><mn>2</mn></msub><mo separator="true">,</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">R(e_1, e_2, t)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">t</span><span class="mclose">)</span></span></span></span></p>
<p>如果仅仅是靠新加入的文档来动态更新 KG 的话，滞后性会很强</p>
<p>在这种半结构化的模板式文档中，LLM 实际上在干一个 Fuzzy DB manager, 提取信息，充当一个搜索引擎</p>
<p>利用 KG 进行某种意义上的多跳推理本质上也只是对文档的多次检索，推理跳数越多，关系越复杂，离线生成 KG 就越难，不是所有领域都像是法律一样有一个明确的 A 判例引用 BCD 法条的连接关系的，这样复杂的 KG 在要想随时间变化也更不可能</p>
<p>从某种意义上来说，KG 是在横向生成，而类似金融这种领域的 RAG 做的是纵向的 Timeline, 这部分对于关键实体是有数据的，并且可能数据都不需要自己做（例如各种行情的图），而离线准备好这些 timeline 之后，如何在 timeline 上进行一个跳跃和查询分析才是关键的。</p>
<p>如果从 DB 的角度上分析的话，金融领域这种关注点快速变化的 RAG 系统（with cache）也就相当于 lazy generated timeseries DB 了，例如问了一个 A 的价格变化，就像是生成了一个 <code>time, delta_price, event(detail)</code> 的 timeseries DB 表，把生成 reason 这样的 LLM 工作 lazy 化了而已</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="chunk-的前总结和后总结离线在线">chunk 的前总结和后总结(离线在线)<a class="hash-link" aria-label="Direct link to chunk 的前总结和后总结(离线在线)" title="Direct link to chunk 的前总结和后总结(离线在线)" href="https://ayanami1314.github.io/blog/RAG%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83%E5%92%8C%E7%BB%86%E8%8A%82#chunk-%E7%9A%84%E5%89%8D%E6%80%BB%E7%BB%93%E5%92%8C%E5%90%8E%E6%80%BB%E7%BB%93%E7%A6%BB%E7%BA%BF%E5%9C%A8%E7%BA%BF">​</a></h4>
<p>离线总结最大的问题在于总结哪些方面，实际上是文档预处理的一个部分</p>
<p>最简单的方法就是整个提示模板每个 chunk 问一次 LLM，有 langchain 的 map reduce 等稍微 high level 一点的工具可以支持这个事情</p>
<p>对长文档总结更有效一些的做法是利用好 embedding，先对 chunk embedding 做聚类，再每个聚类里面抽几个 chunk, 从而保证多样性和 chunk 数量的平衡</p>
<p>后总结，或者说 query-based 总结大体上是用 LLM 做比较多，但对于时延和开销的增加太高了，一个比较新的方法是 paragraph sentence-level mask bert（自己造的词），在段落中根据 q, d 的交叉编码得到句子级别的二进制掩码，从而删除无关部分。有一篇 ICLR2025 基于 bge 训了个，<a href="https://huggingface.co/blog/nadiinchi/provence" target="_blank" rel="noopener noreferrer">https://huggingface.co/blog/nadiinchi/provence</a></p>
<p>provence效果非常好，又快又几乎对齐例如GPT4.1这种顶级模型的效果</p>
<p>另一个思路就是绕过这个问题，切小块，依赖 rerank 和重新合并乃至知识图谱检索之类的策略保证相关性，也就是在查询完之后是合并还是切分的思路差距</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="半结构化数据">半结构化数据<a class="hash-link" aria-label="Direct link to 半结构化数据" title="Direct link to 半结构化数据" href="https://ayanami1314.github.io/blog/RAG%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83%E5%92%8C%E7%BB%86%E8%8A%82#%E5%8D%8A%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE">​</a></h4>
<p><a href="https://docs.superlinked.com/getting-started/installation" target="_blank" rel="noopener noreferrer">https://docs.superlinked.com/getting-started/installation</a> 聚焦半结构化的异构数据，例如朴素 embedding 方案对数字的理解不足，无法建模 1-99 的相似度分数与 higher/lower 这种文本的关系</p>
<p><a href="https://github.com/microsoft/multifield-adaptive-retrieval" target="_blank" rel="noopener noreferrer">https://github.com/microsoft/multifield-adaptive-retrieval</a> 做多字段的权重学习(自适应选择查询应该着重的权重)</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="embedding-相关的调优">embedding 相关的调优<a class="hash-link" aria-label="Direct link to embedding 相关的调优" title="Direct link to embedding 相关的调优" href="https://ayanami1314.github.io/blog/RAG%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83%E5%92%8C%E7%BB%86%E8%8A%82#embedding-%E7%9B%B8%E5%85%B3%E7%9A%84%E8%B0%83%E4%BC%98">​</a></h4>
<p>colbert架构是一个better embedding的方向，其核心在于将文档的token level embedding保存下来，对于每一个query token，计算maxsim算子得到单token的score，再求和</p>
<p><img decoding="async" loading="lazy" src="https://github.com/stanford-futuredata/ColBERT/raw/main/docs/images/ColBERT-Framework-MaxSim-W370px.png" alt="img" class="img_ev3q"></p>
<p>对比朴素embedding方案，它在token level进行计算可以很好的带来类似关键词匹配的效果，有效避免长文档下，embedding过于平均化余弦相似太不敏感的问题</p>
<p>对比rerank方案，它的优点又在嵌入矩阵可以离线计算，不需要完全在线的交叉编码器</p>
<p>引入方案： <a href="https://python.langchain.com/docs/integrations/providers/ragatouille/" target="_blank" rel="noopener noreferrer">https://python.langchain.com/docs/integrations/providers/ragatouille/</a></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="prompt">Prompt<a class="hash-link" aria-label="Direct link to Prompt" title="Direct link to Prompt" href="https://ayanami1314.github.io/blog/RAG%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83%E5%92%8C%E7%BB%86%E8%8A%82#prompt">​</a></h4>
<p>基本没有什么特别通用的工作，但值得一提的是将prompt作为一个优化变量，使用LLM在Trajatory上进行采样和跑各种论文的“prompt优化算法”的解耦框架dsPy <a href="https://dspy.ai/" target="_blank" rel="noopener noreferrer">https://dspy.ai/</a> 用户以类似类型/对象系统的简短注释提供给dspy作为“初始意图”，而后续复杂的提示由dspy生成，核心思想是让用户专注于编程</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">class</span><span class="token plain"> </span><span class="token class-name">CheckCitationFaithfulness</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">dspy</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Signature</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token triple-quoted-string string" style="color:#e3116c">"""Verify that the text is based on the provided context."""</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    context</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token builtin">str</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> dspy</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">InputField</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">desc</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"facts here are assumed to be true"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    text</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token builtin">str</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> dspy</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">InputField</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    faithfulness</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token builtin">bool</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> dspy</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">OutputField</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    evidence</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token builtin">dict</span><span class="token punctuation" style="color:#393A34">[</span><span class="token builtin">str</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token builtin">list</span><span class="token punctuation" style="color:#393A34">[</span><span class="token builtin">str</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> dspy</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">OutputField</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">desc</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"Supporting evidence for claims"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">context </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"The 21-year-old made seven appearances for the Hammers and netted his only goal for them in a Europa League qualification round match against Andorran side FC Lustrains last season. Lee had two loan spells in League One last term, with Blackpool and then Colchester United. He scored twice for the U's but was unable to save them from relegation. The length of Lee's contract with the promoted Tykes has not been revealed. Find all the latest football transfers on our dedicated page."</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">text </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"Lee scored 3 goals for Colchester United."</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">faithfulness </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> dspy</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">ChainOfThought</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">CheckCitationFaithfulness</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">faithfulness</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">context</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">context</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> text</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">text</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<blockquote>
<p>DSPy 中的不同优化器将通过为每个模块<strong>合成良好的小样本示例</strong> （如 <code>dspy.BootstrapRS</code> <a href="https://arxiv.org/abs/2310.03714" target="_blank" rel="noopener noreferrer">1 ）</a> 来调整程序的质量；为每个提示<strong>提出并智能地探索更好的自然语言指令</strong> （如 <code>dspy.MIPROv2</code> <a href="https://arxiv.org/abs/2406.11695" target="_blank" rel="noopener noreferrer">2 ）</a> ，以及<strong>为您的模块构建数据集并使用它们来微调系统中的 LM 权重</strong> （如 <code>dspy.BootstrapFinetune</code> <a href="https://arxiv.org/abs/2407.10930" target="_blank" rel="noopener noreferrer">3 ）</a></p>
</blockquote>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="llm评估">LLM评估<a class="hash-link" aria-label="Direct link to LLM评估" title="Direct link to LLM评估" href="https://ayanami1314.github.io/blog/RAG%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83%E5%92%8C%E7%BB%86%E8%8A%82#llm%E8%AF%84%E4%BC%B0">​</a></h4>
<p>测试不可靠：有多少答案是被记忆出来的？</p>
<p>有多篇相关的paper在讨论这个问题，然后采用了一些方法来衡量这个事情，例如，在数学问题题集中，替换无关的描述、修改数字等等，看看模型性能变差多少</p>
<p>类似数学问题集这种在网络上数据中很难过滤干净，还需要考虑多语言影响</p>
<p>另一些评估指标如ARC-AGI通过抽象图像智力问题集来评估模型的推理能力，相对来说泄题风险小一些(并且有隐藏test set)</p>
<ul>
<li>丢给LLM的时候不是图像，而是矩阵，用数字表示不同颜色</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20250505134411046" src="https://ayanami1314.github.io/assets/images/image-20250505134411046-5ad9c901ec94d830bb33f096ec492f2a.png" width="1224" height="849" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="chatbot-arena-让全世界的人都来进行判断哪个模型好">Chatbot Arena: 让全世界的人都来进行判断哪个模型好<a class="hash-link" aria-label="Direct link to Chatbot Arena: 让全世界的人都来进行判断哪个模型好" title="Direct link to Chatbot Arena: 让全世界的人都来进行判断哪个模型好" href="https://ayanami1314.github.io/blog/RAG%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83%E5%92%8C%E7%BB%86%E8%8A%82#chatbot-arena-%E8%AE%A9%E5%85%A8%E4%B8%96%E7%95%8C%E7%9A%84%E4%BA%BA%E9%83%BD%E6%9D%A5%E8%BF%9B%E8%A1%8C%E5%88%A4%E6%96%AD%E5%93%AA%E4%B8%AA%E6%A8%A1%E5%9E%8B%E5%A5%BD">​</a></h4>
<p>但还是有办法hack: 更fit人的倾向（粗体字、分点、emoji.....）</p>
<p>Elo Score 考虑除了人的直接倾向之外其他因素的影响，在BF模型计算时加上一项<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\beta_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0528em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>,  <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy="false">(</mo><msub><mi>β</mi><mi>i</mi></msub><mo>−</mo><msub><mi>β</mi><mi>j</mi></msub><mo>+</mo><msub><mi>β</mi><mn>0</mn></msub><mo stretchy="false">)</mo></mrow></mfrac><mo>=</mo><msub><mi>E</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\frac{1}{1 + exp(\beta_i - \beta_j + \beta_0)} = E_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3874em;vertical-align:-0.5423em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">p</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05278em">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em"><span style="top:-2.357em;margin-left:-0.0528em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05278em">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em"><span style="top:-2.357em;margin-left:-0.0528em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em"><span></span></span></span></span></span></span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05278em">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em"><span style="top:-2.357em;margin-left:-0.0528em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5423em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">E_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span> 是模型i和j的胜率，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\beta_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0528em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> 是模型i的真实评分，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\beta_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0528em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> 是一个全局偏差项，表示人类评估者的偏好。通过最大化似然函数来估计参数<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\beta_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0528em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\beta_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0528em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>，从而得到模型的真实评分。</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mn>0</mn></msub><mo>=</mo><msub><mi>γ</mi><mn>1</mn></msub><mo>∗</mo><mtext>长度差</mtext><mo>+</mo><msub><mi>γ</mi><mn>2</mn></msub><mo>∗</mo><mi>e</mi><mi>m</mi><mi>o</mi><mi>j</mi><mi>i</mi><mtext>个数差</mtext><mo>+</mo><msub><mi>γ</mi><mn>3</mn></msub><mo>∗</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\beta_0 = \gamma_1 * 长度差 + \gamma_2 * emoji个数差 + \gamma_3 * ...</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0528em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6597em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em">γ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0556em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em"></span><span class="mord cjk_fallback">长度差</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6597em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em">γ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0556em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord mathnormal">e</span><span class="mord mathnormal">m</span><span class="mord mathnormal">o</span><span class="mord mathnormal">ji</span><span class="mord cjk_fallback">个数差</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6597em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em">γ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0556em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.1056em"></span><span class="mord">...</span></span></span></span></p>
<p><img decoding="async" loading="lazy" alt="image-20250505135351256" src="https://ayanami1314.github.io/assets/images/image-20250505135351256-3bf80497f080b17544c064176591200e.png" width="975" height="825" class="img_ev3q"></p>
<p>可以看到，考不考虑这个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\beta_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0528em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>，模型的排名差别很大</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="goodharts-law">Goodhart's Law<a class="hash-link" aria-label="Direct link to Goodhart's Law" title="Direct link to Goodhart's Law" href="https://ayanami1314.github.io/blog/RAG%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83%E5%92%8C%E7%BB%86%E8%8A%82#goodharts-law">​</a></h4>
<p><strong>一旦一项指标被用作目标，它就不再是一个好的指标</strong></p>
<p><a href="http://becomingahacker.org/integrating-agentic-rag-with-mcp-servers-technical-implementation-guide-1aba8fd4e442" target="_blank" rel="noopener noreferrer">http://becomingahacker.org/integrating-agentic-rag-with-mcp-servers-technical-implementation-guide-1aba8fd4e442</a></p>
<p>However, traditional RAG has limitations: it usually queries a single data source and only performs one retrieval pass, so if the initial results are poor or the query is phrased oddly, the answer will suffer
但是，传统的 RAG 存在局限性：它通常查询单个数据源，并且只执行一次检索传递，因此如果初始结果不佳或查询措辞奇怪，答案将受到影响</p>
<p>There’s no built-in mechanism for the system to reason about <em>how</em> to retrieve better information or to use additional tools if needed.
系统没有内置机制来推理<em>如何</em>检索更好的信息或在需要时使用其他工具。</p>
<p>关于结构化输出的另一篇特别好的文章: <a href="https://www.boundaryml.com/blog/schema-aligned-parsing" target="_blank" rel="noopener noreferrer">https://www.boundaryml.com/blog/schema-aligned-parsing</a></p>
<p>推理加速：是对的，例如huggingface-text-embedding项目，将各种转trt/onnx 可以让吞吐提升5x</p>
<p>H100 bge-reranker-v2-m3  1024 * 512char sentence， 13s -&gt; 2.3s</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="关键词抽取">关键词抽取<a class="hash-link" aria-label="Direct link to 关键词抽取" title="Direct link to 关键词抽取" href="https://ayanami1314.github.io/blog/RAG%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83%E5%92%8C%E7%BB%86%E8%8A%82#%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8A%BD%E5%8F%96">​</a></h4>
<p>基于主题LDA，词典等</p>
<p>小模型方法：先用spaCy、hanLP等得到语法树，再从语法树中拿到名词性关键词等</p>
<p>无监督，经典如YAKE！综合考虑词频，词位，共现等。可以考虑<a href="https://github.com/JackHCC/Chinese-Keyphrase-Extraction" target="_blank" rel="noopener noreferrer">https://github.com/JackHCC/Chinese-Keyphrase-Extraction</a></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="一篇非常有insight的blog上下文相关上下文充足定量充足性和它的应用">一篇非常有insight的blog：上下文相关!=上下文充足，定量充足性和它的应用<a class="hash-link" aria-label="Direct link to 一篇非常有insight的blog：上下文相关!=上下文充足，定量充足性和它的应用" title="Direct link to 一篇非常有insight的blog：上下文相关!=上下文充足，定量充足性和它的应用" href="https://ayanami1314.github.io/blog/RAG%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83%E5%92%8C%E7%BB%86%E8%8A%82#%E4%B8%80%E7%AF%87%E9%9D%9E%E5%B8%B8%E6%9C%89insight%E7%9A%84blog%E4%B8%8A%E4%B8%8B%E6%96%87%E7%9B%B8%E5%85%B3%E4%B8%8A%E4%B8%8B%E6%96%87%E5%85%85%E8%B6%B3%E5%AE%9A%E9%87%8F%E5%85%85%E8%B6%B3%E6%80%A7%E5%92%8C%E5%AE%83%E7%9A%84%E5%BA%94%E7%94%A8">​</a></h4>
<p><a href="https://research.google/blog/deeper-insights-into-retrieval-augmented-generation-the-role-of-sufficient-context/" target="_blank" rel="noopener noreferrer">https://research.google/blog/deeper-insights-into-retrieval-augmented-generation-the-role-of-sufficient-context/</a></p>]]></content:encoded>
            <category>rag</category>
            <category>ai</category>
            <category>llm</category>
        </item>
        <item>
            <title><![CDATA[Paper reading - Interleaved Scene Graph for Interleaved Text-and-Image Generation Assessment]]></title>
            <link>https://ayanami1314.github.io/blog/精读  Interleaved Scene Graph for Interleaved Text-and-Image Generation Assessment</link>
            <guid>https://ayanami1314.github.io/blog/精读  Interleaved Scene Graph for Interleaved Text-and-Image Generation Assessment</guid>
            <pubDate>Fri, 30 May 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[开发了一个交错文本和图像生成综合评估框架ISG]]></description>
            <content:encoded><![CDATA[<p>开发了一个<strong>交错文本和图像生成综合评估框架</strong>ISG</p>
<p>使用<code>scene graph</code>捕获文本和图像的关系，提供四个级别的评估：整体的、结构性的、块级别和特定于图像的，并引入了一个新benchmark，ISG-BENCH</p>
<p>作者实验认为现有模型在端到端生成文本图像交错内容时，效果不好，于是做了一个Agent来完成这个任务</p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="motivation">motivation<a class="hash-link" aria-label="Direct link to motivation" title="Direct link to motivation" href="https://ayanami1314.github.io/blog/%E7%B2%BE%E8%AF%BB%20%20Interleaved%20Scene%20Graph%20for%20Interleaved%20Text-and-Image%20Generation%20Assessment#motivation">​</a></h3>
<p><img decoding="async" loading="lazy" alt="image-20250530152606364" src="https://ayanami1314.github.io/assets/images/image-20250530152606364-d9605f8fed7f263b463ed75398a8cf8a.png" width="990" height="433" class="img_ev3q"></p>
<p>如图，现有MLLM<strong>不能直接生成交错文本和图像内容</strong>，需要将生成图像部分交给SD等外部模型再组合，带来了更大的开销与不一致性</p>
<hr>
<p>为了专注这一任务，作者的Benchmark优先考虑视觉为中心的任务，例如风格迁移等图像输出的特定要求。</p>
<ul>
<li>作者的数据集和人工标注比较有<strong>较高Pearson相似度，以此说明准确性</strong></li>
<li>作者表示先前没什么<strong>benchmark主要以视觉为中心，以此说明新颖度</strong></li>
<li>但有一说一，作者的表还是有点不公平的，例如它自己的<strong>sample很少</strong>(一千多)，同时评估级别是自己提出的这个四级别评估</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="作者的表">作者的表<a class="hash-link" aria-label="Direct link to 作者的表" title="Direct link to 作者的表" href="https://ayanami1314.github.io/blog/%E7%B2%BE%E8%AF%BB%20%20Interleaved%20Scene%20Graph%20for%20Interleaved%20Text-and-Image%20Generation%20Assessment#%E4%BD%9C%E8%80%85%E7%9A%84%E8%A1%A8">​</a></h2>
<p><img decoding="async" loading="lazy" alt="image-20250530160048840" src="https://ayanami1314.github.io/assets/images/image-20250530160048840-646ee93968c80f9867ea0f316414a5a5.png" width="1052" height="362" class="img_ev3q"></p>
<hr>
<h1>方法</h1>
<p><img decoding="async" loading="lazy" alt="image-20250530153213139 h:500" src="https://ayanami1314.github.io/assets/images/image-20250530153213139-4ceb43c19d4bcc07cdc1baeb75d2408b.png" width="1151" height="576" class="img_ev3q"></p>
<p>注意点: <strong>中间看起来很复杂, 实际上是很多组prompt完成的</strong></p>
<hr>
<p>评估框架将query拆成scene-graph-like structure，<strong>其中图文作为节点，而它们的关系作为边</strong></p>
<p>在整体，结构，块和图四级别的评估中，每个级别都会生成一些用于评估的QA对。作者的意图是，<strong>让整体和结构评估连贯性和整体质量，块和图像评估指令完成的细节</strong></p>
<hr>
<p>结构性：用一个LLM预估图文交替内容的结构，然后与实际生成的内容进行比较</p>
<p><img decoding="async" loading="lazy" alt="image-20250530163448151" src="https://ayanami1314.github.io/assets/images/image-20250530163448151-71150c0f60bd09aee45e9107edd3eaa7.png" width="1060" height="523" class="img_ev3q"></p>
<hr>
<p>整体：MLLM-as-a-Judge和CoT，用1-10打分配合Yes/No判断</p>
<p>块： 将prompt P用LLM表示成三元组 （subj, obj, rel）,再用LLM生成问题，并用VQA评估</p>
<p><img decoding="async" loading="lazy" alt="image-20250530163519317" src="https://ayanami1314.github.io/assets/images/image-20250530163519317-1ba26e8e2cd40c56119403af2ba7b9b9.png" width="1047" height="770" class="img_ev3q"></p>
<hr>
<p>图像：从prompt 给的图像中用LLM抽出三元组关系和实体，判断query类别，根据类别不同使用不同的prompt产生判断的VQA，例如如果是"How to"，则需要包含特定实体，如果是“Painting”，则需要图像的准确生成</p>
<p><img decoding="async" loading="lazy" alt="image-20250530163331400 h:600" src="https://ayanami1314.github.io/assets/images/image-20250530163331400-1b1c3b6298aa1e9aad449957c2e03fd3.png" width="1039" height="679" class="img_ev3q"></p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="实验结果">实验结果<a class="hash-link" aria-label="Direct link to 实验结果" title="Direct link to 实验结果" href="https://ayanami1314.github.io/blog/%E7%B2%BE%E8%AF%BB%20%20Interleaved%20Scene%20Graph%20for%20Interleaved%20Text-and-Image%20Generation%20Assessment#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C">​</a></h3>
<blockquote>
<p>所有统一模型在按照说明生成交错文本和图像内容方面都存在重大缺陷。许多模型只生成 1 到 3 张图像，而有些模型根本无法生成任何图像。</p>
</blockquote>
<blockquote>
<p>整体评估结果与三个细粒度级别的评估结果之间的不一致表明，即使同时提供用户指示和正确的黄金答案，MLLM-as-a-Judge 在全面评估回答方面也存在显着局限性。具体来说，Judge MLLM 努力根据细粒度的标准评估响应，例如输出结构（包括图像数量）和提示中规定的详细文本-图像关系。此外，我们对结果的分析揭示了 <strong>MLLM-as-a-Judge 中固有的偏见</strong>，即“图像质量偏见”，即<strong>具有更高质量图像内容的回答始终获得更高的分数，尽管这些回答可能违反用户的指导要求和评判指南</strong>。这种偏见表明，即使获得了黄金答案，MLLM-as-a-Judge 仍然无法正确地对符合指定要求的交错回答进行准确评估。</p>
</blockquote>
<hr>
<p><img decoding="async" loading="lazy" alt="image-20250530160948640" src="https://ayanami1314.github.io/assets/images/image-20250530160948640-8a5505eaeadfe2ed274a09937abf96eb.png" width="1200" height="519" class="img_ev3q"></p>
<hr>
<h1>效果展示: 跑一次它这个Benchmark要60美刀</h1>
<p><img decoding="async" loading="lazy" alt="image-20250530163815015 h:600" src="https://ayanami1314.github.io/assets/images/image-20250530163815015-79e642937f498c3c9f5bde75cd8d23e3.png" width="1051" height="1016" class="img_ev3q"></p>
<hr>
<h1>结论</h1>
<ol>
<li>MLLM-as-a-judge存在图像质量bias</li>
<li>现有端到端MLLM生成图文内容效果不佳, 可能需要在工程性上的agent做补救</li>
</ol>]]></content:encoded>
            <category>mllm</category>
            <category>ai</category>
            <category>llm</category>
        </item>
        <item>
            <title><![CDATA[ColBERT-后期交互方法]]></title>
            <link>https://ayanami1314.github.io/blog/ColBERT</link>
            <guid>https://ayanami1314.github.io/blog/ColBERT</guid>
            <pubDate>Thu, 29 May 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[如果简单引入语义搜索，那么第一时间想到的肯定是向量搜索的方法]]></description>
            <content:encoded><![CDATA[<p>如果简单引入语义搜索，那么第一时间想到的肯定是向量搜索的方法</p>
<p>先不论小的优化，向量方法现在大体上就是两种架构，单塔和双塔，对应Cross-Encoder和普通的Encoder模型。</p>
<p>双塔模型如下，查询<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">q</span></span></span></span>和文档<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">d</span></span></span></span>分别通过两个独立的编码器，得到向量表示<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mi>v</mi></msub></mrow><annotation encoding="application/x-tex">q_v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>v</mi></msub></mrow><annotation encoding="application/x-tex">d_v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>，然后计算相似度（内积，余弦，等等）。</p>
<p><img decoding="async" loading="lazy" src="https://blog.vespa.ai/assets/2024-02-14-announcing-colbert-embedder-in-vespa/image5.png" alt="overview traditional text embedding models" class="img_ev3q"></p>
<p>而单塔模型则是将查询和文档拼接在一起，输入到一个交叉编码器中，这个交叉编码器很多时候就直接输出相关性得分score了，即为我们所说的reranker</p>
<p>单塔虽然精度远高于双塔，但有无法离线计算的缺点</p>
<p>而双塔的一大精度困境在于，当编码的文档变长时，文档的大部分内容可能都和查询没什么关系，这会导致查询向量和文档向量的相似度计算不准确。实际上，在楼主之前的一些实验之中，一整个很大的文档集合内，和某个查询最无关和最相关的文档的余弦相似度相差也就0.2左右，这就是长文档带来的问题。</p>
<p>但客观地讲，长文档是无法避免的，如果把文档切成更细粒度的句子，在上下文补齐语义，后续合并等麻烦可能更多，并且会出现"长文档实际上是在让相似度检索考虑上下文"这样的情况，一个例子是，问题是"上海交大的用户论坛中，...."，而文档可能是"...水源社区是上海交大的用户论坛。水源社区....." 如果仅在句子等短文本上面匹配，那缺少了上下文的情况下，"水源社区"当然和"上海交大"没什么关系。</p>
<p>那么，如何保证精度的同时又能离线计算呢？</p>
<p>ColBERT的思路是，使用双塔模型来计算相似度，但在编码文档时，<strong>使用了一个更细粒度的向量表示</strong>。</p>
<p>ColBERT<strong>给每个token一个向量表示</strong>，而不是给每个文档一个向量表示。这样，查询和文档的相似度计算就可以在token级别进行。</p>
<p>如下图，ColBERT在拿到最后一层的输出之后（这一层有非常多的语义信息！），将每一个token对应的vector都存下来，这一部分是离线的。</p>
<p>而在计算相似度的时候，将query的tensor和文档的tensor进行一个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>a</mi><mi>x</mi><mi>S</mi><mi>i</mi><mi>m</mi></mrow><annotation encoding="application/x-tex">MaxSim</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span><span class="mord mathnormal">a</span><span class="mord mathnormal">x</span><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="mord mathnormal">im</span></span></span></span>算子</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>a</mi><mi>x</mi><mi>S</mi><mi>i</mi><mi>m</mi></mrow><annotation encoding="application/x-tex">MaxSim</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span><span class="mord mathnormal">a</span><span class="mord mathnormal">x</span><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="mord mathnormal">im</span></span></span></span>是一个最大池化操作，取出<strong>每个token的向量中与查询向量最相似的那个向量</strong>，然后计算相似度。</p>
<p><img decoding="async" loading="lazy" src="https://blog.vespa.ai/assets/2024-02-14-announcing-colbert-embedder-in-vespa/image1.png" alt="overview colbert" class="img_ev3q"></p>
<p>ColBERT的性能是逼近reranker的，这个也很好理解，毕竟交叉编码器的优势就是可以考虑<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo separator="true">,</mo><mi>d</mi></mrow><annotation encoding="application/x-tex">q,d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">d</span></span></span></span>之间的交互，而ColBERT除了保留语义嵌入之外，比起更暴力的加大embedding维度，更重要的是它<strong>保存了上下文次序的信息</strong></p>
<p>而ColBERT的最后一层MaxSim，而没有采用神经网络的方案，让他带来了良好的可解释性</p>
<p><img decoding="async" loading="lazy" src="https://blog.vespa.ai/assets/2024-02-14-announcing-colbert-embedder-in-vespa/image3.png" alt="colbert snippet" class="img_ev3q"></p>
<p>那看了上面立刻就会想到，这每一个token保存一个<code>768/1024/...</code>维的向量，存储开销不会很大吗？</p>
<p>ColBERT也考虑到了这个问题，因此在ColBERTv2中，采用了这样质心编码的方法来降低存储开销，能降低8倍</p>
<ol>
<li>
<p>对每个token的向量进行聚类，得到<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span>个质心（k是一个预定义的数字）</p>
</li>
<li>
<p>对每个token的向量，找到距离最近的质心，并将其索引存储下来，也就是从 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>v</mi><mi>d</mi></msub><mo separator="true">,</mo><mo stretchy="false">)</mo><mo>−</mo><mo>&gt;</mo><mo stretchy="false">(</mo><mn>1</mn><mo separator="true">,</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(v_d, ) -&gt;(1,)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mclose">)</span><span class="mord">−</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mclose">)</span></span></span></span></p>
</li>
<li>
<p>将质心向量库构建ANN索引，例如FAISS, ScaNN</p>
</li>
<li>
<p>在计算相似度时，查询向量也进行同样的处理，找到距离查询最近的质心索引，然后从质心向量库中取出对应的质心向量进行相似度计算</p>
</li>
</ol>
<p>在实际使用的时候，商业rag公司甚至对大规模检索做更狠的二值化向量压缩（说实话这也能检索出来真的有点现代模型神力了），让ColBERT的开销可以和单独的embedding媲美</p>
<p><img decoding="async" loading="lazy" src="https://blog.vespa.ai/assets/2024-02-14-announcing-colbert-embedder-in-vespa/image2.png" alt="colbert token" class="img_ev3q"></p>
<p>二值化的说法是这样的:</p>
<blockquote>
<p>压缩方法通过将正维度表示为 1、负维度表示为 0 来简化文档标记向量。<strong>这种二进制表示有效地指示了文档标记向量中重要语义特征的存在与否</strong>。
<strong>正维度有助于增加点积，表明相关的语义相似性，而负维度则被忽略。</strong></p>
</blockquote>
<p>ColBERT的使用上，很多公司都有了支持，例如vespa, jina等等，开源方案则有早期的ragatouile和后来的上下游如milvus，llamaindex的支持</p>
<p>但是，文档ColBERT还不是它发挥全部潜能的时候，据说SPLADE算法就比他效果好不少（这个我没有实测过），它在图像又活出了第二世，即所谓的ColPali架构</p>
<p>ColPali是MRAG、MLLM那边的新论文和解决方案，几个月的时间砍了1.9k star，ColPali的想法是这样的</p>
<ul>
<li>OCR的多个组件和分块带来误差传播，且预处理流程耗时也长，能不能直接端到端一次使用文档截图解决</li>
<li>但是如果将整页的文档编码成一个向量，肯定精度不够</li>
<li>我的ViT等视觉编码器会将整页文档变成一系列的patch（可以理解为子图），进而变成一系列视觉token，那我重用ColBERT，不就又有了多向量吗？并且这个存储和交互上比每个token存一个向量更合理! 子图本身就有很多的空间位置信息</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20250529232012895" src="https://ayanami1314.github.io/assets/images/image-20250529232012895-e3798d5e7863883d9a90645e57d47f43.png" width="1506" height="916" class="img_ev3q"></p>
<p>并且，你会发现ColBERT的强可解释性在图像上有更关键的作用！模型在文本中关注了什么可能是某个词，还需要人进行一点逻辑推理来判断关系是否合理，而图像中关注了什么，直接看图就知道了！</p>
<p><img decoding="async" loading="lazy" alt="image-20250529232211333" src="https://ayanami1314.github.io/assets/images/image-20250529232211333-f16577089d8023fe748d53489301703c.png" width="1402" height="1150" class="img_ev3q"></p>
<p>作为一种新的RAG范式，ColPali从源头上解决了复杂的OCR和切块的问题</p>
<p>虽然其在重文字领域上的泛化性还留待验证，精度的提升也依赖于未来VLM的发展，但无疑社区已经认同了这个想法的价值</p>
<blockquote>
<p>基于 OCR 的文本提取，以及随后的布局和边界框分析，仍然是重要文档 AI 模型（例如 LayoutLM）的核心。例如， <a href="https://huggingface.co/microsoft/layoutlmv3-base" target="_blank" rel="noopener noreferrer">LayoutLMv3</a> 对文档文本进行编码，包括文本标记序列的顺序、标记或线段的 OCR 边界框坐标以及文档本身。这在关键的文档 AI 任务中取得了最佳成果，但前提是第一步——OCR 文本提取——能够顺利完成。</p>
<p><strong>但通常情况并非如此。</strong></p>
<p>根据我最近的经验，<strong>OCR 瓶颈导致现实世界生产文档档案中的命名实体识别 (NER) 任务的性能下降近 50%。</strong></p>
</blockquote>
<p>目前例如ColQwen2这种ColBERT + Qwen2.5-VL-3B-Instruct的方案也很火，很多榜上都刷到了SOTA，感兴趣的同学也可以自己试试</p>]]></content:encoded>
            <category>ColBERT</category>
            <category>embedding</category>
            <category>rag</category>
        </item>
        <item>
            <title><![CDATA[美团技术博客阅读]]></title>
            <link>https://ayanami1314.github.io/blog/2025/05/26/技术博客阅读 </link>
            <guid>https://ayanami1314.github.io/blog/2025/05/26/技术博客阅读 </guid>
            <pubDate>Mon, 26 May 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[美团外卖基于GPU的向量检索系统实践]]></description>
            <content:encoded><![CDATA[<h3 class="anchor anchorWithStickyNavbar_LWe7" id="美团外卖基于gpu的向量检索系统实践">美团外卖基于GPU的向量检索系统实践<a class="hash-link" aria-label="Direct link to 美团外卖基于GPU的向量检索系统实践" title="Direct link to 美团外卖基于GPU的向量检索系统实践" href="https://ayanami1314.github.io/blog/2025/05/26/%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB%20#%E7%BE%8E%E5%9B%A2%E5%A4%96%E5%8D%96%E5%9F%BA%E4%BA%8Egpu%E7%9A%84%E5%90%91%E9%87%8F%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5">​</a></h3>
<blockquote>
<p>美团外卖的向量检索系统使用了GPU来加速向量检索过程。该系统主要包括以下几个方面： 美团外卖业务特点具有较强的Location Based Service（LBS）依赖，即商家的配送范围，决定了用户所能点餐的商家列表。以商品向量检索场景为例：向量检索结果集需要经过“可配送商家列表”过滤。</p>
</blockquote>
<blockquote>
<p>美团外卖向量检索基于Elasticsearch+FAISS进行搭建，实现了10亿级别+高维向量集的标量+向量混合检索的能力。为了在保证业务高召回率的同时进一步减少检索时间，我们探索基于GPU的向量检索，并实现了一套通用的检索系统。</p>
</blockquote>
<p><strong>相继使用了HNSW（Hierarchical Navigable Small World），IVF（Inverted File），IVF-PQ（Inverted File with Product Quantization）以及IVF-PQ+Refine等算法，基于CPU实现了向量检索能力</strong></p>
<p>在HNSW算法中，这种导航小世界图的层次结构使得搜索过程可以从图的高层开始，快速定位到目标点的大致位置，然后逐层向下精细化搜索，最终在底层找到最近邻，在通用检索场景上有显著的优势。然而<strong>该算法在高过滤比下性能会有折损</strong>，从而导致在到家搜推这种强LBS过滤场景下会暴露其性能的劣势。业界有较多相关的benchmark可以参考，以Yahoo的向量检索系统Vespa相关博客为例</p>
<p><img decoding="async" loading="lazy" alt="图片" src="https://ayanami1314.github.io/assets/images/640-6ecdab7cf574caf7866ef8076970b00a.webp" width="1080" height="678" class="img_ev3q"></p>
<blockquote>
<p>索引吞吐</p>
<p>Observations: 观察结果：</p>
<ul>
<li>Indexing throughput depends on corpus size for Annoy and HNSW, where throughput is halved when corpus size is increased by 10x.
对于 Annoy 和 HNSW，<strong>索引吞吐量</strong>取决于语料库大小，当语料库大小增加 10 倍时，吞吐量就会减半。</li>
<li>Indexing throughput for RPLSH is independent of corpus size.
RPLSH 的索引吞吐量与语料库大小无关。</li>
<li>Annoy is <strong>4.5 to 5 times</strong> faster than HNSW.
Annoy 比 HNSW 快 <strong>4.5 到 5 倍</strong> 。</li>
<li>RPLSH is <strong>23 to 24 times faster</strong> than HNSW at 1M documents.
对于 1M 文档，RPLSH 的<strong>速度比 HNSW 快 23 到 24 倍</strong> 。</li>
</ul>
</blockquote>
<p><img decoding="async" loading="lazy" alt="img" src="https://ayanami1314.github.io/assets/images/indexing-throughput-sift-0d6b3d3501d6d01b8531d2fbf5f73052.png" width="1110" height="686" class="img_ev3q"></p>
<blockquote>
<p>查询吞吐</p>
<p>Observations: 观察结果：</p>
<ul>
<li>HNSW outperforms Annoy and RPLSH. At corpus size 1M the QPS is <strong>9 times as high</strong> as Annoy, and <strong>16 times as high</strong> as RPLSH at comparable quality. Similar observations between hnswlib and Annoy are found in <a href="https://ann-benchmarks.com/" target="_blank" rel="noopener noreferrer">ANN Benchmarks</a>, where the QPS of hnswlib is 5-10 times higher at the same quality on all tested datasets.
HNSW 的表现优于 Annoy 和 RPLSH。在 1M 语料库规模下，其每秒查询速度 (QPS) 是 Annoy 的 <strong>9 倍</strong> ，在同等质量下是 RPLSH 的 <strong>16 倍</strong> 。在 <a href="https://ann-benchmarks.com/" target="_blank" rel="noopener noreferrer">ANN 基准测试</a>中也发现了 hnswlib 与 Annoy 之间的类似现象：在所有测试数据集上，相同质量下 hnswlib 的每秒查询速度 (QPS) 比 Annoy 高 5-10 倍。</li>
<li><strong>HNSW 搜索算法很大程度上取决于节点之间的链接数量，而链接数量又取决于语料库的大小。当语料库规模增加 10 倍时，QPS 会减半</strong>。在索引过程中，我们也看到了同样的情况，因为它使用搜索算法来查找要连接的候选节点。</li>
</ul>
</blockquote>
<p><img decoding="async" loading="lazy" src="https://blog.vespa.ai/assets/2020-06-30-approximate-nearest-neighbor-search-in-vespa-part-1/search-throughput-sift.png" alt="img" class="img_ev3q"></p>
<blockquote>
<p>内存占用</p>
<p>Observations: 观察结果：</p>
<ul>
<li>The Annoy index is almost 3 times larger than the HNSW index, which results in ~40% more total memory usage in the 1M SIFT dataset.
<strong>Annoy 索引几乎比 HNSW 索引大 3 倍</strong>，这导致 1M SIFT 数据集的总内存使用量增加约 40%。</li>
<li>Both indexes are independent of dimension size, but max points in a leaf node (Annoy) and max links per level (HNSW) might need adjustments with higher dimensionality to get decent quality.
这两个索引都与维度大小无关，但叶节点中的最大点数（Annoy）和每级的最大链接数（HNSW）可能需要使用更高的维度进行调整才能获得不错的质量。</li>
</ul>
</blockquote>
<p><a href="https://blog.vespa.ai/approximate-nearest-neighbor-search-in-vespa-part-1/" target="_blank" rel="noopener noreferrer">博客</a>给出了一个很重要的观察是：<strong>当超过 90% 到 95% 的文档被过滤掉时，过滤后计算精确最近邻比搜索 HNSW 索引（过滤器会丢弃候选匹配项）的成本更低</strong></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="22-ivf-inverted-file">2.2 IVF （Inverted File）<a class="hash-link" aria-label="Direct link to 2.2 IVF （Inverted File）" title="Direct link to 2.2 IVF （Inverted File）" href="https://ayanami1314.github.io/blog/2025/05/26/%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB%20#22-ivf-inverted-file">​</a></h4>
<p>IVF是一种基于倒排索引的方法，它将高维向量空间分为多个簇（Cluster），每个簇对应一个倒排列表，存储了属于该簇的向量索引。这种方法大大减少了搜索时需要比较的向量数量，从而<strong>提高了检索速度</strong>。它的缺点是需要存储原始的向量数据，<strong>同时为了保证检索性能需要将其全量加载到内存中，从而占用了大量的内存空间</strong>，容易造成内存资源瓶颈。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="23-ivf-pqinverted-file-with-product-quantization">2.3 IVF-PQ（Inverted File with Product Quantization）<a class="hash-link" aria-label="Direct link to 2.3 IVF-PQ（Inverted File with Product Quantization）" title="Direct link to 2.3 IVF-PQ（Inverted File with Product Quantization）" href="https://ayanami1314.github.io/blog/2025/05/26/%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB%20#23-ivf-pqinverted-file-with-product-quantization">​</a></h4>
<p>在候选集数量巨大的场景下，比如商品向量检索场景下，IVF带来的内存空间大的问题很快就显现出来，为了解决内存空间的问题，开始尝试使用了IVF-PQ方法。该方法在IVF的基础上，使用了<strong>乘积量化（Product Quantization，PQ）的方法来压缩向量数据。PQ将高维向量分为多个子向量，然后对每个子向量进行量化</strong>，从而大大减少了对内存空间的需求。</p>
<p>然而，由于量化过程会引入误差，因此<strong>IVF-PQ的检索精度会低于IVF，从而导致召回率无法满足线上要求，对召回率要求相对较低的场景可以使用IVF-PQ，对召回率有一定要求的场景需要其他解决方案。</strong></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="24-ivf-pqrefine">2.4 IVF-PQ+Refine<a class="hash-link" aria-label="Direct link to 2.4 IVF-PQ+Refine" title="Direct link to 2.4 IVF-PQ+Refine" href="https://ayanami1314.github.io/blog/2025/05/26/%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB%20#24-ivf-pqrefine">​</a></h4>
<p>为了提高IVF-PQ的检索精度，进一步采用了IVF-PQ+Refine的方案，在IVF-PQ的基础上，在SSD磁盘上保存了未经压缩的原始向量数据。<strong>检索时，通过IVF-PQ召回数量更大的候选向量集合，然后获取对应的原始向量数据进行精确计算，从而提高检索精度</strong>。这种方法既保留了IVF-PQ的存储优势，解决了内存资源瓶颈，又保证了召回率，因此在实际应用中得到了广泛的使用。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="25-基于地理位置的向量检索">2.5 基于地理位置的向量检索<a class="hash-link" aria-label="Direct link to 2.5 基于地理位置的向量检索" title="Direct link to 2.5 基于地理位置的向量检索" href="https://ayanami1314.github.io/blog/2025/05/26/%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB%20#25-%EF%BF%BD%E5%9F%BA%E4%BA%8E%E5%9C%B0%E7%90%86%E4%BD%8D%E7%BD%AE%E7%9A%84%E5%90%91%E9%87%8F%E6%A3%80%E7%B4%A2">​</a></h4>
<p><strong>通过将经纬度编码为向量，优化具体做法是将用户或商家的经纬度以加权的方式加入查询Query和候选向量中，在计算Query和候选向量的相似度时，距离因素就可以在不同程度上影响最终的检索结果，从而达到让向量索引具备LBS属性的目标。</strong></p>
<p>这里没有细讲，但怎么具体怎么融入的LBS属性还是比较有意思的，最直接的方法是将经纬度信息直接拼接到现有的文本embedding向量上，也可以将经纬度用geohash，或者以用户为中心的极坐标系统表示?</p>
<p>我觉得最复杂的在于：</p>
<ul>
<li>如何确定经纬度特征的维度，这也算是一种权值</li>
<li>如何让经纬度特征和其他向量特征上对齐？美团是否有一个专用的embedding模型来嵌入地理信息特征，这个模型又是根据什么进行微调的？是类似推荐系统那种基于用户反馈的，还是内部有一个地理加权的人工设计公式，这个模型提供的地理特征使得整体效果向这个公式靠齐的？</li>
</ul>
<p><a href="https://docs.google.com/document/d/1R5nOiwFUn9ZJtuWywmos2yfB4aCWCGy1TUN5VAnMRaY/edit?usp=sharing" target="_blank" rel="noopener noreferrer">https://docs.google.com/document/d/1R5nOiwFUn9ZJtuWywmos2yfB4aCWCGy1TUN5VAnMRaY/edit?usp=sharing</a></p>
<blockquote>
<p>考虑到美团外卖的业务场景，目标方案应该满足以下要求：</p>
<ul>
<li><strong>支持向量+标量混合检索</strong>：在向量检索的基础上，支持复杂的标量过滤条件。</li>
<li><strong>高过滤比</strong>：标量作为过滤条件，有较高的过滤比（大于99%），过滤后候选集大（以外卖商品为例，符合LBS过滤的商品向量候选集仍然超过百万）。</li>
<li><strong>高召回率</strong>：召回率需要在95%+水平。</li>
<li><strong>高性能</strong>：在满足高召回率的前提下，检索耗时Tp99控制在20ms以内。</li>
<li><strong>数据量</strong>：需要支持上亿级别的候选集规模。</li>
</ul>
</blockquote>
<blockquote>
<p>实现向量+标量混合检索，一般有两种方式：前置过滤（pre-filter）和后置过滤（post-filter）。<strong>前置过滤指先对全体数据进行标量过滤，得到候选结果集，然后在候选结果集中进行向量检索，得到TopK结果。后置过滤指先进行向量检索，得到TopK*N个检索结果，再对这些结果进行标量过滤，得到最终的TopK结果</strong>。其中N为扩召回倍数，主要是为了缓解向量检索结果被标量检索条件过滤，导致最终结果数不足K个的问题。</p>
<p>业界已有较多的成熟的全库检索的方案，后置过滤方案可以尽量复用现有框架，开发量小、风险低，<strong>因此我们优先考虑后置过滤方案</strong>。我们基于GPU的后置过滤方案快速实现了一版向量检索引擎，并验证其召回率与检索性能。GPU中成熟的检索算法有Flat、IVFFlat和IVFPQ等，在不做扩召回的情况下，召回率偏低，<strong>因此我们在benchmark上选择了较大的扩召回倍数以提高召回率。</strong></p>
</blockquote>
<p><img decoding="async" loading="lazy" src="https://mmbiz.qpic.cn/sz_mmbiz_png/hEx03cFgUsVShPhmBKFPvZmO6XEY3ficv2O6cewUo5kHicVklOU2wUzECA2q5d0lf8kBFtYI8Jj2HBbvNs0TuQ9w/640?wx_fmt=png&amp;from=appmsg&amp;tp=webp&amp;wxfrom=10005&amp;wx_lazy=1" alt="图片" class="img_ev3q"></p>
<blockquote>
<p><strong>测试结果表明，以上三种算法均无法同时满足我们对检索性能和召回率的需求。其中IVF与IVFPQ召回率较低，Flat算法虽然召回率较高，但是与全体候选集计算向量相似度导致其性能较差。</strong></p>
</blockquote>
<blockquote>
<p><strong>根据用户的地理位置信息计算其GeoHash值，并扩展至附近9个或25个GeoHash块，在这些GeoHash块内采用Flat算法进行向量检索，可以有效减少计算量。这种向量子空间划分方式有效地提高了检索性能，但是存在某些距离稍远的商家无法被召回的情况，最终测得的召回率只有80%左右，无法满足要求。</strong></p>
</blockquote>
<blockquote>
<p>综上，后置过滤方案无法同时满足检索性能和召回率的需求，而GPU版本的Faiss无法实现前置过滤功能，考虑到美团外卖的业务场景，向量+标量混合检索能力是最基本的要求，因此我们决定自研GPU向量检索引擎。</p>
</blockquote>
<blockquote>
<p>基于GPU的向量检索，要想实现前置过滤，一般有三种实现方案：</p>
<ol>
<li>所有<strong>原始数据都保存在GPU显存中，由GPU完成前置过滤</strong>，再进行向量计算。</li>
<li>所有<strong>原始数据都保存在CPU内存中，在CPU内存中完成前置过滤，将过滤后的原始向量数据传给GPU进行向量计算</strong>。(能存更大的数据集)</li>
<li><strong>原始向量数据保存在GPU显存中，其他标量数据保存在CPU内存中，在CPU内存完成标量过滤后，将过滤结果的下标传给GPU，GPU根据下标从显存中获取向量数据进行计算。</strong>（省显存带宽）</li>
</ol>
<p>由于GPU与CPU结构与功能上的差异性，使用GPU完成前置过滤，显存资源占用量更大，过滤性能较差，且无法充分利用过滤比大的业务特点，<strong>因此不考虑方案1</strong>。</p>
<p><img decoding="async" loading="lazy" alt="图片" src="https://ayanami1314.github.io/assets/images/640-1748242298419-5-cc781b495cb0bc8b56c804a537b59a3d.webp" width="1080" height="278" class="img_ev3q"></p>
<p>实验结果表明，方案2在数据拷贝阶段耗时严重，时延无法达到要求。因为在美团外卖的场景下，过滤后的数据集仍然很大，这对CPU到GPU之间的数据传输带宽（A30显卡带宽数据如下 CPU-GPU：PCIe Gen4: 64GB/s；GPU-GPU：933GB/s）提出了很高的要求，<strong>因此我们最终选择了方案3。</strong></p>
</blockquote>
<blockquote>
<p>考虑到显存的价格远高于内存，因此我们在设计方案的过程中，尽可能将数据存储在内存当中，仅将需要GPU计算的数据存储在显存当中。</p>
<p>内存中保存了所有的标量数据，数据<strong>按列存储</strong>，通过位置索引可以快速找到某条数据的所有字段信息，数据按列存储具备较高的灵活性和可扩展性，同时也更容易进行数据压缩和计算加速。针对需要用于过滤的标量字段，<strong>在内存中构造了倒排索引，倒排链中保存了对应的原始数据位置索引信息</strong>，内存数据结构如下图所示</p>
</blockquote>
<p><img decoding="async" loading="lazy" alt="图片" src="https://ayanami1314.github.io/assets/images/640-1748242561687-8-46646c8a46fe5a278b81322532de631c.webp" width="1080" height="1238" class="img_ev3q"></p>
<blockquote>
<p>显存中保存了所有的向量数据，数据位置索引与内存中的数据一一对应，可以通过位置索引快速获取某条数据的向量信息，如下图所示：</p>
<p><img decoding="async" loading="lazy" alt="图片" src="data:image/webp;base64,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" width="1050" height="186" class="img_ev3q"></p>
</blockquote>
<p>最后的流程图(Flat)</p>
<p><img decoding="async" loading="lazy" alt="图片" src="https://ayanami1314.github.io/assets/images/640-1748242653397-14-854b2dbbbffe8af6b1e6a08532e26649.webp" width="1080" height="816" class="img_ev3q"></p>
<p>最后的流程图(IVF)，放宽召回率，提升性能</p>
<p><img decoding="async" loading="lazy" alt="图片" src="https://ayanami1314.github.io/assets/images/640-1748242729349-17-2a9cdd350ddfde26a2e58ee500477319.webp" width="1080" height="856" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" alt="图片" src="https://ayanami1314.github.io/assets/images/640-1748242743071-20-64fd68119b0135d73db5463a38526ce9.webp" width="1080" height="375" class="img_ev3q"></p>
<p><strong>可见，无论是Flat还是IVF，在相同的召回率下，使用前置过滤的性能都要明显好于后置过滤。</strong></p>
<p>性能优化</p>
<ul>
<li>
<p>高并发支持，通过Cuda Stream，GPU可以并行处理多个查询请求，高并发压测下，GPU利用率可以达到100%。</p>
</li>
<li>
<p>通过GPU实现部分标量过滤功能，支持在GPU上实现部分标量过滤功能，向量计算与标量过滤同处一个Kernel，充分利用GPU并行计算能力</p>
</li>
<li>
<p><strong>资源管理优化，支持句柄机制，资源预先分配，重复利用</strong>。每个句柄持有一部分私有资源，包含保存向量检索中间计算结果的可读写内存、显存，以及单独的Cuda Stream执行流；<strong>共享一份全局只读公有资源。在初始化阶段，创建句柄对象池，可以通过控制句柄数量，来调整服务端并发能力，避免服务被打爆。在检索阶段，每次向量检索需从句柄对象池中申请一个空闲的句柄，然后进行后续的计算流程，并在执行完后释放响应的句柄，达到资源回收和重复利用的目的</strong></p>
</li>
</ul>
<p><img decoding="async" loading="lazy" alt="图片" src="https://ayanami1314.github.io/assets/images/640-1748243142566-23-725fd68c9ca6aff07b382e1e9408c08b.webp" width="1080" height="367" class="img_ev3q"></p>
<blockquote>
<p>我们最终选择了单机多卡的数据分片方案，单台服务器部署多张GPU，检索时并行从本地多张GPU中检索数据，在CPU内存中进行数据合并。</p>
<p>为了支持更大规模的向量数据检索，我们还在GPU检索引擎上支持了半精度计算，使用FP16替换原来的FP32进行计算，可以节省一半的GPU显存占用，经验证Flat召回率由100%下降到99.4%，依然满足需求。使用半精度之后，单机可以加载近10亿数据，足够支撑较长时间的业务数据增长。</p>
</blockquote>
<p>GPU 检索系统上线后实际性能数据如下（数据量1亿+）：</p>
<p><img decoding="async" loading="lazy" alt="图片" src="data:image/webp;base64,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" width="1080" height="185" class="img_ev3q"></p>
<hr>
<p>22年还有一篇早期的搜索基于elasticsearch的优化实践</p>
<p><a href="https://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;mid=2651772026&amp;idx=1&amp;sn=6ff4cb024bb416c46d5d2850a6ae77d1&amp;chksm=bd120d378a6584217f1838c0f951204023e5c32b0ad413a731078e2f11f8f0009b39c3dec4ea&amp;scene=21#wechat_redirect" target="_blank" rel="noopener noreferrer">https://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;mid=2651772026&amp;idx=1&amp;sn=6ff4cb024bb416c46d5d2850a6ae77d1&amp;chksm=bd120d378a6584217f1838c0f951204023e5c32b0ad413a731078e2f11f8f0009b39c3dec4ea&amp;scene=21#wechat_redirect</a></p>
<p>但这个就很工程很机架了</p>]]></content:encoded>
            <category>tech blog</category>
            <category>美团</category>
            <category>system</category>
            <category>ai</category>
        </item>
        <item>
            <title><![CDATA[稀疏神经嵌入]]></title>
            <link>https://ayanami1314.github.io/blog/Milvus</link>
            <guid>https://ayanami1314.github.io/blog/Milvus</guid>
            <pubDate>Sun, 25 May 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[下午在看milvus文档的时候看到着重提了稀疏检索，注意到bge-m3是有神经稀疏检索的支持的，于是学习了一下，下面属于纯入门笔记。]]></description>
            <content:encoded><![CDATA[<p>下午在看milvus文档的时候看到着重提了稀疏检索，注意到bge-m3是有神经稀疏检索的支持的，于是学习了一下，下面属于纯入门笔记。</p>
<p><a href="https://bge-model.com/bge/bge_m3.html" target="_blank" rel="noopener noreferrer">https://bge-model.com/bge/bge_m3.html</a></p>
<p><img decoding="async" loading="lazy" alt="image-20250525152523623" src="https://ayanami1314.github.io/assets/images/image-20250525152523623-379d98e15be92bb305e9460ea197f20f.png" width="1141" height="874" class="img_ev3q"></p>
<p>和传统的BM25等稀疏嵌入不同，bge-m3的稀疏嵌入是基于模型的，复用密集嵌入的前面层</p>
<blockquote>
<p>BGE-M3 实现的是一种**“learned sparse embedding”（神经稀疏语义嵌入**）。与 SPLADE、uniCOIL 这类模型类似，这些都是让模型自适应学习每个 token 某种“匹配权重”，在大规模预训练和下游 fine-tune 时引入了专门的稀疏激活目标，使输出稀疏且有用</p>
</blockquote>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/v2/resize:fit:1050/0*_IxiJuTn_LTcDlq2.png" alt="From tokens to BERT dense embeddings" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/v2/resize:fit:1050/0*lmMjfFrUs1-VikZ_.png" alt="From tokens to sparse embeddings.png" class="img_ev3q"></p>
<p>SPLADE 模型的全称为"Sparse Lexical and Expansion Model"（稀疏词法和扩展模型），结合了传统稀疏向量检索的优点和神经网络的语义理解能力。</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>j</mi></msub><mo>=</mo><mi>m</mi><mi>a</mi><msub><mi>x</mi><mrow><mi>i</mi><mo>∈</mo><mi>t</mi><mi>o</mi><mi>k</mi><mi>e</mi><mi>n</mi><mi>s</mi></mrow></msub><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><mi>R</mi><mi>e</mi><mi>L</mi><mi>U</mi><mo stretchy="false">(</mo><msub><mi>w</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">w_j = max_{i\in tokens} log(1 + ReLU(w_{ij}))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">ma</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">∈</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em">g</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em"></span><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.10903em">LU</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mclose">))</span></span></span></span></p>
<p><img decoding="async" loading="lazy" alt="image-20250525155231480" src="https://ayanami1314.github.io/assets/images/image-20250525155231480-44fe88ea18a1d74d6f97bc797f54a880.png" width="980" height="323" class="img_ev3q"></p>
<p>BERT 的 MLM 头部会为每个输入位置计算对词汇表中每个词元的贡献分数。这些分数反映了当前上下文下，特定词元与其他词元的关联强度。</p>
<p><img decoding="async" loading="lazy" src="https://www.pinecone.io/_next/image/?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fvr8gru94%2Fproduction%2F81ba987ca3713008eb0b9ecaf1a4680d03fcff5f-2185x743.png&amp;w=3840&amp;q=75" alt="Term expansion in the query can lead to much greater overlap between queries and relevant documents, helping us minimize the vocabulary mismatch problem." class="img_ev3q"></p>
<p>也就是说，这个方法实际处理了三个问题:</p>
<ol>
<li>词表不够大（或者分词精度不够）的问题，采用预训练BERT的词表和分词器，可以随着预训练模型的拓展而拓展；</li>
<li>针对传统稀疏编码需要精确词匹配、编码值实际上都是离散变化的问题，采用遍历整个词表，利用BERT的mask-预测概率，计算将原始句子的每一个词与词汇表中其他词的<strong>关联强度</strong>，对应logits即为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span>，从而实现了词汇的拓展，允许相关词、近义词匹配等</li>
<li>针对传统BM25中没有上下文位置关系的问题，利用BERT的位置编码和捕获双向信息的预测，将传统手工设计特征的部分取代</li>
</ol>
<p>还有一些其他的操作比如稀疏化，用于提供较密集嵌入更强的筛选能力</p>
<p>SPLADE 使用 ReLU 激活和 MAX 池化操作来确保生成稀疏向量。ReLU 将负值置为零，增加稀疏性；MAX 池化则为每个词元选择所有位置中的最大贡献值，进一步增强了稀疏性 <a href="https://www.pinecone.io/learn/splade/" target="_blank" rel="noopener noreferrer">1</a>。</p>
<p>此外，SPLADE 还使用正则化（如 FLOPS 正则化）来控制稀疏性程度：</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">L_FLOPS = λ * ||q_splade||_1 * ||d_splade||_1</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>这个正则化项通过惩罚向量的 L1 范数（非零元素的绝对值和）来鼓励模型生成更稀疏的向量</p>
<p>还有一个问题是：这个“关联强度"是什么?</p>
<p>从模型的角度说，这个关联强度向量就是BERT的嵌入再过一个MLP得到<code>(vocab_size, )</code>的向量</p>
<p>但实际上，这里并没有直接使用BERT的mask预测权重，而是针对信息检索进行了微调（使用MS MARCO数据集，100万条搜索引擎搜索数据）</p>
<p><img decoding="async" loading="lazy" alt="image-20250525160740142" src="https://ayanami1314.github.io/assets/images/image-20250525160740142-b41c4821f26321a294df4b6abce5d0ca.png" width="1459" height="800" class="img_ev3q"></p>
<p>最后的损失函数是三者的加权组合</p>
<p>目前SPLADE稀疏向量的召回率已经显著由于BM25传统搜索引擎的召回率</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/v2/resize:fit:1155/1*nfUexIXcqoIaDUFLYcPtwg.png" alt="img" class="img_ev3q"></p>
<p>但是BM25等传统方法就完全不行了吗？也未必，有文章指出SPLADE这样的基于模型的方法始终会受到预训练语料的领域限制，并且在垂域少量数据上训练/微调的成本开销都比较大，此时未必有简单的BM25 + 领域定制词典权重好</p>
<p>而作为召回的一道路径来说，还有许多额外的召回规则，例如通配符和前缀，编辑距离和短语......</p>
<hr>
<p>很fashion的reranker <a href="https://www.mixedbread.com/blog/mxbai-rerank-v2" target="_blank" rel="noopener noreferrer">https://www.mixedbread.com/blog/mxbai-rerank-v2</a></p>
<p>双模搜索：<a href="https://www.mixedbread.com/blog/the-hidden-ceiling" target="_blank" rel="noopener noreferrer">https://www.mixedbread.com/blog/the-hidden-ceiling</a></p>
<p>做了一系列实验证明了OCR质量在RAG系统中的重要性和目前的OCR方法质量的局限性，多模态生成用于检索的编码，OCR生成嵌入：检索时用能理解文本布局、复杂图表的多模态嵌入，而进入LLM的时候用OCR生成的文本</p>
<ul>
<li>他们也实验了使用图片/嵌入直接进视觉LLM，但效果不佳。提出的观点是LLM能够容忍文本的噪声和解析错误（文字质量下降），但不太能容忍精致且无关的文本（搜索质量下降），在传统rag流程中，OCR质量下降会直接导致搜索质量下降</li>
</ul>]]></content:encoded>
            <category>milvus</category>
            <category>sparse embedding</category>
        </item>
        <item>
            <title><![CDATA[RocketMQ学习]]></title>
            <link>https://ayanami1314.github.io/blog/RocketMQ</link>
            <guid>https://ayanami1314.github.io/blog/RocketMQ</guid>
            <pubDate>Sat, 24 May 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[mq: 异步，解耦，削峰填谷]]></description>
            <content:encoded><![CDATA[<p>mq: 异步，解耦，削峰填谷</p>
<p>传统项目架构下，对网络波动没有耐受性</p>
<p>mq多用于分布式系统间进行通信</p>
<p>请求方/响应方 <code>-&gt;</code> 生产者/消费者</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="优劣">优劣<a class="hash-link" aria-label="Direct link to 优劣" title="Direct link to 优劣" href="https://ayanami1314.github.io/blog/RocketMQ#%E4%BC%98%E5%8A%A3">​</a></h3>
<p>优势：异步，解耦，削峰填谷</p>
<ul>
<li>解耦: 消费方存活与否不影响生产方</li>
<li>异步: 提速</li>
<li>削峰填谷（作为一个buffer/cache）, 提升系统稳定性，应对突发性高并发冲击</li>
</ul>
<p>例子-电子商务下单：</p>
<p>生产者: 订单系统 <code>-&gt;</code> MQ <code>-&gt;</code> 库存系统、支付系统、物流系统、大数据系统(用户数据收集)（复制与多分发）</p>
<p>生产者发完消息，可以继续下一步业务逻辑</p>
<p>订单系统不需要新增业务代码，达成解耦</p>
<p>同时，订单系统可以发MQ消息之后就返回。准确地说，MQ消息 + 订单入库(校验等)</p>
<p>劣势：</p>
<ul>
<li>可用性降低: MQ宕机就寄，需要保证MQ的高可用</li>
<li>系统复杂度提高：<strong>消息丢失? 消息保序？重复消费？</strong></li>
<li>一致性问题：多消费，部分成功，部分失败？下游失败怎么办？</li>
</ul>
<p>市面主流MQ产品：</p>
<ul>
<li>ActiveMQ: 万级吞吐，主从架构，ms延迟，现在不怎么用</li>
<li>RabbitMQ: erlang，us处理，万级吞吐，主从架构，较难维护</li>
<li>RocketMQ: java，十万级吞吐，ms级，分布式</li>
<li>kafka: scala， 十万级，ms级，分布式，功能比较少</li>
</ul>
<p>rocketmq: 17年双十一，TPS 5600w</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="架构">架构<a class="hash-link" aria-label="Direct link to 架构" title="Direct link to 架构" href="https://ayanami1314.github.io/blog/RocketMQ#%E6%9E%B6%E6%9E%84">​</a></h3>
<p>生产者集群 Producer</p>
<p>消息服务器集群 Broker 接受消息，提供消息，消息持久化，过滤消息，高可用</p>
<p>消费者 Consumer</p>
<p>命名服务器集群 NameServer Cluster 存储元数据**（Broker IPs）**</p>
<p>producer，broker，consumer向nameserver注册，nameserver用心跳确认其他组件的存活</p>
<p><img decoding="async" loading="lazy" alt="image-20250524133745882" src="https://ayanami1314.github.io/assets/images/image-20250524133745882-2079dd6b627ccbcc592dcdba316130f8.png" width="1723" height="844" class="img_ev3q"></p>
<p>支持拉推两种模式，Consumer可以主动拉取，也可以用监听器模式</p>
<p>能推肯定是推省资源，免去轮询等</p>
<p>消息</p>
<ul>
<li>Message</li>
<li>Topic 一级标题</li>
<li>Tag 二级标题</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="基础流程">基础流程:<a class="hash-link" aria-label="Direct link to 基础流程:" title="Direct link to 基础流程:" href="https://ayanami1314.github.io/blog/RocketMQ#%E5%9F%BA%E7%A1%80%E6%B5%81%E7%A8%8B">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="producer">Producer：<a class="hash-link" aria-label="Direct link to Producer：" title="Direct link to Producer：" href="https://ayanami1314.github.io/blog/RocketMQ#producer">​</a></h4>
<p>生产者创建 - 设置nameserver - 生产者启动 - 创建消息（指定topic，tag，内容）- 发送（获取结果）- 关闭生产者</p>
<p>发送结果是什么？主要是记录消息元数据例如消息ID的一个结构体，和<code>Future</code>那种设计不一样</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="consumer">Consumer<a class="hash-link" aria-label="Direct link to Consumer" title="Direct link to Consumer" href="https://ayanami1314.github.io/blog/RocketMQ#consumer">​</a></h4>
<p>两类： <code>DefaultLitePullConsumer</code> 和 <code>DefaultMQPushConsumer</code></p>
<p>对应拉取(额外线程轮询)和推送(长连接)模式</p>
<p>消费者创建 - 设置nameserver - 设置监听(订阅)主题 - 注册监听器(消息处理函数类，返回消息处理结果) - 消费者启动</p>
<p>设置监听的api rocketmq是这样设计的</p>
<p><code>subscribe(&lt;topic&gt;, &lt;subExpression&gt;)</code></p>
<p>这个<code>subExpression</code>通过通配符等支持，让api 表达力变强不少</p>
<ul>
<li>支持tag过滤</li>
<li>支持sql过滤，在给<strong>消息追加属性</strong>的时候很有用<!-- -->
<ul>
<li><code>&gt;&lt;=</code> <code>BETWEEN</code> <code>IN</code> <code>IS NULL</code> <code>AND</code> <code>OR</code> <code>NOT</code></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="onetomany-多消费">OneToMany 多消费<a class="hash-link" aria-label="Direct link to OneToMany 多消费" title="Direct link to OneToMany 多消费" href="https://ayanami1314.github.io/blog/RocketMQ#onetomany-%E5%A4%9A%E6%B6%88%E8%B4%B9">​</a></h3>
<p>多个消费者监听一个topic的默认行为：</p>
<ul>
<li><strong>一条消息只会被消费一次</strong></li>
<li><strong>多个消费者之间有默认的负载均衡</strong></li>
</ul>
<p>如果想要多个消费者都消费这条消息呢？例如上面的电商情况</p>
<ul>
<li><strong>消费者组</strong> consumer group概念</li>
</ul>
<p>相同组的消费者，有负载均衡，单消费</p>
<ul>
<li><strong>也可以修改消息模式</strong>，将默认的消费模式改掉<!-- -->
<ul>
<li><code>CLUSTERING -&gt; BROADCASTING</code></li>
</ul>
</li>
</ul>
<p>单条消息会被<strong>复制数份</strong>，发送到每一个消费者组</p>
<ul>
<li>“复制”是指HTTP传数次，不是存储文件复制</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="消息类型">消息类型<a class="hash-link" aria-label="Direct link to 消息类型" title="Direct link to 消息类型" href="https://ayanami1314.github.io/blog/RocketMQ#%E6%B6%88%E6%81%AF%E7%B1%BB%E5%9E%8B">​</a></h3>
<p>同步：即时性强、必须有回执，例如短信通知</p>
<p>异步：即时性弱，也需要有回执，如订单信息</p>
<p>单向：不需要有回执，如写日志</p>
<ul>
<li>eg 分布式日志系统，所有Producer只管发</li>
</ul>
<p>直接<code>send(msg)</code> 是发同步消息</p>
<p><code>send(msg, callback)</code>是异步，等有结果再做处理</p>
<p><code>sendOneway</code>是单向</p>
<p>延时消息</p>
<p>早期: v4.x</p>
<p>只支持不同的delayLevel，固定的1s 1m这样的时间</p>
<ul>
<li>固定级别的延时消息实现简单，<strong>为每个延时类别创建单独的队列来管理， 采用内部特定主题（SCHEDULE_TOPIC_XXXX）和队列来实现延时功能</strong></li>
<li>可能是简单的分队列定时扫描算法</li>
</ul>
<p>后来：v5+</p>
<p>任意毫秒级时间戳延时，需要高效时间轮算法, 每条消息单独计时器跟踪</p>
<ul>
<li>
<p><strong>时间轮算法</strong>：小时轮，分钟轮，秒钟轮。将消息“填入时间轮槽”（即每个槽是一个<code>TaskList</code>）</p>
<ul>
<li><strong>层级时间轮</strong>，如果一个任务是1分30s, 会先被放入1分的分钟轮，处理到时，减去1分，降级放入秒钟轮</li>
</ul>
</li>
<li>
<p>将时间线分割成多个区间，不同区间采用不同精度的扫描策略, 近期消息采用高精度扫描，远期消息采用低频率扫描</p>
</li>
<li>
<p>高效索引，分布式时钟对齐.....</p>
</li>
</ul>
<p>批量消息</p>
<p>底层支持直接传 <code>Collection&lt;Message&gt;</code></p>
<p>注意:</p>
<ul>
<li>相同的topic</li>
<li>不能是延时消息</li>
<li>总长度不超过<strong>4M</strong> (IBM默认最大消息长度设置，可以通过改环境变量修改，但4M算是一个实验值)</li>
<li>相同的waitStoreMsgOK</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="spring-ioc集成">Spring IoC集成<a class="hash-link" aria-label="Direct link to Spring IoC集成" title="Direct link to Spring IoC集成" href="https://ayanami1314.github.io/blog/RocketMQ#spring-ioc%E9%9B%86%E6%88%90">​</a></h3>
<p>直接在配置文件中指定name-server， producer group之类</p>
<p>类似Kafka/Redis, <code>RocketMQTemplate</code> 链接管理</p>
<p><code>convertAndSend</code> 方法</p>
<ul>
<li><code>convert</code>? Spring的Template send发送的是抽象的message，只有一个<code>byte[]</code>的<code>payload</code>，convert就是在处理上层java类与下层不同的template需要的通信格式的转换</li>
</ul>
<p>消费者也是和Kafka类似的</p>
<p><code>@Service</code>的类 <code>implements RocketMQListener&lt;MessageType&gt;</code> 就行,  <code>@RocketMQListener(topic=, tag=,consumerGroup=, selctorExpression=, selectorType=, messageModal=)</code></p>
<p>然后这个类就作为监听类了，调用的方法就是重载方法<code>onMessage(T t)</code></p>
<p>(这里Spring顺带还做了个返回值处理，只要没抛异常都是消费成功，抛异常消费失败回传)</p>
<p>其他的机制也整合了，例如同步异步单向延时批量之类对应<code>syncSend, asyncSend, ...</code></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="消息保序">消息保序<a class="hash-link" aria-label="Direct link to 消息保序" title="Direct link to 消息保序" href="https://ayanami1314.github.io/blog/RocketMQ#%E6%B6%88%E6%81%AF%E4%BF%9D%E5%BA%8F">​</a></h3>
<p>消息错乱的原因，队列内有序，队列外无序</p>
<p>要做多队列的负载均衡，就不能无开销严格保证顺序</p>
<p>一连串的消息需要作为一个不能被拆分到多个负载均衡队列的整体</p>
<ul>
<li>一个实现<code>messagequeueSelector</code>的实体类，例如id hash + 取模</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="事务消息无丢">事务消息（无丢）<a class="hash-link" aria-label="Direct link to 事务消息（无丢）" title="Direct link to 事务消息（无丢）" href="https://ayanami1314.github.io/blog/RocketMQ#%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF%E6%97%A0%E4%B8%A2">​</a></h3>
<p><img decoding="async" loading="lazy" alt="image-20250524165007633" src="https://ayanami1314.github.io/assets/images/image-20250524165007633-44d4c669017b42796867ad8a572764af.png" width="1621" height="776" class="img_ev3q"></p>
<p>本地事务：如入本地数据库</p>
<p>事务状态：</p>
<ul>
<li>提交状态，允许进入队列</li>
<li>回滚状态，不允许进入队列，当作没发生过</li>
<li>中间状态，未对half做二次确认</li>
</ul>
<p>代码实现</p>
<p><code>TransactionMQProducer</code></p>
<p><code>setTransactionListener</code>: 正常事务过程, 补偿过程</p>
<ul>
<li><code>executeLocalTransaction</code>: 正常事务，入库等，根据本地事务状态返回消息状态</li>
<li><code>checkLocalTransaction</code>：在正常事务超时等情况（实际上是正常事务函数返回了<code>UNKNOW</code>状态）时被调用，本地再次查询事务状态的函数</li>
</ul>
<p>事务补偿还是<code>UNKNOW</code>?写个log或者其他人工介入方式</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="集群搭建">集群搭建<a class="hash-link" aria-label="Direct link to 集群搭建" title="Direct link to 集群搭建" href="https://ayanami1314.github.io/blog/RocketMQ#%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA">​</a></h3>
<p>多broker：</p>
<p>多master多slave架构</p>
<p>master slave同步消息的方式可以是同步（生产者阻塞请求）也可以是异步（不阻塞）</p>
<p>常见：一主三从</p>
<ul>
<li>只有brokerId为0的是主节点</li>
<li>brokerName是集群名</li>
</ul>
<p>每一个broker会向<strong>所有的</strong>nameserver注册</p>
<p><img decoding="async" loading="lazy" alt="image-20250525132947941" src="https://ayanami1314.github.io/assets/images/image-20250525132947941-9a53ed1bdc0ac1caef4e61df5db97513.png" width="1576" height="521" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="高级特性">高级特性<a class="hash-link" aria-label="Direct link to 高级特性" title="Direct link to 高级特性" href="https://ayanami1314.github.io/blog/RocketMQ#%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7">​</a></h3>
<p>消息存储</p>
<p>一次完整的消费需要两个ACK</p>
<p>即Producer向Broker发消息，Broker返回ACK</p>
<p>Broker向Consumer发消息，Consumer返回ACK</p>
<p>但如果中间Broker宕机，就会出现重复消费</p>
<p>例如，在Broker返回ACK之前宕机，Producer就可能再发一次消息；在Consumer返回ACK之前宕机，Broker就可能再发一次消息。</p>
<p>解决方案是，<strong>在Broker返回Producer ACK之前，先将消息存储到磁盘上持久化（数据库中），在接收到Consumer ACK之后，Broker删除这一条消息</strong></p>
<ul>
<li>如果在返回Producer ACK之前宕机，能从磁盘读消息避免重发</li>
<li>如果在Consumer返回ACK之前宕机，也是同理</li>
</ul>
<p>消息的存储介质</p>
<p>使用<strong>数据库</strong>：</p>
<ul>
<li>ActiveMQ：缺点是<strong>数据库瓶颈成为MQ瓶颈</strong></li>
</ul>
<p><strong>文件系统</strong>：</p>
<ul>
<li><strong>RocketMQ/Kafka/RabbitMQ：采用消息刷盘机制，进行数据存储</strong></li>
</ul>
<p>zero copy：mmap，java MappedByteBuffer</p>
<p>预留了一块空间进行顺序读写，默认1G commitlog</p>
<p>本质上，利用<code>mmap</code>,<code>sendfile</code>等系统api减少了<strong>内核空间与用户空间</strong>的数据交换次数。<code>mmap</code>处理<code>文件-内存</code>在内核态直通，<code>sendfile</code>处理<code>内存-网络</code>在内核态直通。省去的是内核态内存页到用户态内存页的拷贝，zero copy的用户程序都是没有持有数据copy的buffer的。</p>
<p><img decoding="async" loading="lazy" alt="image-20250525135808051" src="https://ayanami1314.github.io/assets/images/image-20250525135808051-fd6ae5ce6cf4bf10575448fffe1f8747.png" width="1557" height="859" class="img_ev3q"></p>
<p>刷盘机制</p>
<p>同步刷盘：先<strong>入盘</strong>再返回ACK</p>
<ul>
<li>可靠性高，性能低</li>
</ul>
<p>异步刷盘：<strong>不挂起Producer线程</strong>，也先不写硬盘，<strong>将消息保留到内存之后就向Producer返回ACK</strong>，而是<strong>积累到一定batch的消息，再批量刷盘</strong></p>
<p>高可用：</p>
<ul>
<li>nameserver:<!-- -->
<ul>
<li>无状态+全服务器注册</li>
</ul>
</li>
<li>消息服务器<!-- -->
<ul>
<li>主从架构，2主2从</li>
</ul>
</li>
<li>消息生产<!-- -->
<ul>
<li>生产者将相同的topic绑定到多个group组，保障master挂掉之后，其他master仍然可以正常接受消息</li>
</ul>
</li>
<li>消息消费：RocketMQ会根据master压力确认是否由master承担数据读取功能，master繁忙的时候，自动切换slave做承担数据读取的工作（<strong>读写分离</strong>）</li>
</ul>
<p>负载均衡</p>
<p>Producer负载均衡</p>
<ul>
<li>RocketMQ内部实现了不同broker集群中对同一topic对应消费队列的负载均衡</li>
</ul>
<p>Consumer负载均衡</p>
<ul>
<li>平均分配(AABBCC)不好，循环平均分配(ABCABC)好<!-- -->
<ul>
<li>原因，broker部分挂掉时，生产者的流量会被均分到剩下的broker上，如果平均分配，则有些对应挂掉的broker的consumer就不干活了，其他consumer压力会变大；循环平均分配则是将所有的consumer都分到剩下的broker上，避免了单个consumer压力过大</li>
</ul>
</li>
</ul>
<p>消息重试：</p>
<p>顺序消息：</p>
<ul>
<li>当消费消息失败后，RocketMQ会以1s为间隔进行自动重试。</li>
<li>应用会出现消息消费被阻塞的情况，因此需要对顺序消息的消费情况进行监控（监控offset等），避免阻塞</li>
</ul>
<p>无序消息：</p>
<ul>
<li>
<p>仅适用于负载均衡（集群）模型下的消息消费，不适用于广播模式</p>
</li>
<li>
<p>MQ设定了合理的消息重试间隔时长，有一个指数的backoff</p>
</li>
<li>
<p>当重试到达指定次数（默认16次）后，MQ将无法被正常消费的消息称为死信消息。<strong>死信消息不会被直接抛弃，而是会被发送到一个死信队列中</strong>，供后续处理</p>
</li>
</ul>
<p>死信消息不会再被重复消费，有效期为3天，过时后会被删除</p>
<p>死信处理，业务逻辑处理，或者人工介入</p>
<p>RocketMQ不可能完全避免重复消费，还是存在可能出现重复消费的情况：</p>
<ul>
<li>生产者发送重复消息，例如，网络闪断没收到ACK，生产者宕机</li>
<li>Broker和消费者之间网络闪断，消费者/broker重启</li>
<li>客户端扩缩容</li>
<li>......</li>
</ul>
<p><strong>所以不能完全依赖RocketMQ的幂等性，还是要在业务逻辑上做幂等性处理</strong></p>
<ul>
<li>使用业务id作为消息key</li>
<li>在消费消息时，客户端对key做判定，未使用放行，使用过抛弃</li>
<li>注意：messageId由RocketMQ生成，不具有唯一性，不能做幂等判定条件</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="kafka-vs-rocketmq">Kafka VS RocketMQ<a class="hash-link" aria-label="Direct link to Kafka VS RocketMQ" title="Direct link to Kafka VS RocketMQ" href="https://ayanami1314.github.io/blog/RocketMQ#kafka-vs-rocketmq">​</a></h3>
<p><strong>Kafka:</strong></p>
<ul>
<li><strong>专注简单与吞吐量</strong>: "Do one thing and do it well"的Unix哲学，专注于高吞吐的消息传递</li>
<li><strong>不可变数据流</strong>: 将消息视为不可变的数据流，适合事件溯源和流处理</li>
<li><strong>客户端复杂性</strong>: 将复杂性推向客户端，保持服务端简单高效</li>
</ul>
<p><strong>RocketMQ:</strong></p>
<ul>
<li><strong>丰富的消息功能</strong>: 目标是作为全功能的企业级消息系统</li>
<li><strong>服务端智能</strong>: 在服务端实现更多功能，减轻客户端负担</li>
<li><strong>电商场景驱动</strong>: 由阿里巴巴电商业务需求驱动设计，面向复杂业务场景</li>
</ul>
<p>那么古尔丹，高吞吐量的代价是什么呢？</p>
<ul>
<li>偏移量指针的设计只能顺序前进，无法原生支持延迟时间，通过时间戳索引查找偏移量、专用延时主题、定时扫描来达到延时队列</li>
<li>必须顺序处理消息，无法灵活跳过（异常消息）和回退（重放）</li>
<li>消息路由和分布式一致性绑定，路由灵活性受限</li>
<li>不支持消息优先级队列，因为都得按照offset指针顺序处理.....</li>
<li>无法设置可见性超时等，都需要上层应用做</li>
<li>消费失败的幂等性保证处理复杂，偏移量需要分布式维护增加网络开销.....</li>
</ul>
<table><thead><tr><th>特性</th><th>Kafka</th><th>RocketMQ</th></tr></thead><tbody><tr><td>定时/延时消息</td><td>需外部实现</td><td>原生支持 <a href="https://rocketmq.apache.org/docs/" target="_blank" rel="noopener noreferrer">1</a></td></tr><tr><td>消息回溯</td><td>支持(通过偏移量)</td><td>支持(更灵活) <a href="https://rocketmq.apache.org/docs/" target="_blank" rel="noopener noreferrer">1</a></td></tr><tr><td>消息过滤</td><td>有限支持</td><td>服务器端支持SQL92表达式过滤 <a href="https://rocketmq.apache.org/docs/" target="_blank" rel="noopener noreferrer">1</a></td></tr><tr><td>事务消息</td><td>有限支持</td><td>完整支持 <a href="https://rocketmq.apache.org/docs/" target="_blank" rel="noopener noreferrer">1</a></td></tr><tr><td>死信队列</td><td>不支持</td><td>支持</td></tr><tr><td>消息优先级</td><td>不支持</td><td>不直接支持，但可通过设计实现</td></tr><tr><td>多租户隔离</td><td>有限支持</td><td>更好支持</td></tr><tr><td>消息轨迹追踪</td><td>需外部工具</td><td>原生支持 <a href="https://rocketmq.apache.org/docs/" target="_blank" rel="noopener noreferrer">1</a></td></tr></tbody></table>
<p>核心设计的哪些不同带来了这样的差异？</p>
<p>存储模型</p>
<p><strong>Kafka:</strong></p>
<ul>
<li><strong>分散的文件存储</strong>: 每个主题的每个分区对应一个物理文件，消息按照写入顺序存储 <a href="https://rocketmq.apache.org/docs/" target="_blank" rel="noopener noreferrer">1</a></li>
<li><strong>顺序追加写入</strong>: 使用顺序追加的方式写入文件，不允许修改已写入的数据</li>
<li><strong>偏移量指针</strong>: 消费者通过偏移量指针确定读取位置，不复制消息</li>
</ul>
<p><strong>RocketMQ:</strong></p>
<ul>
<li><strong>统一的文件存储</strong>: 所有主题的消息存储在同一组物理文件中 <a href="https://alibaba-cloud.medium.com/kafka-vs-rocketmq-multiple-topic-stress-test-results-d27b8cbb360f" target="_blank" rel="noopener noreferrer">3</a></li>
<li><strong>逻辑分区</strong>: 主题和队列仅是逻辑概念，不与物理文件一一对应</li>
<li><strong>消息索引</strong>: 维护更复杂的索引结构，支持按多种方式查询消息</li>
</ul>
<p>消息投递模型</p>
<p><strong>Kafka:</strong></p>
<ul>
<li><strong>基于分区的消费模型</strong>: 消费者组内的消费者分配分区，消费者只能按顺序消费分区中的消息 <a href="https://rocketmq.apache.org/docs/" target="_blank" rel="noopener noreferrer">1</a></li>
<li><strong>仅支持拉模式</strong>: 消费者主动从Broker拉取消息</li>
</ul>
<p><strong>RocketMQ:</strong></p>
<ul>
<li><strong>更灵活的消费模型</strong>: 支持更多的消费模式，包括集群消费和广播消费 <a href="https://rocketmq.apache.org/docs/" target="_blank" rel="noopener noreferrer">1</a></li>
<li><strong>推拉结合</strong>: 同时支持推模式和拉模式，提供更灵活的消息投递方式</li>
<li><strong>消息过滤</strong>: 支持在服务器端进行消息过滤，减少不必要的网络传输</li>
</ul>
<p>消息处理机制</p>
<p><strong>Kafka:</strong> 消息就是字节数组</p>
<p>**RocketMQ: ** 消息包含更多元数据和属性</p>]]></content:encoded>
            <category>mq</category>
        </item>
        <item>
            <title><![CDATA[ucb cs186 课程笔记(更新中)]]></title>
            <link>https://ayanami1314.github.io/blog/cs186-database-WIP</link>
            <guid>https://ayanami1314.github.io/blog/cs186-database-WIP</guid>
            <pubDate>Wed, 12 Feb 2025 13:56:21 GMT</pubDate>
            <description><![CDATA[lec2]]></description>
            <content:encoded><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="lec2">lec2<a class="hash-link" aria-label="Direct link to lec2" title="Direct link to lec2" href="https://ayanami1314.github.io/blog/cs186-database-WIP#lec2">​</a></h2>
<p>join: inner join, natural join, outer join</p>
<p>sql  实际执行模型 写起来是 SELECT - FROM - GROUP BY - HAVING - WHERE - DISTINCT - ORDER BY</p>
<p>实际是 FROM(table过滤) - GRUOP BY(行分组) - HAVING(组过滤) - WHERE(行过滤) - DISTINCT(行去重) - SELECT(行内列过滤)</p>
<p>inner join:叉积，对AB所有行组合</p>
<div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">SELECT</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">FROM</span><span class="token plain"> TABLE1 t1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> TABLE2 t2 </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	</span><span class="token keyword" style="color:#00009f">WHERE</span><span class="token plain"> t1</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">id </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> t2</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">id</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	</span><span class="token operator" style="color:#393A34">AND</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">-- 等效于</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">SELECT</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">FROM</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	TABLE1 t1 </span><span class="token keyword" style="color:#00009f">INNER</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">JOIN</span><span class="token plain"> TABLE2 t2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">ON</span><span class="token plain"> t1</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">id </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> t2</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">id</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">WHERE</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">-- 下面这种更加清晰一点</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">-- 等效于</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">SELECT</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">FROM</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	TABLE1 t1 </span><span class="token keyword" style="color:#00009f">NATURAL</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">JOIN</span><span class="token plain"> TABLE2 t2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">WHERE</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">-- natural join就是在组合的基础上自动用了一个过滤，要求table所有相同名字的列的值都相同</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>outer join:</p>
<p>Left Outer join:</p>
<p><code>A LEFT OUTER JOIN B ON cond</code> 如果cond满足的话，得到的是AB的组合（一行有A的列+B的列）;如果不满足，得到A的列+空</p>
<p>Right Outer Join 同理</p>
<p>Full Outer Join 同理 例如<code>ON A.id = B.id</code></p>
<p>如果有A没有对应的B, 那就是是 A + 空</p>
<p>如果有B没有对应的A, 那就是 空 + B</p>
<p>非常好的图</p>
<p><img decoding="async" loading="lazy" alt="db-join" src="https://ayanami1314.github.io/assets/images/image-f9fa91e00a44e27c8e39a9d1bf4c6d74.png" width="1419" height="322" class="img_ev3q"></p>
<p>alias</p>
<p>简化 + 看起来更清楚（尤其是self-join）</p>
<p><code>FROM TABLE1 AS x, TABLE1 AS y</code></p>
<p>String Comp</p>
<p><code>LIKE</code>或者正则<code>S.name ~ '^B.*'</code> (等效于<code>S.name LIKE 'B_%'</code>)</p>
<p><code>AND</code> <code>OR</code> 做条件交并</p>
<p><code>EXCEPT</code> <code>UNION (ALL)</code> <code>INTERSECT</code>做子查询结果集合的交并差</p>
<p><code>IN</code> <code>EXISTS</code>用于子查询 (<code>NOT IN</code>, <code>NOT EXIST</code>) EXISTS是判空</p>
<div class="language-SQL language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">SELECT</span><span class="token plain"> S</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">sname </span><span class="token keyword" style="color:#00009f">FROM</span><span class="token plain"> Sailors S </span><span class="token keyword" style="color:#00009f">WHERE</span><span class="token plain"> S</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">sid </span><span class="token operator" style="color:#393A34">IN</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	</span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">SELECT</span><span class="token plain"> R</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">sid </span><span class="token keyword" style="color:#00009f">FROM</span><span class="token plain"> Reserves R </span><span class="token keyword" style="color:#00009f">WHERE</span><span class="token plain"> R</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">bid</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">102</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>还有<code>ANY</code> <code>ALL</code></p>
<p>ARGMAX?</p>
<div class="language-SQL language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">SELECT</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">FROM</span><span class="token plain"> Sailors S </span><span class="token keyword" style="color:#00009f">WHERE</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	S</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">rating </span><span class="token operator" style="color:#393A34">&gt;=</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">ALL</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">		</span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">SELECT</span><span class="token plain"> S2</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">rating </span><span class="token keyword" style="color:#00009f">FROM</span><span class="token plain"> Sailors S2</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>View: Named Queries</p>
<div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">CREATE</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">VIEW</span><span class="token plain"> xxx</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token keyword" style="color:#00009f">AS</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">SELECT</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">FROM</span><span class="token plain"> xxx</span><span class="token punctuation" style="color:#393A34">;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>cache and reuse</p>
<p>或者</p>
<p><code>WITH [viewname] AS [statement]</code>创建一个临时view</p>
<p>NULL 参与的运算大多是NULL, 除了IS NULL，False AND NULL这种</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="lec3">lec3<a class="hash-link" aria-label="Direct link to lec3" title="Direct link to lec3" href="https://ayanami1314.github.io/blog/cs186-database-WIP#lec3">​</a></h2>
<p>Disk &amp; Buffer</p>
<p>整体架构</p>
<p>SQL client-&gt; Query Parsing &amp; Optimization-&gt;Relational Operators-&gt; Files and Index Management-&gt;Buffer Management-&gt;Disk Space Management</p>
<p>Concurrency Control &amp; Recovery</p>
<p>磁盘太慢，需要尽量减少读写，且寻道和旋转时间是大头</p>
<p>"block" &amp;&amp; "page": 一个意思，磁盘上的块状读写最小单元 一般64KB-128KB</p>
<p>为了重用硬件驱动，经常会将磁盘空间管理器建立在文件系统API上，但带来了一些大数据库多文件系统的问题，也有直接建立在设备上的，更快但是移植性问题</p>
<p>给上层的抽象是一个巨大的文件</p>
<p>DB file: page的集合，每个page又包含了许多records</p>
<p>给上层提供：CRUD on records</p>
<p>record解构成一个"指针" <code>{pageID, location on page}</code></p>
<p>structures</p>
<ul>
<li>Unordered Heap Files(和数据结构heap没啥关系，无序records)</li>
<li>Clustered Heap Files</li>
<li>Sorted Files</li>
<li>Index Files</li>
</ul>
<p>如何组织page呢？</p>
<p>链表？ 想想就知道效率很差</p>
<p>类似目录的形式？ 部分page只存到其他page的指针，并且始终放在缓存之中</p>
<p>page解构</p>
<p>Page Header:</p>
<ul>
<li>Number of records</li>
<li>Free space</li>
<li>Mayba a last/next pointer</li>
<li>Bitmaps, slot table</li>
</ul>
<p>record 中间留不留空？</p>
<p>不留空：Fixed Length Records, Packed</p>
<p>header后面跟紧密定长records, 因此可以有 record id = <code>{pageId, record number in page}</code>， 简单运算得到location</p>
<p>加很简单，直接append</p>
<p>删，全移一遍？-&gt;O(N),自然想到能不能lazy delete或者soft delete</p>
<p>方法是在header里面放一个delete bit的bitmap</p>
<p>变长？</p>
<p>slotted page</p>
<p>将信息存在footer（称为slot directory）, record从头部开始存</p>
<p>由record id得到dir中位置，位置里面是pointer + length，</p>
<p>删，将slot dir中的项置空</p>
<p>插入，插在空位上，更新slot dir</p>
<p>fragmentation?</p>
<p>什么时候reorganize?-&gt;设计取舍，大部分时候没有那么多删除（乐）</p>
<p>slot不够-&gt;从page尾部向前增长</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="lec4">lec4<a class="hash-link" aria-label="Direct link to lec4" title="Direct link to lec4" href="https://ayanami1314.github.io/blog/cs186-database-WIP#lec4">​</a></h2>
<p>cost model for ayalysis</p>
<p>B, D, R</p>
<ul>
<li>the number of data blocks</li>
<li>the number of records per clock</li>
<li>avg time to r/w disk block</li>
<li>opt: index</li>
</ul>
<p>indexes:</p>
<p>大幅度降低range操作耗时</p>
<p>An index is data structure that enables fast lookup and modification of data entries by search key</p>
<p>区间查找 &amp; 子集搜索, 可以复合, 不需要唯一</p>
<p>2-d box 2-d circle n-d indexes都有</p>
<p>kd树啊R树啊</p>
<p>postgres 的 GiST index</p>
<p>left key opt: 最小的key是不需要的,直接拿-inf当下界就行</p>
<p>处理相等:<code>&gt;=</code> 向右走就行</p>
<p>B+树</p>
<ul>
<li>
<p>叶子不一定是连续的-动态分配,指针连接以支持range scan</p>
</li>
<li>
<p>阶数d, fan-out 2d+1 典型的fan-out 为2144()</p>
</li>
<li>
<p>删除, 理论上来说, 可能涉及到重新平衡等操作 但实际的操作之中, 只需要删除即可, 原因是平衡太慢了,并且删了也能再插</p>
</li>
</ul>
<p>叶子放什么?</p>
<ol>
<li>数据</li>
</ol>
<p>pros:</p>
<ul>
<li>快</li>
</ul>
<p>cons:</p>
<ul>
<li>想要在另一列构建索引只能重新复制文件(文件只能按照一种方式实际排序存储)</li>
<li>即使真复制了,同步问题也很寄</li>
</ul>
<ol start="2">
<li>指向数据的指针 (key, page id+list of record id)</li>
</ol>
<p>在b+树里面有重复项</p>
<ol start="3">
<li>指向同一个键的所有records (key, list of (page id + list of record id))</li>
</ol>
<p>减少冗余,增加复杂性</p>
<p>clustered: index指向的数据块在磁盘上是按照这个index排序或者近似排序的</p>
<p>非常大影响性能 顺序比随机快100倍</p>
<p>对于一个有变化的数据,例如插入或者删除,需要一些成本进行磁盘数据的重新排序来维持clustered</p>
<p>B+树的平衡性:</p>
<p>使用字节数半满(占页面容量)就行, 甚至实际上更低, 按照实际性能来决定,不严格</p>
<p>变长key: 前缀压缩 trie</p>
<p>性能的常数:</p>
<p>由于顺序读写比随机读写快100倍</p>
<p>B+树比全表扫描差不多也是涉及到1%以下的表才有显著优势</p>
<p>所以例如对一个非聚簇索引进行一个跨越半个表的range的扫描, 那还不如直接把全表取出来</p>
<p>优化</p>
<p>由于B+树效率真的很低,所以有很多优化策略</p>
<ul>
<li>bulk loading 批量装载</li>
</ul>
<ol>
<li>Sort the data by a key.</li>
<li>Fill leaf pages up to size f (the <strong>fill factor</strong>).</li>
<li>If the leaf page overflows, then use the insertion split algorithm from a normal B+ tree.</li>
<li>Adjust pointers to reflect new nodes if needed.</li>
</ol>]]></content:encoded>
            <category>database</category>
            <category>system</category>
        </item>
        <item>
            <title><![CDATA[NJU操作系统(jyy OS)课程笔记-虚拟化部分]]></title>
            <link>https://ayanami1314.github.io/blog/jyy-os-虚拟化</link>
            <guid>https://ayanami1314.github.io/blog/jyy-os-虚拟化</guid>
            <pubDate>Wed, 12 Feb 2025 13:56:21 GMT</pubDate>
            <description><![CDATA[lec14 操作系统上的进程]]></description>
            <content:encoded><![CDATA[<h3 class="anchor anchorWithStickyNavbar_LWe7" id="lec14-操作系统上的进程">lec14 操作系统上的进程<a class="hash-link" aria-label="Direct link to lec14 操作系统上的进程" title="Direct link to lec14 操作系统上的进程" href="https://ayanami1314.github.io/blog/jyy-os-%E8%99%9A%E6%8B%9F%E5%8C%96#lec14-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B8%8A%E7%9A%84%E8%BF%9B%E7%A8%8B">​</a></h3>
<p>cpu有初始pc地址<code>-&gt;</code>放置固件上的初始程序(固件状态机)<code>-&gt;</code>启动OS(os状态机)<code>-&gt;</code>load init程序(程序状态机), 之后OS完全把行为转交给init(进程树的root)</p>
<p>llm <code>知道存在</code>与<code>知道</code>的界限正在模糊: 知道存在且合理 逐渐趋同于 能做</p>
<p>例如 qemu 相关的一些东西</p>
<p>问llm发散出的概念<code>-&gt;</code>知识体系的快速建立</p>
<p>fork? 以状态机的视角理解</p>
<p>经典的for fork + printf</p>
<p>写了个示例</p>
<div class="language-cpp codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-cpp codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token macro property directive-hash" style="color:#36acaa">#</span><span class="token macro property directive keyword" style="color:#00009f">include</span><span class="token macro property" style="color:#36acaa"> </span><span class="token macro property string" style="color:#e3116c">&lt;cstddef&gt;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token macro property directive-hash" style="color:#36acaa">#</span><span class="token macro property directive keyword" style="color:#00009f">include</span><span class="token macro property" style="color:#36acaa"> </span><span class="token macro property string" style="color:#e3116c">&lt;cstdio&gt;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token macro property directive-hash" style="color:#36acaa">#</span><span class="token macro property directive keyword" style="color:#00009f">include</span><span class="token macro property" style="color:#36acaa"> </span><span class="token macro property string" style="color:#e3116c">&lt;cstdlib&gt;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token macro property directive-hash" style="color:#36acaa">#</span><span class="token macro property directive keyword" style="color:#00009f">include</span><span class="token macro property" style="color:#36acaa"> </span><span class="token macro property string" style="color:#e3116c">&lt;stdio.h&gt;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token macro property directive-hash" style="color:#36acaa">#</span><span class="token macro property directive keyword" style="color:#00009f">include</span><span class="token macro property" style="color:#36acaa"> </span><span class="token macro property string" style="color:#e3116c">&lt;unistd.h&gt;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token macro property directive-hash" style="color:#36acaa">#</span><span class="token macro property directive keyword" style="color:#00009f">include</span><span class="token macro property" style="color:#36acaa"> </span><span class="token macro property string" style="color:#e3116c">&lt;vector&gt;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token macro property directive-hash" style="color:#36acaa">#</span><span class="token macro property directive keyword" style="color:#00009f">include</span><span class="token macro property" style="color:#36acaa"> </span><span class="token macro property string" style="color:#e3116c">&lt;mutex&gt;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token macro property directive-hash" style="color:#36acaa">#</span><span class="token macro property directive keyword" style="color:#00009f">include</span><span class="token macro property" style="color:#36acaa"> </span><span class="token macro property string" style="color:#e3116c">&lt;sys/wait.h&gt;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token macro property directive-hash" style="color:#36acaa">#</span><span class="token macro property directive keyword" style="color:#00009f">include</span><span class="token macro property" style="color:#36acaa"> </span><span class="token macro property string" style="color:#e3116c">&lt;map&gt;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token macro property directive-hash" style="color:#36acaa">#</span><span class="token macro property directive keyword" style="color:#00009f">include</span><span class="token macro property" style="color:#36acaa"> </span><span class="token macro property string" style="color:#e3116c">&lt;string&gt;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">using</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">namespace</span><span class="token plain"> std</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">const</span><span class="token plain"> size_t buf_size </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1024</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">const</span><span class="token plain"> std</span><span class="token double-colon punctuation" style="color:#393A34">::</span><span class="token plain">map</span><span class="token operator" style="color:#393A34">&lt;</span><span class="token keyword" style="color:#00009f">int</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> std</span><span class="token double-colon punctuation" style="color:#393A34">::</span><span class="token plain">string</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> mode_map </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">_IONBF</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"no buffer"</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">_IOLBF</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"line buffer"</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">_IOFBF</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"full buffer"</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">void</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">test</span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">int</span><span class="token plain"> __modes</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token function" style="color:#d73a49">printf</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"test in mode %s\n"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> mode_map</span><span class="token punctuation" style="color:#393A34">.</span><span class="token function" style="color:#d73a49">at</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">__modes</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token function" style="color:#d73a49">c_str</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token function" style="color:#d73a49">fflush</span><span class="token punctuation" style="color:#393A34">(</span><span class="token constant" style="color:#36acaa">stdout</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    vector</span><span class="token operator" style="color:#393A34">&lt;</span><span class="token keyword" style="color:#00009f">int</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> childs</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std</span><span class="token double-colon punctuation" style="color:#393A34">::</span><span class="token plain">mutex mtx</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token function" style="color:#d73a49">setvbuf</span><span class="token punctuation" style="color:#393A34">(</span><span class="token constant" style="color:#36acaa">stdout</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">nullptr</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> __modes</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">int</span><span class="token plain"> i </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"> i </span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">++</span><span class="token plain">i</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">int</span><span class="token plain"> pid </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">fork</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token function" style="color:#d73a49">printf</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"hello from pid %d\n"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> pid</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">pid </span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            std</span><span class="token double-colon punctuation" style="color:#393A34">::</span><span class="token plain">lock_guard</span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain">mutex</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">lock</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">mtx</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            childs</span><span class="token punctuation" style="color:#393A34">.</span><span class="token function" style="color:#d73a49">push_back</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">pid</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">int</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">main</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic">// _IOLBF, _IOFBF, _IONBF</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token function" style="color:#d73a49">test</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">_IOFBF</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token function" style="color:#d73a49">printf</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"\n"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token function" style="color:#d73a49">fflush</span><span class="token punctuation" style="color:#393A34">(</span><span class="token constant" style="color:#36acaa">stdout</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>在<code>_IOLBF</code>和<code>_IONBF</code>的情况下会出来6个hello</p>
<p>每次printf都直接刷新/检测到换行符刷新缓冲, fork的时候没有IO状态
而<code>_IOFBF</code>会有8个hello, 在fork第二次的时候会带着缓冲区(就是一段内存空间)进行fork,所以最后的4个进程每个都带着2个hello</p>
<p><strong>系统里面没有魔法</strong></p>
<p>fork: 把所有的知道的不知道的都复制了</p>
<p>“是不是这样?” <code>-&gt;</code> 不知道的底层状态被复制了</p>
<p><code>execve</code>: <strong>重置状态机</strong> <code>argc, argv, envp -&gt; main()</code></p>
<p>execve是唯一一个可以新建一个状态机的系统调用</p>
<p><code>exit</code>?</p>
<ul>
<li>main return</li>
<li><code>exit</code> libc提供的</li>
<li><code>_exit</code> 系统调用退出（<code>== asm volatile("mov ..., %rax; syscall")</code>）</li>
<li>直接<code>SYSCALL</code></li>
</ul>
<p>前两个在c语言的空间, 是“normal exit”</p>
<p>后两个不是normal的, <code>_exit</code> <code>exit_group</code> , <code>__exit</code> exit self</p>
<p>行为区别? <code>strace</code></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="lec15-进程的地址空间">lec15 进程的地址空间<a class="hash-link" aria-label="Direct link to lec15 进程的地址空间" title="Direct link to lec15 进程的地址空间" href="https://ayanami1314.github.io/blog/jyy-os-%E8%99%9A%E6%8B%9F%E5%8C%96#lec15-%E8%BF%9B%E7%A8%8B%E7%9A%84%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4">​</a></h3>
<p>pmap</p>
<p><code>/proc/[pid]/maps</code></p>
<p>vvar(r), vdso(rx), vsyscall</p>
<p>os内只读的syscall <code>-&gt;</code> 可以以内存的形式共享</p>
<p>其实只需要进程能和OS交互一些数据就行 —— why not进程写page, OS轮询?</p>
<ul>
<li>在极端的时候能提高一些高优先级的进程的性能, 某篇OSDI</li>
</ul>
<p>地址空间应该是在运行时可变的</p>
<p>所以我们需要一个不存在于c世界的操作(syscall)去操作地址空间 <code>-&gt;</code> mmap, munmap</p>
<p>入侵进程的地址空间: gdb, perf</p>
<p>Game Genie 物理入侵地址空间</p>
<ul>
<li>外接电路: 当cpu读地址a的时候读到x, 则替换为y</li>
</ul>
<p>jyy现场演示mini CE(雾)</p>
<p>gdb attach到虚拟机,查找满足某个模式的内存值, 修改之</p>
<p><code>/proc/[pid]/mem</code> 修改器 = 调试器</p>
<p>xdotool: cmd X11 automation tool</p>
<p>ydotool: better xdotool <code>-&gt;</code> 按键精灵</p>
<p>evdev 按键显示脚本</p>
<p>xdotool测试vsc插件, crazy</p>
<p>或许不需要那么多的“魔法工具”</p>
<p>OS: 解放编程能力, 什么事情在OS上可以做</p>
<p>变速齿轮: syscall是感知时间的唯一方法</p>
<p>gdb 脚本之中, 在gettimeofday打断点, 然后修改寄存器, amazing!!!</p>
<p>hook</p>
<p>patching: 整活, kpatch, 不停机更新(软件动态链接)</p>
<p><code>old func, rx -&gt; 修改为rwx -&gt; 修改old func为, jmp到new func</code></p>
<p>在chcore里面看看? 或许有必要研究一下gdb(attach with qemu)</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="lec16-syscall--unix-shell">lec16 syscall &amp; unix shell<a class="hash-link" aria-label="Direct link to lec16 syscall &amp; unix shell" title="Direct link to lec16 syscall &amp; unix shell" href="https://ayanami1314.github.io/blog/jyy-os-%E8%99%9A%E6%8B%9F%E5%8C%96#lec16-syscall--unix-shell">​</a></h3>
<p>everything is a file</p>
<p>thing: 操作系统里面的对象</p>
<p>gpt时代的“编程”——自然语言?</p>
<div class="language-c codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-c codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic">//OS: API:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">//	get_object_by_name(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">//		"the address space file of pid=1234"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">//	)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><strong>文件描述符: 指向OS对象的“指针”</strong></p>
<p>windows: handle(句柄)</p>
<p>IPC endpoints: 例子, 管道</p>
<p>管道是同步的</p>
<p>fork + pipe? 本质是"指针"的拷贝</p>
<p>现在两个进程都有读口和写口啦</p>
<p>shell, kernel 的外壳</p>
<p>cli: 高效简洁的编程语言</p>
<p>算力的提升: <code>cli -&gt; gui -&gt; 自然语言</code></p>
<p>shell as pl: <strong>基于文本替换的快速工作流搭建</strong></p>
<p>job control: 类比窗口管理器的"x", 最小化</p>
<p>或许不需要tmux, shell就是最简单的tmux</p>
<p>手册: complete ref</p>
<p>AI是“被动的”, 读一读shell manual</p>
<p>复刻unix shell</p>
<p>“抛开系统库”</p>
<p><code>-ffreestanding -nostdlib -static</code></p>
<p>gdb init已经很常见了, 但gdb init到python再在python里面转回<code>/proc/[pid]/fd</code>打印, 最后结合gdb的内置hook,在stop时候打印, fancy!</p>
<p>这打印的不是我们go的channel语法吗, 更有趣了</p>
<p>sh manual</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="lec-17-syscall的封装-libc">lec 17 syscall的封装: libc<a class="hash-link" aria-label="Direct link to lec 17 syscall的封装: libc" title="Direct link to lec 17 syscall的封装: libc" href="https://ayanami1314.github.io/blog/jyy-os-%E8%99%9A%E6%8B%9F%E5%8C%96#lec-17-syscall%E7%9A%84%E5%B0%81%E8%A3%85-libc">​</a></h3>
<p>pipe write如果小于PIPE_BUF, 是原子的</p>
<p>pipe 7</p>
<p>读者关闭: Broken pipe</p>
<p>libc 标准化, 稳定可靠, 移植性极好</p>
<p>C runtime library: -Wl, --verbose看到链接列表</p>
<p>调试glibc? 历史包袱重, 大量内联汇编, musl</p>
<p>只要实现了C ABI指定的堆栈排布的系统调用, 就可以轻松移植musl等到自己的OS上, 底层的计算由硬件指令集给出</p>
<p>System V ABI</p>
<p>脱开workload 做优化就是耍流氓</p>
<ul>
<li>在开始考虑性能之前, 理解需要考虑什么样的性能</li>
</ul>
<p><strong>workload哪里找? 当然是paper了(顺便白得方案)</strong></p>
<ul>
<li>看wkld调性能</li>
</ul>
<p>mm alloctor: 根基</p>
<ul>
<li>大对象应该有长生存期, 否则是performance bug</li>
<li>越小的对象创建/分配越频繁</li>
<li>小对象, 中对象, 大对象</li>
</ul>
<p>瓶颈几乎是小对象</p>
<p>链表/区间树不是一个好想法: 上锁, 不能很好的并行化</p>
<p>设置两套系统：</p>
<ul>
<li>Fast path 性能极好，并行度极高，覆盖大部分情况</li>
<li>Slow path 不在乎速度，但把困难的事情做好</li>
<li>例如cache</li>
</ul>
<p>init ram fs</p>
<p>ISA -&gt; OS 对象/syscall -&gt; libc -&gt; 系统工具 coreutils, busybox -&gt; 应用程序</p>
<p>initramfs</p>
<ul>
<li>
<p>加载剩余必要的驱动程序, 例如磁盘/网卡</p>
</li>
<li>
<p>挂载必要的fs</p>
</li>
<li>
<p><strong>将根文件系统和控制权移交给另一个程序, 例如systemd</strong></p>
</li>
</ul>
<p>initramfs作为一个非常小的启动fs, 再把磁盘这个OS Object mount进来, 最后switch root把控制权给到磁盘的的根系统</p>
<p>启动的第二级阶段 /sbin/init</p>
<p>疯狂的事情不断有人在做, 但疯狂的事情的起点其实经常很小</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="lec-19-可执行文件">lec 19 可执行文件<a class="hash-link" aria-label="Direct link to lec 19 可执行文件" title="Direct link to lec 19 可执行文件" href="https://ayanami1314.github.io/blog/jyy-os-%E8%99%9A%E6%8B%9F%E5%8C%96#lec-19-%E5%8F%AF%E6%89%A7%E8%A1%8C%E6%96%87%E4%BB%B6">​</a></h3>
<p>elf不是一个人类友好的“状态机数据结构描述”</p>
<p>为了性能, 彻底违背了可读(“信息局部性”)原则</p>
<p>可执行文件=OS的<strong>数据结构</strong>(core.dump), 描述了程序应该的初始状态</p>
<p>支持的特性越多, 人类越不能理解</p>
<p>人类友好: <strong>平坦的</strong></p>
<p>回归连接和加载的核心概念: 代码、符号、重定位</p>
<p>my_execve</p>
<p>elf file -&gt; parse as struct</p>
<p>-&gt; 将各个section load到指定的地址(mmap)-&gt;asm volatile布置好ABI调用栈(根据手册)-&gt;jmp!</p>
<p>如何释放旧进程的内存资源？proc里面需要有记录</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="lec-21-syscall--ctx-switch">lec 21 syscall &amp; ctx switch<a class="hash-link" aria-label="Direct link to lec 21 syscall &amp; ctx switch" title="Direct link to lec 21 syscall &amp; ctx switch" href="https://ayanami1314.github.io/blog/jyy-os-%E8%99%9A%E6%8B%9F%E5%8C%96#lec-21-syscall--ctx-switch">​</a></h3>
<p>dynamic linker</p>
<p>se给的os基础还是很扎实的
很难想象ics2里面讲了GOT和PLT</p>
<p>SEE ALSO是一个宝藏 man ld.so</p>
<p>hacking: <code>LD_PRELOAD</code>不需要修改libc, 动态加载的全局符号, <strong>先到先得</strong></p>
<p><strong>劫持大法</strong>！</p>
<p>kernel memory mapping</p>
<p>低配版Linux 1.X 分段, 内核在低位, 只是分个段</p>
<p>低配版Linux 2.X 内核还是在物理低位, 但程序看到虚拟地址已经是高位了</p>
<p>today: complete memory map</p>
<p>qemu is a state machine simulator: 调试syscall(gdb并不能si从用户态进kernel)</p>
<p>另一种理解中断的方式："被"插入一条syscall</p>
<p>中断, 把状态机的整个寄存器状态存到内存里面</p>
<p>在汇编之中小心排布内存和搬运寄存器, 返回到c之中就是结构体的context</p>
<p>schedule的核心: 调用一个“不会返回的函数”</p>
<p>这个(汇编)函数以context为参数, 并且根据context, 返回到另一处控制流...</p>
<p><code>-&gt;</code> coroutine 也是如此! OS作为一个“状态机管理器”就在做一个"coroutine event handler"的作用</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="lec-22-process">lec 22 process<a class="hash-link" aria-label="Direct link to lec 22 process" title="Direct link to lec 22 process" href="https://ayanami1314.github.io/blog/jyy-os-%E8%99%9A%E6%8B%9F%E5%8C%96#lec-22-process">​</a></h3>
<p>进程: “戴上VR”的thread</p>
<p>有自己的地址转换, 对一切的load/store会应用一个f，作用在addr上</p>
<p>硬件提供了“戴上VR”的指令</p>
<p>这个f从ds的视角来说就是<code>int-&gt;int</code>的映射</p>
<p>查页表(<code>int-&gt;int</code>的映射)这件事, 如何加速? --自然想到radix tree</p>
<p>普通实现是radix tree(x86, riscv, ...收敛到的最终方案)</p>
<p>每一次访存都要查这么几次的话不可接受</p>
<p>因此有了TLB, 但立刻带来的一个设计问题是, 谁来管TLB(以及对应的miss处理？)</p>
<p>x86选择放到硬件, 但丧失灵活性的后果是即使有些进程只想要f(x)=x, 也必须要老实查表, TLB在和cpu cache抢带宽</p>
<p>MIPS选择放到软件, miss了直接丢出来异常, 让软件来决定怎么处理TLB</p>
<p>疯狂的想法: inverted page table</p>
<p>把key从VPN换成 (VPN, pid), 然后从一一映射改成hashtable, 支持每个进程有自己的页表</p>
<p>缺点在例如hashtable带来的冲突时(TLB miss, etc)时间不可控(O(1) ~ O(n))</p>
<p>每个进程都有自己的“VR眼镜”这件事情还带来了更多的优化空间, 例如多个进程, 不同的虚拟地址块映射到同一个物理地址, 以及cow</p>
<p>KSM(kernel samepage merging/mermory deduplication), demand paging</p>
<p>fork: 进程快照, redis</p>
<p>cow fork的缺点: 让系统实现变复杂</p>
<p>改革: 砍掉所有的内核部分, 剩下的全部交给xv6</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="lec-23-处理器调度">lec 23 处理器调度<a class="hash-link" aria-label="Direct link to lec 23 处理器调度" title="Direct link to lec 23 处理器调度" href="https://ayanami1314.github.io/blog/jyy-os-%E8%99%9A%E6%8B%9F%E5%8C%96#lec-23-%E5%A4%84%E7%90%86%E5%99%A8%E8%B0%83%E5%BA%A6">​</a></h3>
<p>trampoline code</p>
<p>跳板代码, 例子</p>
<ul>
<li>call printf -&gt; call *GOT(printf)</li>
<li>JIT编译器</li>
<li>软件热更新(patch 函数头)</li>
</ul>
<p>资源调度(分配)是一个非常复杂的问题</p>
<p>建模, 预测, 决策 <code>-&gt;</code> 调度策略的设计空间</p>
<p>调度策略</p>
<p>再加一层机制 "niceness", 管理员控制nice, 越nice越能得到cpu</p>
<p>10 nice ~ 10倍性能差异</p>
<p>taskset 绑定一个process到一个cpu上</p>
<p>round-robin时代: MLFQ, 动态优先级</p>
<ul>
<li>
<p>让出CPU(I/O) -&gt; “好”</p>
</li>
<li>
<p>用完时间片 -&gt; “坏”!</p>
</li>
</ul>
<p>1960s: breakthrough!</p>
<p>2020s: 对很多负载都欠考虑</p>
<p>今天的调度: CFS(complete fair scheduling)</p>
<p>但有vruntime, "好人"的钟快一些</p>
<p>真实的处理器调度: 不要高兴得太早...</p>
<ul>
<li><strong>低优先级的在持有mutex的时候被中间优先级的赶下处理器</strong>, 可以<strong>导致高优先级的任务等待mutex退化到低优先级</strong> <code>-&gt;</code> 火星车</li>
</ul>
<p><strong>Linux: 没法解决, CFS凑合用</strong></p>
<p>实时系统: 火星车在CPU Reset, 不能摆烂</p>
<ul>
<li>
<p>优先级继承, 条件变量唤醒?</p>
</li>
<li>
<p>lockdep预警</p>
</li>
<li>
<p>...</p>
</li>
</ul>
<p><strong>然而不止有锁, 还有多处理器...</strong></p>
<p><strong>今天的计算机系统: SMP</strong></p>
<p><strong>多处理器的矛盾困境</strong></p>
<ul>
<li><strong>绑定一个线程:"一核有难, 八方围观"</strong></li>
<li><strong>谁空丢给谁: cache, TLB白干</strong></li>
</ul>
<p><strong>更多的实际情况: NUMA, 异构, 多用户</strong></p>
<ul>
<li>
<p><strong>numa: 远近cpu性能差达到数倍</strong></p>
</li>
<li>
<p><strong>多用户的cpu共享? namespaces, cgroups, 例如一个程序开并行, 另一个程序是串行的, 是否需要给串行的保留一个核, 而不是开得越多抢得越多</strong></p>
</li>
<li>
<p><strong>异构, 大小核超小核, GPUNPU, 每个核的独有缓存和共享缓存...</strong></p>
</li>
<li>
<p><strong>更少的处理器可能更快...(反直觉, 同步cacheline带来的开销)</strong></p>
</li>
</ul>
<p>复杂的系统无人掌控</p>
<p>ghOSt: Fast &amp; Flexible User-Space Delegation of Linux</p>
<p>开始下放给应用程序做调度</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="others">Others<a class="hash-link" aria-label="Direct link to Others" title="Direct link to Others" href="https://ayanami1314.github.io/blog/jyy-os-%E8%99%9A%E6%8B%9F%E5%8C%96#others">​</a></h3>
<p>早期优雅的设计可能会成为后续发展的包袱: fork+exec带来的膨胀, <strong>所有涉及到OS内部状态的api都需要考虑fork行为</strong>, 例如文件偏移量...</p>
<p>总线, 中断控制器, DMA</p>
<p>总线: 提供设备的“虚拟化”, 注册和转发, 把收到的地址(总线地址)和数据转发到对应的设备上</p>
<p><strong>这样cpu只需要直连一根总线就行了!</strong></p>
<p>PCI总线</p>
<ul>
<li>总线可以桥接其他总线, 例如<code>pci -&gt; usb</code></li>
</ul>
<p><code>lspci -tv</code>可视化</p>
<p>"即插即用"的实现——非常复杂!</p>
<p>cpu: 只有一根中断线</p>
<p>启动多个cpu: cpu给其他cpu发中断!</p>
<p>中断仲裁: 收集各个设备中断, 选一个发给cpu</p>
<p>APIC(Advanced PIC):</p>
<ul>
<li>local APIC: 中断向量表, IPI, 时钟, ...</li>
<li>IO APIC: IO设备</li>
</ul>
<p>DMA: 很早期就有了, 解放cpu, 设计专用的电路只做memcpy</p>
<p>今天: PCI总线直接支持</p>
<p><strong>文件 = 实现了文件操作的“Anything”</strong></p>
<p><strong>设备驱动程序: 一个 struct file_operations的实现, 就是一段普通的内核, “翻译”read/write等系统调用</strong></p>
<p><code>/dev/null</code>的驱动: read永远什么都不做返回0, write永远什么都不做返回count</p>
<p>一种"duck type"</p>
<p>设备不仅仅是数据, 还有配置</p>
<p>配置设备:</p>
<ul>
<li>控制作为数据流的一部分(自定义一套write的指令编码)</li>
<li>提供一个新的接口</li>
</ul>
<p>ioctl: 非数据的设备功能几乎完全依赖ioctl, 完全由驱动决定</p>
<p>数量最庞大,质量最低的shit</p>
<p>unix的负担: 复杂的hidden spec</p>
<p>/dev/kvm 硬件虚拟化, 支撑了几乎所有的云产商虚拟化方案</p>
<p>unix的设计: 目录树的拼接</p>
<p>将一棵目录树拼到另一棵上</p>
<p>回想最小linux系统, 只有/dev/console和几个文件</p>
<p>/proc, /sys, /tmp都是mount系统调用创建的</p>
<p>"看到的fs!=磁盘的fs", is just a <strong>view</strong></p>
<p>像是procfs这种并非实际的fs更是, 可以挂载到任意的地方, 以任意的数量(因为他只是fake了read/write的“file Object”)</p>
<p>根本设计哲学: 灵活</p>
<p>灵活性带来的</p>
<ul>
<li><code>/</code>, <code>/home</code>, <code>/var</code>都可以是独立的设备, 把有些快的放在一个目录存可执行文件, 另一些存数据...</li>
</ul>
<p>mount一个文件? loopback device</p>
<p>设备驱动把设备的read/write翻译成文件的rw</p>
<p>FHS: Filesystem Hierarchy Standard</p>
<p>ln -s 图结构 as 状态机</p>
<p>fs: 一个”数据结构题“, 但读写的单元是一个block</p>
<p>FAT: 集中保存所有"next"指针, 可靠性? 存n份!</p>
<p>fat manual</p>
<p>fat 小文件ok, 大文件不行</p>]]></content:encoded>
            <category>os</category>
            <category>system</category>
            <category>virtualize</category>
        </item>
    </channel>
</rss>